{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e77c2854",
   "metadata": {},
   "source": [
    "---\n",
    "description: Runs the server and then multiple integration scenarious agains it\n",
    "output-file: integration_test.html\n",
    "title: Integration test\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp integraion_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:22:11.493088: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "[WARNING] airt.testing.activate_by_import: Failed to set gpu memory limit for tf; This could happen because of no gpu availability\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af70c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import *\n",
    "\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import pyotp\n",
    "from airt.remote_path import RemotePath\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "from fastcore.script import Param, call_parse\n",
    "from sqlmodel import select\n",
    "\n",
    "from airt_service.aws.utils import upload_to_s3_with_retry\n",
    "from airt_service.sanitizer import sanitized_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df37bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "import posix_ipc\n",
    "import pytest\n",
    "import uvicorn\n",
    "\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.server import create_ws_server\n",
    "from airt_service.uvicorn_helpers import run_uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def integration_scenario_docs(base_url: str = \"http://0.0.0.0:6006\"):\n",
    "    \"\"\"Test fastapi docs\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"getting /docs\")\n",
    "    r = httpx.get(f\"{base_url}/docs\")\n",
    "    assert not r.is_error, r  # nosec B101\n",
    "\n",
    "    sanitized_print(\"getting /redocs\")\n",
    "    r = httpx.get(f\"{base_url}/redoc\")\n",
    "    assert not r.is_error, r  # nosec B101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_auth(base_url: str, username: str, password: str) -> str:\n",
    "    \"\"\"Get jwt token for given credentials\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        username: Username\n",
    "        password: Password\n",
    "    Returns:\n",
    "        The jwt token for the given username and password\n",
    "    \"\"\"\n",
    "    # Authenticate\n",
    "    sanitized_print(\"authenticating and getting token\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/token\",\n",
    "        data=dict(username=username, password=password),\n",
    "        timeout=30,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    token = r.json()[\"access_token\"]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec41e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_create_user(base_url: str) -> Tuple[Dict[str, Any], str]:\n",
    "    \"\"\"Create a new user for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    Returns:\n",
    "        The user dictionary and its password as a tuple\n",
    "    \"\"\"\n",
    "    # Get token for super user\n",
    "    token = os.environ[\"AIRT_SERVICE_TOKEN\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    sanitized_print(\"creating user\")\n",
    "    username = \"\".join(  # nosec\n",
    "        random.choice(string.ascii_lowercase) for _ in range(10)\n",
    "    )\n",
    "    password = \"\".join(  # nosec\n",
    "        random.choice(string.ascii_lowercase) for _ in range(10)\n",
    "    )\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/\",\n",
    "        json=dict(\n",
    "            username=username,\n",
    "            first_name=\"integration\",\n",
    "            last_name=\"user\",\n",
    "            email=f\"{username}@email.com\",\n",
    "            subscription_type=\"small\",\n",
    "            super_user=False,\n",
    "            password=password,\n",
    "            otp=None,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=30,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    user = r.json()\n",
    "    return user, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb03799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_apikey(\n",
    "    base_url: str, headers: Dict[str, str], otp: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Create apikey for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        otp: Dynamically generated six-digit verification code from the authenticator app\n",
    "    Returns:\n",
    "        The apikey jwt token\n",
    "    \"\"\"\n",
    "    sanitized_print(\"creating apikey\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/apikey\",\n",
    "        json=dict(\n",
    "            expiry=(datetime.utcnow() + timedelta(minutes=60)).isoformat(), otp=otp\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    apikey = r.json()[\"access_token\"]\n",
    "    return apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca364f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def check_steps_completed(url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Check whether completed steps equals to total steps\n",
    "\n",
    "    Args:\n",
    "        url: Url to call\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        The dictionary returned by url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"start waiting for steps to complete\")\n",
    "    while True:\n",
    "        r = httpx.get(url, headers=headers)\n",
    "        assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "        obj = r.json()\n",
    "        if obj[\"completed_steps\"] == obj[\"total_steps\"]:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "    sanitized_print(\"stop waiting for steps to complete\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71850726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_csv_local_datablob_and_datasource(\n",
    "    base_url: str, headers: Dict[str, str]\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"Create datablob from local, upload csv files and create datasource from it\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        Datablob and datasource dictionaries as a tuple\n",
    "    \"\"\"\n",
    "    # Create csv datablob\n",
    "    sanitized_print(\"creating datablob\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/from_local/start\",\n",
    "        json=dict(path=\"tmp/test-folder/\"),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datablob_uuid = r.json()[\"uuid\"]\n",
    "    presigned = r.json()[\"presigned\"]\n",
    "\n",
    "    sanitized_print(\"downloading csv file\")\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        df = pd.read_parquet(test_s3_path.as_path())\n",
    "        df.to_csv(test_s3_path.as_path() / \"file.csv\", index=False)\n",
    "\n",
    "        sanitized_print(\"uploading csv file using presigned url\")\n",
    "        upload_to_s3_with_retry(\n",
    "            test_s3_path.as_path() / \"file.csv\", presigned[\"url\"], presigned[\"fields\"]\n",
    "        )\n",
    "\n",
    "    # Create datasource from csv datablob\n",
    "    sanitized_print(\"creating datasource\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/{datablob_uuid}/to_datasource\",\n",
    "        json=dict(\n",
    "            file_type=\"csv\",\n",
    "            deduplicate_data=True,\n",
    "            index_column=\"PersonId\",\n",
    "            sort_by=\"OccurredTime\",\n",
    "            blocksize=\"256MB\",\n",
    "            kwargs_json=dict(\n",
    "                usecols=[0, 1, 2, 3, 4],\n",
    "                parse_dates=[\"OccurredTime\"],\n",
    "            ),\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datasource = r.json()\n",
    "\n",
    "    # Wait for pull to complete\n",
    "    datasource = check_steps_completed(\n",
    "        url=f\"{base_url}/datasource/{datasource['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"pull completed for datasource\")\n",
    "\n",
    "    # Get datablob object to return\n",
    "    datablob = check_steps_completed(\n",
    "        url=f\"{base_url}/datablob/{datablob_uuid}\", headers=headers\n",
    "    )\n",
    "\n",
    "    # Display head and dtypes\n",
    "    r = httpx.get(f\"{base_url}/datasource/{datasource['uuid']}/head\", headers=headers)\n",
    "    sanitized_print(\"head of datasource\")\n",
    "    sanitized_print(r.json())\n",
    "    r = httpx.get(f\"{base_url}/datasource/{datasource['uuid']}/dtypes\", headers=headers)\n",
    "    sanitized_print(\"dtypes of datasource\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return datablob, datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe92e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_azure_datablob(base_url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Create datablob using from_azure route\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        A azure datablob\n",
    "    \"\"\"\n",
    "    storage_client = StorageManagementClient(\n",
    "        DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "    )\n",
    "    keys = storage_client.storage_accounts.list_keys(\n",
    "        \"test-airt-service\", \"testairtservice\"\n",
    "    )\n",
    "    credential = keys.keys[0].value\n",
    "\n",
    "    # Create azure datablob\n",
    "    sanitized_print(\"creating azure datablob\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/from_azure_blob_storage\",\n",
    "        json=dict(\n",
    "            uri=\"https://testairtservice.blob.core.windows.net/test-container/account_312571_events\",\n",
    "            credential=credential,\n",
    "            cloud_provider=\"azure\",\n",
    "            region=\"westeurope\",\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datablob = r.json()\n",
    "\n",
    "    # Wait for pull to complete\n",
    "    datablob = check_steps_completed(\n",
    "        url=f\"{base_url}/datablob/{datablob['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"pull completed for azure datablob\")\n",
    "\n",
    "    return datablob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_model(\n",
    "    base_url: str, headers: Dict[str, str], datasource: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Train model and evaluate it for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        datasource: Datasource dictionary\n",
    "    Returns:\n",
    "        The model dictionary\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    sanitized_print(\"training model\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/model/train\",\n",
    "        json=dict(\n",
    "            data_uuid=datasource[\"uuid\"],\n",
    "            client_column=\"AccountId\",\n",
    "            target_column=\"DefinitionId\",\n",
    "            target=\"load*\",\n",
    "            predict_after=20 * 24 * 60 * 60,\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    model = r.json()\n",
    "\n",
    "    # Wait for model training to complete\n",
    "    model = check_steps_completed(\n",
    "        url=f\"{base_url}/model/{model['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"model training completed\")\n",
    "\n",
    "    # Evaluate model\n",
    "    r = httpx.get(f\"{base_url}/model/{model['uuid']}/evaluate\", headers=headers)\n",
    "    assert not r.is_error  # nosec B101\n",
    "    sanitized_print(\"model evaluation\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8148cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_prediction(\n",
    "    base_url: str, headers: Dict[str, str], model: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run prediction and evaluate prediction for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        model: Model dictionary\n",
    "    Returns:\n",
    "        The prediction dictionary\n",
    "    \"\"\"\n",
    "    # Run prediction for the model\n",
    "    sanitized_print(\"running prediction\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/model/{model['uuid']}/predict\",\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    prediction = r.json()\n",
    "\n",
    "    # Wait for prediction to complete\n",
    "    prediction = check_steps_completed(\n",
    "        url=f\"{base_url}/prediction/{prediction['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"prediction completed\")\n",
    "\n",
    "    # Get prediction as pandas\n",
    "    r = httpx.get(f\"{base_url}/prediction/{prediction['uuid']}/pandas\", headers=headers)\n",
    "    assert not r.is_error  # nosec B101\n",
    "    sanitized_print(\"prediction as pandas\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44313d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_generate_mfa_url(base_url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate mfa provisioning uri\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "\n",
    "    Returns:\n",
    "        The provisioning uri generated from the secret\n",
    "    \"\"\"\n",
    "\n",
    "    r = httpx.get(f\"{base_url}/user/mfa/generate\", headers=headers)\n",
    "    assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "    sanitized_print(\"Generating mfa url\")\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_valid_otp(mfa_url: str) -> str:\n",
    "    \"\"\"Get valid otp for the mfa_url\n",
    "\n",
    "    Args:\n",
    "        mfa_url: mfa provisioning url\n",
    "\n",
    "    Returns:\n",
    "        The valid otp for the url\n",
    "    \"\"\"\n",
    "    return pyotp.TOTP(pyotp.parse_uri(mfa_url).secret).now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d158090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_activate_mfa(\n",
    "    base_url: str, mfa_url: str, headers: Dict[str, str]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Activate mfa\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        mfa_url: mfa provisioning url\n",
    "        headers: Headers dict with authorization header\n",
    "\n",
    "    Returns:\n",
    "        The provisioning uri generated from the secret\n",
    "    \"\"\"\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/mfa/activate\",\n",
    "        json=dict(user_otp=get_valid_otp(mfa_url)),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "    sanitized_print(\"Activate mfa\")\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df232845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def reset_test_user_password(\n",
    "    base_url: str, headers: Dict[str, str], username: str, password: str, otp: str\n",
    "):\n",
    "    \"\"\"Reset the test user password\"\"\"\n",
    "    sanitized_print(f\"Resetting password for: {username}\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/reset_password\",\n",
    "        json=dict(username=username, new_password=password, otp=otp),\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    sanitized_print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_disable_mfa(\n",
    "    base_url: str, headers: Dict[str, str], username: str, otp: Optional[str] = None\n",
    "):\n",
    "    \"\"\"Disable MFA for the user\"\"\"\n",
    "    current_active_user = httpx.get(\n",
    "        f\"{base_url}/user/details?user_id_or_name=None\", headers=headers\n",
    "    )\n",
    "    current_active_user_uuid = current_active_user.json()[\"uuid\"]\n",
    "    r = httpx.delete(\n",
    "        f\"{base_url}/user/mfa/{current_active_user_uuid}/disable?otp={otp}\",\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    sanitized_print(r.text)\n",
    "    assert username in r.text  # nosec B101\n",
    "    sanitized_print(\"Deactivate mfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77152a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_auth_with_otp(\n",
    "    base_url: str, username: str, password: str, mfa_url: str, retry_limit: int = 3\n",
    ") -> str:\n",
    "    \"\"\"Get jwt token for given credentials and otp\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        username: Username\n",
    "        password: Password\n",
    "        mfa_url: MFA URL\n",
    "        retry_limit: Retry limit if there is an error with otp auth\n",
    "    Returns:\n",
    "        The jwt token for the given username and password\n",
    "    \"\"\"\n",
    "    # Authenticate\n",
    "    sanitized_print(\"authenticating with otp and getting token\")\n",
    "    for i in range(retry_limit):\n",
    "        otp = get_valid_otp(mfa_url)\n",
    "        r = httpx.post(\n",
    "            f\"{base_url}/token\",\n",
    "            data=dict(\n",
    "                username=username,\n",
    "                password=json.dumps(\n",
    "                    {\n",
    "                        \"password\": password,\n",
    "                        \"user_otp\": otp,\n",
    "                    }\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if not r.is_error:\n",
    "            break\n",
    "\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    token = r.json()[\"access_token\"]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8624d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def delete_test_user(base_url: str, test_username: str):\n",
    "    \"\"\"Delete the test user created for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        test_username: Username to delete\n",
    "    \"\"\"\n",
    "    # Get token for super user\n",
    "    token = os.environ[\"AIRT_SERVICE_TOKEN\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    sanitized_print(\"deleting test user\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/cleanup\",\n",
    "        json=dict(\n",
    "            username=test_username,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=None,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def integration_tests(base_url: str = \"http://127.0.0.1:6006\"):\n",
    "    \"\"\"Integration tests\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"starting integration tests\")\n",
    "    integration_scenario_docs(base_url)\n",
    "\n",
    "    user, password = test_create_user(base_url)\n",
    "\n",
    "    token = test_auth(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=password,\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    # enable mfa for the user\n",
    "    mfa_url = test_generate_mfa_url(base_url, headers)\n",
    "    # activate mfa\n",
    "    test_activate_mfa(base_url, mfa_url[\"mfa_url\"], headers)\n",
    "\n",
    "    # Get token by passing password and otp as json encoded dict\n",
    "    token = test_auth_with_otp(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=password,\n",
    "        mfa_url=mfa_url[\"mfa_url\"],\n",
    "        retry_limit=3,\n",
    "    )\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    apikey = test_apikey(base_url, headers, otp=get_valid_otp(mfa_url[\"mfa_url\"]))\n",
    "    headers = {\"Authorization\": f\"Bearer {apikey}\"}\n",
    "\n",
    "    datablob, datasource = test_csv_local_datablob_and_datasource(base_url, headers)\n",
    "\n",
    "    azure_datablob = test_azure_datablob(base_url, headers)\n",
    "\n",
    "    model = test_model(base_url, headers, datasource)\n",
    "\n",
    "    prediction = test_prediction(base_url, headers, model)\n",
    "\n",
    "    new_password = \"new_password\"  # nosec B105\n",
    "    reset_test_user_password(\n",
    "        base_url=base_url,\n",
    "        headers=headers,\n",
    "        username=user[\"username\"],\n",
    "        password=new_password,\n",
    "        otp=get_valid_otp(mfa_url[\"mfa_url\"]),\n",
    "    )\n",
    "\n",
    "    # Get token by using the new password\n",
    "    token = test_auth_with_otp(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=new_password,\n",
    "        mfa_url=mfa_url[\"mfa_url\"],\n",
    "        retry_limit=3,\n",
    "    )\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    test_disable_mfa(\n",
    "        base_url, headers, user[\"username\"], otp=get_valid_otp(mfa_url[\"mfa_url\"])\n",
    "    )\n",
    "\n",
    "    delete_test_user(base_url, test_username=user[\"username\"])\n",
    "\n",
    "    sanitized_print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c148aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [31985]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Keeping the old async specifications at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Skipping generating async documentation in '/work/airt-service/notebooks/asyncapi/docs'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_realtime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_realtime_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_start_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_start_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 32) with member_id aiokafka-0.8.0-99a2ac37-4959-4569-a321-50a7b569b891\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 32\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_training_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 33) with member_id aiokafka-0.8.0-1b6599f1-571a-47c9-bb01-3e33b479c272\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 33) with member_id aiokafka-0.8.0-99a2ac37-4959-4569-a321-50a7b569b891\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 33) with member_id aiokafka-0.8.0-ec88e252-e787-4af9-9178-132128f112a5\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'None_training_data': 1} to {'None_realtime_data': 1, 'None_start_training_data': 1, 'None_training_data': 1}. \n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 33\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 33\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 33\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_start_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "server started\n",
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:48220 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48226 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48228 - \"GET /redoc HTTP/1.1\" 200 OK\n",
      "starting integration tests\n",
      "getting /docs\n",
      "getting /redocs\n",
      "creating user\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_start_training_data created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_data created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_realitime_data created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_data_status created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_model_status created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_model_metrics created\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_prediction created\n",
      "INFO:     127.0.0.1:48234 - \"POST /user/ HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674559350.845|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674559350.845|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:48248 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48256 - \"GET /user/mfa/generate HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48260 - \"POST /user/mfa/activate HTTP/1.1\" 200 OK\n",
      "Generating mfa url\n",
      "Activate mfa\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:48274 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48280 - \"POST /apikey HTTP/1.1\" 200 OK\n",
      "creating apikey\n",
      "creating datablob\n",
      "[INFO] botocore.credentials: Found credentials in environment variables.\n",
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('0e24a4dd-ca3a-4961-a37d-f374650e84ea'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-1.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20230124/eu-west-1/s3/aws4_request', 'x-amz-date': '20230124T112232Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "INFO:     127.0.0.1:48282 - \"POST /datablob/from_local/start HTTP/1.1\" 200 OK\n",
      "downloading csv file\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_sa26le0y\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_sa26le0y\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_sa26le0y\n",
      "uploading csv file using presigned url\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_sa26le0y\n",
      "creating datasource\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='process_csv 142 81 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='process_csv 142 81 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:38780 - \"POST /datablob/0e24a4dd-ca3a-4961-a37d-f374650e84ea/to_datasource HTTP/1.1\" 202 Accepted\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'process_csv 142 81 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['process_csv', '142', '81', 'PersonId', '[\"OccurredTime\"]', '--blocksize', '256MB', '--deduplicate_data']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'process_csv 142 81 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "INFO:     127.0.0.1:38784 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:38796 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:33476 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:33478 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60466 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60472 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:37784 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:37798 - \"GET /datablob/0e24a4dd-ca3a-4961-a37d-f374650e84ea HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for datasource\n",
      "start waiting for steps to complete\n",
      "stop waiting for steps to complete\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached_g6cmtpod\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached_g6cmtpod\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached_g6cmtpod\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'process_csv 142 81 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "23-01-24 11:22:51.916 [INFO] airt.data.importers: Module loaded:\n",
      "23-01-24 11:22:51.917 [INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "23-01-24 11:22:51.917 [INFO] airt.data.importers:  - using dask       : 2022.10.0\n",
      "23-01-24 11:22:53.030 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): processing user uploaded csv file for datablob_id=142 and uploading parquet back to S3 for datasource_id=81\n",
      "23-01-24 11:22:53.089 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-24 11:22:55.423 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-1/217/datablob/142\n",
      "23-01-24 11:22:55.423 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/datablob/142\n",
      "23-01-24 11:22:55.423 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm\n",
      "23-01-24 11:22:55.424 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/datablob/142 locally in /tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm\n",
      "23-01-24 11:22:55.424 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/217/datablob/142 to /tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm\n",
      "23-01-24 11:22:59.850 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): step 2/4: running import_csv()\n",
      "23-01-24 11:22:59.850 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/datasource/81\n",
      "23-01-24 11:22:59.851 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j\n",
      "23-01-24 11:22:59.851 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/datasource/81 locally in /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j\n",
      "23-01-24 11:22:59.851 [INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm/file.csv] using blocksize='256MB' and kwargs={} and storing result in /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j\n",
      "23-01-24 11:22:59.858 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:23:01.232 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:45229' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:23:01.233 [INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "23-01-24 11:23:03.259 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:23:03.259 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:23:03.651 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:23:03.651 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:23:04.264 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:46799' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:23:04.264 [INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "23-01-24 11:23:05.797 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:23:05.797 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:23:06.124 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:23:06.124 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:23:06.954 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:36483' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:23:06.955 [INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-24 11:23:09.464 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:23:09.464 [INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "23-01-24 11:23:11.200 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:23:11.200 [INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-24 11:23:13.548 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:23:13.548 [INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j as Parquet files with:\n",
      "23-01-24 11:23:13.776 [INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('O'), 'OccurredTimeTicks': dtype('int64')}\n",
      "23-01-24 11:23:13.776 [INFO] airt.data.importers:  - npartitions=1\n",
      "23-01-24 11:23:13.776 [INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "23-01-24 11:23:13.776 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:23:14.175 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:23:14.589 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-1/217/datasource/81, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j, access_key=None, secret_key=None)\n",
      "23-01-24 11:23:14.589 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j to s3://kumaran-airt-service-eu-west-1/217/datasource/81\n",
      "23-01-24 11:23:18.727 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_k445p58j\n",
      "23-01-24 11:23:18.728 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217datablob142_cached_3p3arhzm\n",
      "23-01-24 11:23:18.731 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "23-01-24 11:23:20.354 [INFO] airt_service.data.csv: process_csv(datablob_id=142, datasource_id=81): completed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'process_csv 142 81 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'process_csv 142 81 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data' with return code 0\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached_g6cmtpod\n",
      "INFO:     127.0.0.1:37802 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527/head HTTP/1.1\" 200 OK\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached__yzhcb_j\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached__yzhcb_j\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/217/datasource/81/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached__yzhcb_j\n",
      "head of datasource\n",
      "{'data': {'index': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'columns': ['AccountId', 'DefinitionId', 'OccurredTime', 'OccurredTimeTicks'], 'data': [[312571, 'loadTests2', '2019-12-31 21:30:02', 1577836802678], [312571, 'loadTests3', '2020-01-03 23:53:22', 1578104602678], [312571, 'loadTests1', '2020-01-07 02:16:42', 1578372402678], [312571, 'loadTests2', '2020-01-10 04:40:02', 1578640202678], [312571, 'loadTests3', '2020-01-13 07:03:22', 1578908002678], [312571, 'loadTests1', '2020-01-16 09:26:42', 1579175802678], [312571, 'loadTests2', '2020-01-19 11:50:02', 1579443602678], [312571, 'loadTests3', '2020-01-22 14:13:22', 1579711402678], [312571, 'loadTests1', '2020-01-25 16:36:42', 1579979202678], [312571, 'loadTests2', '2020-01-28 19:00:02', 1580247002678]], 'index_names': ['PersonId'], 'column_names': [None]}, 'dtypes': {'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}}\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217datasource81metadata_by_airt_cached__yzhcb_j\n",
      "INFO:     127.0.0.1:37804 - \"GET /datasource/f88216ef-6ce6-4c5a-8232-c9d93201a527/dtypes HTTP/1.1\" 200 OK\n",
      "dtypes of datasource\n",
      "{'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='azure_blob_storage_pull 144', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='azure_blob_storage_pull 144', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:37820 - \"POST /datablob/from_azure_blob_storage HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'azure_blob_storage_pull 144'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['azure_blob_storage_pull', '144']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'azure_blob_storage_pull 144'\n",
      "INFO:     127.0.0.1:37824 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "creating azure datablob\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:46102 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:46108 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50568 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50572 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:35908 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'azure_blob_storage_pull 144':\n",
      "23-01-24 11:23:28.649 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:23:28.650 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:23:29.262 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:31.563 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:33.852 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:23:33.852 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:23:33.853 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/217/datablob/144\n",
      "23-01-24 11:23:33.854 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope217datablob144_cached_lwufabzd\n",
      "23-01-24 11:23:33.854 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/217/datablob/144 locally in /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope217datablob144_cached_lwufabzd\n",
      "23-01-24 11:23:33.854 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:23:33.855 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:23:33.855 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://testairtservice.blob.core.windows.net/test-container/account_312571_events\n",
      "23-01-24 11:23:33.855 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_kgzz7eua\n",
      "23-01-24 11:23:33.856 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://testairtservice.blob.core.windows.net/test-container/account_312571_events locally in /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_kgzz7eua\n",
      "23-01-24 11:23:33.856 [INFO] airt.remote_path: AzureBlobPath.__enter__(): pulling data from https://testairtservice.blob.core.windows.net/test-container/account_312571_events to /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_kgzz7eua\n",
      "23-01-24 11:23:39.122 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_kgzz7eua\n",
      "23-01-24 11:23:39.123 [INFO] airt.remote_path: AzureBlobPath.__exit__(): pushing data from /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope217datablob144_cached_lwufabzd to https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/217/datablob/144\n",
      "23-01-24 11:23:39.753 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:40.697 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:42.627 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:47.969 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope217datablob144_cached_lwufabzd\n",
      "23-01-24 11:23:47.972 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:23:47.972 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:23:48.594 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:50.845 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:23:52.586 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:23:52.587 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:23:53.203 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'azure_blob_storage_pull 144':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'azure_blob_storage_pull 144' with return code 0\n",
      "INFO:     127.0.0.1:35918 - \"GET /datablob/538577fb-3c0f-4c77-a7e5-acf59e4742c1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:35928 - \"POST /model/train HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:35934 - \"GET /model/f1315ceb-c7e2-4395-967a-61f7b88b812b HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for azure datablob\n",
      "training model\n",
      "start waiting for steps to complete\n",
      "stop waiting for steps to complete\n",
      "model training completed\n",
      "INFO:     127.0.0.1:35942 - \"GET /model/f1315ceb-c7e2-4395-967a-61f7b88b812b/evaluate HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='predict 34', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='predict 34', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:35958 - \"POST /model/f1315ceb-c7e2-4395-967a-61f7b88b812b/predict HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'predict 34'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['predict', '34']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'predict 34'\n",
      "INFO:     127.0.0.1:35960 - \"GET /prediction/83dfead0-26e4-42ea-ad0a-92020b532927 HTTP/1.1\" 200 OK\n",
      "model evaluation\n",
      "{'accuracy': 0.985, 'recall': 0.962, 'precision': 0.934}\n",
      "running prediction\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:39218 - \"GET /prediction/83dfead0-26e4-42ea-ad0a-92020b532927 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39230 - \"GET /prediction/83dfead0-26e4-42ea-ad0a-92020b532927 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54654 - \"GET /prediction/83dfead0-26e4-42ea-ad0a-92020b532927/pandas HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "prediction completed\n",
      "prediction as pandas\n",
      "{'user_id': [520088904, 530496790, 561587266, 518085591, 558856683, 520772685, 514028527, 518574284, 532364121, 532647354], 'Score': [0.979853, 0.979157, 0.979055, 0.978915, 0.97796, 0.004043, 0.00389, 0.001346, 0.001341, 0.001139]}\n",
      "Resetting password for: rtpqucqszz\n",
      "INFO:     127.0.0.1:54666 - \"POST /user/reset_password HTTP/1.1\" 200 OK\n",
      "\"Password reset successful\"\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:54682 - \"POST /token HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'predict 34':\n",
      "23-01-24 11:24:00.080 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-24 11:24:01.065 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/prediction/34\n",
      "23-01-24 11:24:01.066 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217prediction34_cached_vti26yxd\n",
      "23-01-24 11:24:01.066 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/prediction/34 locally in /tmp/s3kumaran-airt-service-eu-west-1217prediction34_cached_vti26yxd\n",
      "23-01-24 11:24:01.066 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/217/datasource/81\n",
      "23-01-24 11:24:01.067 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_8phmtej_\n",
      "23-01-24 11:24:01.067 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/217/datasource/81 locally in /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_8phmtej_\n",
      "23-01-24 11:24:01.067 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/217/datasource/81 to /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_8phmtej_\n",
      "23-01-24 11:24:03.967 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217datasource81_cached_8phmtej_\n",
      "23-01-24 11:24:03.967 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1217prediction34_cached_vti26yxd to s3://kumaran-airt-service-eu-west-1/217/prediction/34\n",
      "23-01-24 11:24:07.438 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1217prediction34_cached_vti26yxd\n",
      "\n",
      "[INFO] airt_service.background_task: Background task stderr for command: 'predict 34':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'predict 34' with return code 0\n",
      "INFO:     127.0.0.1:54692 - \"GET /user/details?user_id_or_name=None HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54694 - \"DELETE /user/mfa/1632c348-569a-427a-bd6d-24768c5d3e6c/disable?otp=336807 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.cleanup: deleting predictions\n",
      "{\"username\":\"rtpqucqszz\",\"first_name\":\"integration\",\"last_name\":\"user\",\"email\":\"rtpqucqszz@email.com\",\"subscription_type\":\"small\",\"super_user\":false,\"phone_number\":null,\"uuid\":\"1632c348-569a-427a-bd6d-24768c5d3e6c\",\"disabled\":false,\"created\":\"2023-01-24T11:22:31\",\"is_phone_number_verified\":false,\"is_mfa_active\":false}\n",
      "Deactivate mfa\n",
      "deleting test user\n",
      "[INFO] airt_service.cleanup: deleting models\n",
      "[INFO] airt_service.cleanup: deleting datasources\n",
      "[INFO] airt_service.cleanup: deleting datablobs\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.cleanup: deleting apikeys\n",
      "[INFO] airt_service.cleanup: Deleting user files in s3://kumaran-airt-service-eu-west-1/217\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_start_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_realitime_data deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_data_status deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_training_model_status deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_model_metrics deleted\n",
      "[INFO] airt_service.confluent: Topic rtpqucqszz_prediction deleted\n",
      "[INFO] airt_service.cleanup: deleting user\n",
      "INFO:     127.0.0.1:54700 - \"POST /user/cleanup HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "%4|1674559463.255|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674559463.255|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [31985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "# from https://github.com/encode/uvicorn/issues/742\n",
    "\n",
    "\n",
    "def test_integration_tests():\n",
    "    # Start integration tests\n",
    "    token = test_auth(\n",
    "        \"http://0.0.0.0:6006\",\n",
    "        username=\"kumaran\",\n",
    "        password=os.environ[\"AIRT_SERVICE_SUPER_USER_PASSWORD\"],\n",
    "    )\n",
    "    with set_env_variable_context(variable=\"AIRT_SERVICE_TOKEN\", value=token):\n",
    "        integration_tests()\n",
    "\n",
    "\n",
    "# with posix_ipc.Semaphore(\n",
    "#     \"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT, initial_value=1\n",
    "# ) as sem:\n",
    "# sem = posix_ipc.Semaphore(\"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT)\n",
    "# sem.acquire(timeout=10 * 60)\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    app, fast_kafka_api_app = create_ws_server(\n",
    "        assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "    )\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=6006, log_level=\"info\")\n",
    "\n",
    "    with run_uvicorn(config):\n",
    "        time.sleep(30)\n",
    "        # Server started.\n",
    "        sanitized_print(\"server started\")\n",
    "\n",
    "        test_integration_tests()\n",
    "\n",
    "    sanitized_print(\"server stopped\")\n",
    "    # Server stopped.\n",
    "# sem.release()\n",
    "# sem.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def run_integration_tests(\n",
    "    host: Param(\"hostname\", str),  # type: ignore\n",
    "    port: Param(\"port\", int),  # type: ignore\n",
    "    protocol: Param(\"http or https\", str) = \"https\",  # type: ignore\n",
    "):\n",
    "    \"\"\"Run integration tests against given host and port\n",
    "\n",
    "    Args:\n",
    "        host: Hostname of the webserver to run tests against\n",
    "        port: Port of the webserver\n",
    "        protocol: Protocol to use for testing\n",
    "    \"\"\"\n",
    "    base_url = f\"{protocol}://{host}:{port}\"\n",
    "    integration_tests(base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0087f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [34283]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Keeping the old async specifications at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Skipping generating async documentation in '/work/airt-service/notebooks/asyncapi/docs'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_realtime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_realtime_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_start_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_start_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 35) with member_id aiokafka-0.8.0-6f644358-b6ff-4790-a1c6-c17a443f634a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-73f6fd20-1648-4eab-ad47-8c9ca29f9343\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-7516535f-b149-4464-871f-80042ce6e2b7\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-6f644358-b6ff-4790-a1c6-c17a443f634a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'None_realtime_data': 1} to {'None_realtime_data': 1, 'None_start_training_data': 1, 'None_training_data': 1}. \n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_start_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:52882 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52896 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52908 - \"GET /redoc HTTP/1.1\" 200 OK\n",
      "starting integration tests\n",
      "getting /docs\n",
      "getting /redocs\n",
      "creating user\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_start_training_data created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_data created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_realitime_data created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_data_status created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_model_status created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_model_metrics created\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_prediction created\n",
      "INFO:     127.0.0.1:52912 - \"POST /user/ HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674559479.590|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674559479.590|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:52920 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52926 - \"GET /user/mfa/generate HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52930 - \"POST /user/mfa/activate HTTP/1.1\" 200 OK\n",
      "Generating mfa url\n",
      "Activate mfa\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:52934 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52942 - \"POST /apikey HTTP/1.1\" 200 OK\n",
      "[INFO] botocore.credentials: Found credentials in environment variables.\n",
      "creating apikey\n",
      "creating datablob\n",
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('30f97e61-443f-42ca-8839-3addd056b650'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-1.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20230124/eu-west-1/s3/aws4_request', 'x-amz-date': '20230124T112441Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "INFO:     127.0.0.1:52958 - \"POST /datablob/from_local/start HTTP/1.1\" 200 OK\n",
      "downloading csv file\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_wpvb2mz1\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_wpvb2mz1\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_wpvb2mz1\n",
      "uploading csv file using presigned url\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_wpvb2mz1\n",
      "creating datasource\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='process_csv 146 84 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='process_csv 146 84 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:54322 - \"POST /datablob/30f97e61-443f-42ca-8839-3addd056b650/to_datasource HTTP/1.1\" 202 Accepted\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'process_csv 146 84 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['process_csv', '146', '84', 'PersonId', '[\"OccurredTime\"]', '--blocksize', '256MB', '--deduplicate_data']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'process_csv 146 84 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "INFO:     127.0.0.1:38382 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:38394 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_start_training_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_training_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_realtime_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 37) with member_id aiokafka-0.8.0-73f6fd20-1648-4eab-ad47-8c9ca29f9343\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 37) with member_id aiokafka-0.8.0-7516535f-b149-4464-871f-80042ce6e2b7\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 37) with member_id aiokafka-0.8.0-6f644358-b6ff-4790-a1c6-c17a443f634a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 37\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 37\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 37\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_start_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "INFO:     127.0.0.1:47174 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:47182 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52980 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52988 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'process_csv 146 84 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "23-01-24 11:25:00.750 [INFO] airt.data.importers: Module loaded:\n",
      "23-01-24 11:25:00.750 [INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "23-01-24 11:25:00.750 [INFO] airt.data.importers:  - using dask       : 2022.10.0\n",
      "23-01-24 11:25:01.794 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): processing user uploaded csv file for datablob_id=146 and uploading parquet back to S3 for datasource_id=84\n",
      "23-01-24 11:25:01.852 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-24 11:25:04.118 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-1/222/datablob/146\n",
      "23-01-24 11:25:04.118 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/datablob/146\n",
      "23-01-24 11:25:04.119 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug\n",
      "23-01-24 11:25:04.119 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/datablob/146 locally in /tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug\n",
      "23-01-24 11:25:04.119 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/222/datablob/146 to /tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug\n",
      "23-01-24 11:25:07.735 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): step 2/4: running import_csv()\n",
      "23-01-24 11:25:07.735 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/datasource/84\n",
      "23-01-24 11:25:07.735 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm\n",
      "23-01-24 11:25:07.735 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/datasource/84 locally in /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm\n",
      "23-01-24 11:25:07.735 [INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug/file.csv] using blocksize='256MB' and kwargs={} and storing result in /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm\n",
      "23-01-24 11:25:07.741 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:25:08.777 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:42167' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:25:08.777 [INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "23-01-24 11:25:10.169 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:25:10.169 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:25:10.574 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:25:10.575 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:25:11.525 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:41959' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:25:11.525 [INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "23-01-24 11:25:12.976 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:25:12.976 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:25:13.214 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:25:13.214 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-24 11:25:14.095 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:42025' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-24 11:25:14.095 [INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-24 11:25:16.617 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:25:16.617 [INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "23-01-24 11:25:18.425 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:25:18.425 [INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-24 11:25:20.322 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-24 11:25:20.322 [INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm as Parquet files with:\n",
      "23-01-24 11:25:20.525 [INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('O'), 'OccurredTimeTicks': dtype('int64')}\n",
      "23-01-24 11:25:20.526 [INFO] airt.data.importers:  - npartitions=1\n",
      "23-01-24 11:25:20.526 [INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "23-01-24 11:25:20.526 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-24 11:25:21.007 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-24 11:25:21.359 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-1/222/datasource/84, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm, access_key=None, secret_key=None)\n",
      "23-01-24 11:25:21.359 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm to s3://kumaran-airt-service-eu-west-1/222/datasource/84\n",
      "23-01-24 11:25:26.093 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_k45yyttm\n",
      "23-01-24 11:25:26.094 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222datablob146_cached__51k2iug\n",
      "23-01-24 11:25:26.098 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "23-01-24 11:25:27.796 [INFO] airt_service.data.csv: process_csv(datablob_id=146, datasource_id=84): completed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'process_csv 146 84 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'process_csv 146 84 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data' with return code 0\n",
      "INFO:     127.0.0.1:47496 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:47510 - \"GET /datablob/30f97e61-443f-42ca-8839-3addd056b650 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for datasource\n",
      "start waiting for steps to complete\n",
      "stop waiting for steps to complete\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_2_4tfegw\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_2_4tfegw\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_2_4tfegw\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_2_4tfegw\n",
      "INFO:     127.0.0.1:47512 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076/head HTTP/1.1\" 200 OK\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_1_ce3e9_\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_1_ce3e9_\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/222/datasource/84/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_1_ce3e9_\n",
      "head of datasource\n",
      "{'data': {'index': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'columns': ['AccountId', 'DefinitionId', 'OccurredTime', 'OccurredTimeTicks'], 'data': [[312571, 'loadTests2', '2019-12-31 21:30:02', 1577836802678], [312571, 'loadTests3', '2020-01-03 23:53:22', 1578104602678], [312571, 'loadTests1', '2020-01-07 02:16:42', 1578372402678], [312571, 'loadTests2', '2020-01-10 04:40:02', 1578640202678], [312571, 'loadTests3', '2020-01-13 07:03:22', 1578908002678], [312571, 'loadTests1', '2020-01-16 09:26:42', 1579175802678], [312571, 'loadTests2', '2020-01-19 11:50:02', 1579443602678], [312571, 'loadTests3', '2020-01-22 14:13:22', 1579711402678], [312571, 'loadTests1', '2020-01-25 16:36:42', 1579979202678], [312571, 'loadTests2', '2020-01-28 19:00:02', 1580247002678]], 'index_names': ['PersonId'], 'column_names': [None]}, 'dtypes': {'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}}\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222datasource84metadata_by_airt_cached_1_ce3e9_\n",
      "INFO:     127.0.0.1:47528 - \"GET /datasource/f0d543c5-97df-4629-a468-ec9876979076/dtypes HTTP/1.1\" 200 OK\n",
      "dtypes of datasource\n",
      "{'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='azure_blob_storage_pull 147', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='azure_blob_storage_pull 147', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:47530 - \"POST /datablob/from_azure_blob_storage HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'azure_blob_storage_pull 147'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['azure_blob_storage_pull', '147']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'azure_blob_storage_pull 147'\n",
      "INFO:     127.0.0.1:47534 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "creating azure datablob\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:54156 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_start_training_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_training_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_realtime_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 38) with member_id aiokafka-0.8.0-73f6fd20-1648-4eab-ad47-8c9ca29f9343\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 38) with member_id aiokafka-0.8.0-7516535f-b149-4464-871f-80042ce6e2b7\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 38) with member_id aiokafka-0.8.0-6f644358-b6ff-4790-a1c6-c17a443f634a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 38\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 38\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_start_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "INFO:     127.0.0.1:54158 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:33942 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:33948 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54500 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'azure_blob_storage_pull 147':\n",
      "23-01-24 11:25:37.809 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:25:37.810 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:25:38.445 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:41.462 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:43.728 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:25:43.728 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:25:43.729 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/222/datablob/147\n",
      "23-01-24 11:25:43.730 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope222datablob147_cached_1v04qrob\n",
      "23-01-24 11:25:43.730 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/222/datablob/147 locally in /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope222datablob147_cached_1v04qrob\n",
      "23-01-24 11:25:43.731 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:25:43.731 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:25:43.732 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://testairtservice.blob.core.windows.net/test-container/account_312571_events\n",
      "23-01-24 11:25:43.732 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_rjf8iyc8\n",
      "23-01-24 11:25:43.732 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://testairtservice.blob.core.windows.net/test-container/account_312571_events locally in /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_rjf8iyc8\n",
      "23-01-24 11:25:43.733 [INFO] airt.remote_path: AzureBlobPath.__enter__(): pulling data from https://testairtservice.blob.core.windows.net/test-container/account_312571_events to /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_rjf8iyc8\n",
      "23-01-24 11:25:48.461 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_rjf8iyc8\n",
      "23-01-24 11:25:48.462 [INFO] airt.remote_path: AzureBlobPath.__exit__(): pushing data from /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope222datablob147_cached_1v04qrob to https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/222/datablob/147\n",
      "23-01-24 11:25:48.991 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:49.954 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:51.762 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:55.926 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope222datablob147_cached_1v04qrob\n",
      "23-01-24 11:25:55.928 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:25:55.928 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:25:56.441 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:57.196 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-24 11:25:59.444 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-24 11:25:59.444 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-24 11:25:59.981 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "\n",
      "[INFO] airt_service.background_task: Background task stderr for command: 'azure_blob_storage_pull 147':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'azure_blob_storage_pull 147' with return code 0\n",
      "INFO:     127.0.0.1:54504 - \"GET /datablob/211040d7-0e32-451e-ac6e-8cfb517cd293 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54510 - \"POST /model/train HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54526 - \"GET /model/2051911e-91d5-4a7b-bbdf-7adc46cf3f11 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for azure datablob\n",
      "training model\n",
      "start waiting for steps to complete\n",
      "stop waiting for steps to complete\n",
      "model training completed\n",
      "INFO:     127.0.0.1:54528 - \"GET /model/2051911e-91d5-4a7b-bbdf-7adc46cf3f11/evaluate HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='predict 37', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='predict 37', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:54532 - \"POST /model/2051911e-91d5-4a7b-bbdf-7adc46cf3f11/predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task starting for command: 'predict 37'\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['predict', '37']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'predict 37'\n",
      "INFO:     127.0.0.1:54544 - \"GET /prediction/5cd85237-32bc-4d17-aa53-b7e770c587f9 HTTP/1.1\" 200 OK\n",
      "model evaluation\n",
      "{'accuracy': 0.985, 'recall': 0.962, 'precision': 0.934}\n",
      "running prediction\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:59528 - \"GET /prediction/5cd85237-32bc-4d17-aa53-b7e770c587f9 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59530 - \"GET /prediction/5cd85237-32bc-4d17-aa53-b7e770c587f9 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'predict 37':\n",
      "23-01-24 11:26:09.251 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-24 11:26:10.420 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/prediction/37\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222prediction37_cached_3ysm2758\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/prediction/37 locally in /tmp/s3kumaran-airt-service-eu-west-1222prediction37_cached_3ysm2758\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/222/datasource/84\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_php2asgn\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/222/datasource/84 locally in /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_php2asgn\n",
      "23-01-24 11:26:10.421 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/222/datasource/84 to /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_php2asgn\n",
      "23-01-24 11:26:13.882 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222datasource84_cached_php2asgn\n",
      "23-01-24 11:26:13.883 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1222prediction37_cached_3ysm2758 to s3://kumaran-airt-service-eu-west-1/222/prediction/37\n",
      "23-01-24 11:26:20.299 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1222prediction37_cached_3ysm2758\n",
      "\n",
      "[INFO] airt_service.background_task: Background task stderr for command: 'predict 37':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'predict 37' with return code 0\n",
      "INFO:     127.0.0.1:45828 - \"GET /prediction/5cd85237-32bc-4d17-aa53-b7e770c587f9 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:45832 - \"GET /prediction/5cd85237-32bc-4d17-aa53-b7e770c587f9/pandas HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "prediction completed\n",
      "prediction as pandas\n",
      "{'user_id': [520088904, 530496790, 561587266, 518085591, 558856683, 520772685, 514028527, 518574284, 532364121, 532647354], 'Score': [0.979853, 0.979157, 0.979055, 0.978915, 0.97796, 0.004043, 0.00389, 0.001346, 0.001341, 0.001139]}\n",
      "Resetting password for: mupiibnhcu\n",
      "INFO:     127.0.0.1:45834 - \"POST /user/reset_password HTTP/1.1\" 200 OK\n",
      "\"Password reset successful\"\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:45836 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:45850 - \"GET /user/details?user_id_or_name=None HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:45860 - \"DELETE /user/mfa/358ad23b-f39b-4be0-ac8b-8fc896d31b29/disable?otp=013688 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.cleanup: deleting predictions\n",
      "{\"username\":\"mupiibnhcu\",\"first_name\":\"integration\",\"last_name\":\"user\",\"email\":\"mupiibnhcu@email.com\",\"subscription_type\":\"small\",\"super_user\":false,\"phone_number\":null,\"uuid\":\"358ad23b-f39b-4be0-ac8b-8fc896d31b29\",\"disabled\":false,\"created\":\"2023-01-24T11:24:40\",\"is_phone_number_verified\":false,\"is_mfa_active\":false}\n",
      "Deactivate mfa\n",
      "deleting test user\n",
      "[INFO] airt_service.cleanup: deleting models\n",
      "[INFO] airt_service.cleanup: deleting datasources\n",
      "[INFO] airt_service.cleanup: deleting datablobs\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.cleanup: deleting apikeys\n",
      "[INFO] airt_service.cleanup: Deleting user files in s3://kumaran-airt-service-eu-west-1/222\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_start_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_realitime_data deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_data_status deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_training_model_status deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_model_metrics deleted\n",
      "[INFO] airt_service.confluent: Topic mupiibnhcu_prediction deleted\n",
      "[INFO] airt_service.cleanup: deleting user\n",
      "INFO:     127.0.0.1:45872 - \"POST /user/cleanup HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "%4|1674559596.339|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674559596.339|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [34283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "def test_run_integration_tests(host, port, protocol):\n",
    "    # Start integration tests\n",
    "    token = test_auth(\n",
    "        f\"{protocol}://{host}:{port}\",\n",
    "        username=\"kumaran\",\n",
    "        password=os.environ[\"AIRT_SERVICE_SUPER_USER_PASSWORD\"],\n",
    "    )\n",
    "    with set_env_variable_context(variable=\"AIRT_SERVICE_TOKEN\", value=token):\n",
    "        run_integration_tests(host, port, protocol)\n",
    "\n",
    "\n",
    "# with posix_ipc.Semaphore(\n",
    "#     \"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT, initial_value=1\n",
    "# ) as sem:\n",
    "# sem = posix_ipc.Semaphore(\"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT)\n",
    "# sem.acquire(timeout=10 * 60)\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    app, fast_kafka_api_app = create_ws_server(\n",
    "        assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "    )\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=6006, log_level=\"info\")\n",
    "\n",
    "    with run_uvicorn(config):\n",
    "        time.sleep(30)\n",
    "        test_run_integration_tests(\"0.0.0.0\", port=6006, protocol=\"http\")\n",
    "\n",
    "    sanitized_print(\"server stopped\")\n",
    "# sem.release()\n",
    "# sem.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2086b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
