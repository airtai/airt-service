{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e77c2854",
   "metadata": {},
   "source": [
    "---\n",
    "description: Runs the server and then multiple integration scenarious agains it\n",
    "output-file: integration_test.html\n",
    "title: Integration test\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp integraion_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 10:13:28.388550: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "[WARNING] airt.testing.activate_by_import: Failed to set gpu memory limit for tf; This could happen because of no gpu availability\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af70c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import *\n",
    "\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import pyotp\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "from fastcore.script import call_parse, Param\n",
    "from sqlmodel import select\n",
    "\n",
    "from airt_service.sanitizer import sanitized_print\n",
    "from airt_service.aws.utils import upload_to_s3_with_retry\n",
    "from airt.remote_path import RemotePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df37bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import pytest\n",
    "import threading\n",
    "import uvicorn\n",
    "from pathlib import Path\n",
    "import posix_ipc\n",
    "\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.server import create_ws_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def integration_scenario_docs(base_url: str = \"http://127.0.0.1:6006\"):\n",
    "    \"\"\"Test fastapi docs\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"getting /docs\")\n",
    "    r = httpx.get(f\"{base_url}/docs\")\n",
    "    assert not r.is_error, r  # nosec B101\n",
    "\n",
    "    sanitized_print(\"getting /redocs\")\n",
    "    r = httpx.get(f\"{base_url}/redoc\")\n",
    "    assert not r.is_error, r  # nosec B101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_auth(base_url: str, username: str, password: str) -> str:\n",
    "    \"\"\"Get jwt token for given credentials\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        username: Username\n",
    "        password: Password\n",
    "    Returns:\n",
    "        The jwt token for the given username and password\n",
    "    \"\"\"\n",
    "    # Authenticate\n",
    "    sanitized_print(\"authenticating and getting token\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/token\",\n",
    "        data=dict(username=username, password=password),\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    token = r.json()[\"access_token\"]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec41e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_create_user(base_url: str) -> Tuple[Dict[str, Any], str]:\n",
    "    \"\"\"Create a new user for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    Returns:\n",
    "        The user dictionary and its password as a tuple\n",
    "    \"\"\"\n",
    "    # Get token for super user\n",
    "    token = os.environ[\"AIRT_SERVICE_TOKEN\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    sanitized_print(\"creating user\")\n",
    "    username = \"\".join(  # nosec\n",
    "        random.choice(string.ascii_lowercase) for _ in range(10)\n",
    "    )\n",
    "    password = \"\".join(  # nosec\n",
    "        random.choice(string.ascii_lowercase) for _ in range(10)\n",
    "    )\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/\",\n",
    "        json=dict(\n",
    "            username=username,\n",
    "            first_name=\"integration\",\n",
    "            last_name=\"user\",\n",
    "            email=f\"{username}@email.com\",\n",
    "            subscription_type=\"small\",\n",
    "            super_user=False,\n",
    "            password=password,\n",
    "            otp=None,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=30,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    user = r.json()\n",
    "    return user, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb03799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_apikey(\n",
    "    base_url: str, headers: Dict[str, str], otp: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Create apikey for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        otp: Dynamically generated six-digit verification code from the authenticator app\n",
    "    Returns:\n",
    "        The apikey jwt token\n",
    "    \"\"\"\n",
    "    sanitized_print(\"creating apikey\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/apikey\",\n",
    "        json=dict(\n",
    "            expiry=(datetime.utcnow() + timedelta(minutes=60)).isoformat(), otp=otp\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    apikey = r.json()[\"access_token\"]\n",
    "    return apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca364f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def check_steps_completed(url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Check whether completed steps equals to total steps\n",
    "\n",
    "    Args:\n",
    "        url: Url to call\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        The dictionary returned by url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"start waiting for steps to complete\")\n",
    "    while True:\n",
    "        r = httpx.get(url, headers=headers)\n",
    "        assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "        obj = r.json()\n",
    "        if obj[\"completed_steps\"] == obj[\"total_steps\"]:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "    sanitized_print(\"stop waiting for steps to complete\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71850726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_csv_local_datablob_and_datasource(\n",
    "    base_url: str, headers: Dict[str, str]\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"Create datablob from local, upload csv files and create datasource from it\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        Datablob and datasource dictionaries as a tuple\n",
    "    \"\"\"\n",
    "    # Create csv datablob\n",
    "    sanitized_print(\"creating datablob\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/from_local/start\",\n",
    "        json=dict(path=\"tmp/test-folder/\"),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datablob_uuid = r.json()[\"uuid\"]\n",
    "    presigned = r.json()[\"presigned\"]\n",
    "\n",
    "    sanitized_print(\"downloading csv file\")\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        df = pd.read_parquet(test_s3_path.as_path())\n",
    "        df.to_csv(test_s3_path.as_path() / \"file.csv\", index=False)\n",
    "\n",
    "        sanitized_print(\"uploading csv file using presigned url\")\n",
    "        upload_to_s3_with_retry(\n",
    "            test_s3_path.as_path() / \"file.csv\", presigned[\"url\"], presigned[\"fields\"]\n",
    "        )\n",
    "\n",
    "    # Create datasource from csv datablob\n",
    "    sanitized_print(\"creating datasource\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/{datablob_uuid}/to_datasource\",\n",
    "        json=dict(\n",
    "            file_type=\"csv\",\n",
    "            deduplicate_data=True,\n",
    "            index_column=\"PersonId\",\n",
    "            sort_by=\"OccurredTime\",\n",
    "            blocksize=\"256MB\",\n",
    "            kwargs_json=dict(\n",
    "                usecols=[0, 1, 2, 3, 4],\n",
    "                parse_dates=[\"OccurredTime\"],\n",
    "            ),\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datasource = r.json()\n",
    "\n",
    "    # Wait for pull to complete\n",
    "    datasource = check_steps_completed(\n",
    "        url=f\"{base_url}/datasource/{datasource['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"pull completed for datasource\")\n",
    "\n",
    "    # Get datablob object to return\n",
    "    datablob = check_steps_completed(\n",
    "        url=f\"{base_url}/datablob/{datablob_uuid}\", headers=headers\n",
    "    )\n",
    "\n",
    "    # Display head and dtypes\n",
    "    r = httpx.get(f\"{base_url}/datasource/{datasource['uuid']}/head\", headers=headers)\n",
    "    sanitized_print(\"head of datasource\")\n",
    "    sanitized_print(r.json())\n",
    "    r = httpx.get(f\"{base_url}/datasource/{datasource['uuid']}/dtypes\", headers=headers)\n",
    "    sanitized_print(\"dtypes of datasource\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return datablob, datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe92e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_azure_datablob(base_url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Create datablob using from_azure route\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "    Returns:\n",
    "        A azure datablob\n",
    "    \"\"\"\n",
    "    storage_client = StorageManagementClient(\n",
    "        DefaultAzureCredential(), os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "    )\n",
    "    keys = storage_client.storage_accounts.list_keys(\n",
    "        \"test-airt-service\", \"testairtservice\"\n",
    "    )\n",
    "    credential = keys.keys[0].value\n",
    "\n",
    "    # Create azure datablob\n",
    "    sanitized_print(\"creating azure datablob\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/datablob/from_azure_blob_storage\",\n",
    "        json=dict(\n",
    "            uri=\"https://testairtservice.blob.core.windows.net/test-container/account_312571_events\",\n",
    "            credential=credential,\n",
    "            cloud_provider=\"azure\",\n",
    "            region=\"westeurope\",\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    datablob = r.json()\n",
    "\n",
    "    # Wait for pull to complete\n",
    "    datablob = check_steps_completed(\n",
    "        url=f\"{base_url}/datablob/{datablob['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"pull completed for azure datablob\")\n",
    "\n",
    "    return datablob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_model(\n",
    "    base_url: str, headers: Dict[str, str], datasource: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Train model and evaluate it for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        datasource: Datasource dictionary\n",
    "    Returns:\n",
    "        The model dictionary\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    sanitized_print(\"training model\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/model/train\",\n",
    "        json=dict(\n",
    "            data_uuid=datasource[\"uuid\"],\n",
    "            client_column=\"AccountId\",\n",
    "            target_column=\"DefinitionId\",\n",
    "            target=\"load*\",\n",
    "            predict_after=20 * 24 * 60 * 60,\n",
    "        ),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    model = r.json()\n",
    "\n",
    "    # Wait for model training to complete\n",
    "    model = check_steps_completed(\n",
    "        url=f\"{base_url}/model/{model['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"model training completed\")\n",
    "\n",
    "    # Evaluate model\n",
    "    r = httpx.get(f\"{base_url}/model/{model['uuid']}/evaluate\", headers=headers)\n",
    "    assert not r.is_error  # nosec B101\n",
    "    sanitized_print(\"model evaluation\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8148cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_prediction(\n",
    "    base_url: str, headers: Dict[str, str], model: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run prediction and evaluate prediction for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "        model: Model dictionary\n",
    "    Returns:\n",
    "        The prediction dictionary\n",
    "    \"\"\"\n",
    "    # Run prediction for the model\n",
    "    sanitized_print(\"running prediction\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/model/{model['uuid']}/predict\",\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    prediction = r.json()\n",
    "\n",
    "    # Wait for prediction to complete\n",
    "    prediction = check_steps_completed(\n",
    "        url=f\"{base_url}/prediction/{prediction['uuid']}\", headers=headers\n",
    "    )\n",
    "    sanitized_print(\"prediction completed\")\n",
    "\n",
    "    # Get prediction as pandas\n",
    "    r = httpx.get(f\"{base_url}/prediction/{prediction['uuid']}/pandas\", headers=headers)\n",
    "    assert not r.is_error  # nosec B101\n",
    "    sanitized_print(\"prediction as pandas\")\n",
    "    sanitized_print(r.json())\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44313d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_generate_mfa_url(base_url: str, headers: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate mfa provisioning uri\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        headers: Headers dict with authorization header\n",
    "\n",
    "    Returns:\n",
    "        The provisioning uri generated from the secret\n",
    "    \"\"\"\n",
    "\n",
    "    r = httpx.get(f\"{base_url}/user/mfa/generate\", headers=headers)\n",
    "    assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "    sanitized_print(\"Generating mfa url\")\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_valid_otp(mfa_url: str) -> str:\n",
    "    \"\"\"Get valid otp for the mfa_url\n",
    "\n",
    "    Args:\n",
    "        mfa_url: mfa provisioning url\n",
    "\n",
    "    Returns:\n",
    "        The valid otp for the url\n",
    "    \"\"\"\n",
    "    return pyotp.TOTP(pyotp.parse_uri(mfa_url).secret).now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d158090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_activate_mfa(\n",
    "    base_url: str, mfa_url: str, headers: Dict[str, str]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Activate mfa\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        mfa_url: mfa provisioning url\n",
    "        headers: Headers dict with authorization header\n",
    "\n",
    "    Returns:\n",
    "        The provisioning uri generated from the secret\n",
    "    \"\"\"\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/mfa/activate\",\n",
    "        json=dict(user_otp=get_valid_otp(mfa_url)),\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, f\"{r.text=} {r.status_code=}\"  # nosec B101\n",
    "    sanitized_print(\"Activate mfa\")\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df232845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def reset_test_user_password(\n",
    "    base_url: str, headers: Dict[str, str], username: str, password: str, otp: str\n",
    "):\n",
    "    \"\"\"Reset the test user password\"\"\"\n",
    "    sanitized_print(f\"Resetting password for: {username}\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/reset_password\",\n",
    "        json=dict(username=username, new_password=password, otp=otp),\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    sanitized_print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_disable_mfa(\n",
    "    base_url: str, headers: Dict[str, str], username: str, otp: Optional[str] = None\n",
    "):\n",
    "    \"\"\"Disable MFA for the user\"\"\"\n",
    "    current_active_user = httpx.get(\n",
    "        f\"{base_url}/user/details?user_id_or_name=None\", headers=headers\n",
    "    )\n",
    "    current_active_user_uuid = current_active_user.json()[\"uuid\"]\n",
    "    r = httpx.delete(\n",
    "        f\"{base_url}/user/mfa/{current_active_user_uuid}/disable?otp={otp}\",\n",
    "        headers=headers,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    sanitized_print(r.text)\n",
    "    assert username in r.text  # nosec B101\n",
    "    sanitized_print(\"Deactivate mfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77152a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def test_auth_with_otp(\n",
    "    base_url: str, username: str, password: str, mfa_url: str, retry_limit: int = 3\n",
    ") -> str:\n",
    "    \"\"\"Get jwt token for given credentials and otp\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        username: Username\n",
    "        password: Password\n",
    "        mfa_url: MFA URL\n",
    "        retry_limit: Retry limit if there is an error with otp auth\n",
    "    Returns:\n",
    "        The jwt token for the given username and password\n",
    "    \"\"\"\n",
    "    # Authenticate\n",
    "    sanitized_print(\"authenticating with otp and getting token\")\n",
    "    for i in range(retry_limit):\n",
    "        otp = get_valid_otp(mfa_url)\n",
    "        r = httpx.post(\n",
    "            f\"{base_url}/token\",\n",
    "            data=dict(\n",
    "                username=username,\n",
    "                password=json.dumps(\n",
    "                    {\n",
    "                        \"password\": password,\n",
    "                        \"user_otp\": otp,\n",
    "                    }\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if not r.is_error:\n",
    "            break\n",
    "\n",
    "    assert not r.is_error, r.text  # nosec B101\n",
    "    token = r.json()[\"access_token\"]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8624d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def delete_test_user(base_url: str, test_username: str):\n",
    "    \"\"\"Delete the test user created for testing\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "        test_username: Username to delete\n",
    "    \"\"\"\n",
    "    # Get token for super user\n",
    "    token = os.environ[\"AIRT_SERVICE_TOKEN\"]\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    sanitized_print(\"deleting test user\")\n",
    "    r = httpx.post(\n",
    "        f\"{base_url}/user/cleanup\",\n",
    "        json=dict(\n",
    "            username=test_username,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=None,\n",
    "    )\n",
    "    assert not r.is_error, r.text  # nosec B101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def integration_tests(base_url: str = \"http://127.0.0.1:6006\"):\n",
    "    \"\"\"Integration tests\n",
    "\n",
    "    Args:\n",
    "        base_url: Base url\n",
    "    \"\"\"\n",
    "    sanitized_print(\"starting integration tests\")\n",
    "    integration_scenario_docs(base_url)\n",
    "\n",
    "    user, password = test_create_user(base_url)\n",
    "\n",
    "    token = test_auth(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=password,\n",
    "    )\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    # enable mfa for the user\n",
    "    mfa_url = test_generate_mfa_url(base_url, headers)\n",
    "    # activate mfa\n",
    "    test_activate_mfa(base_url, mfa_url[\"mfa_url\"], headers)\n",
    "\n",
    "    # Get token by passing password and otp as json encoded dict\n",
    "    token = test_auth_with_otp(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=password,\n",
    "        mfa_url=mfa_url[\"mfa_url\"],\n",
    "        retry_limit=3,\n",
    "    )\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    apikey = test_apikey(base_url, headers, otp=get_valid_otp(mfa_url[\"mfa_url\"]))\n",
    "    headers = {\"Authorization\": f\"Bearer {apikey}\"}\n",
    "\n",
    "    datablob, datasource = test_csv_local_datablob_and_datasource(base_url, headers)\n",
    "\n",
    "    azure_datablob = test_azure_datablob(base_url, headers)\n",
    "\n",
    "    model = test_model(base_url, headers, datasource)\n",
    "\n",
    "    prediction = test_prediction(base_url, headers, model)\n",
    "\n",
    "    new_password = \"new_password\"  # nosec B105\n",
    "    reset_test_user_password(\n",
    "        base_url=base_url,\n",
    "        headers=headers,\n",
    "        username=user[\"username\"],\n",
    "        password=new_password,\n",
    "        otp=get_valid_otp(mfa_url[\"mfa_url\"]),\n",
    "    )\n",
    "\n",
    "    # Get token by using the new password\n",
    "    token = test_auth_with_otp(\n",
    "        base_url,\n",
    "        username=user[\"username\"],\n",
    "        password=new_password,\n",
    "        mfa_url=mfa_url[\"mfa_url\"],\n",
    "        retry_limit=3,\n",
    "    )\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    test_disable_mfa(\n",
    "        base_url, headers, user[\"username\"], otp=get_valid_otp(mfa_url[\"mfa_url\"])\n",
    "    )\n",
    "\n",
    "    delete_test_user(base_url, test_username=user[\"username\"])\n",
    "\n",
    "    sanitized_print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c148aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [71801]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Keeping the old async specifications at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Skipping generating async documentation in '/work/airt-service/notebooks/asyncapi/docs'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server started\n",
      "authenticating and getting token\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_realtime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_realtime_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 73) with member_id aiokafka-0.8.0-4c64f093-fd53-458e-948b-f4d9a509ee1a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 74) with member_id aiokafka-0.8.0-4c64f093-fd53-458e-948b-f4d9a509ee1a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 74) with member_id aiokafka-0.8.0-c1f09974-0724-4d37-aa05-5734602749a5\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 74) with member_id aiokafka-0.8.0-2b48df5f-8a65-4821-8d77-f5a57bfa74ff\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'infobip_training_data': 6} to {'infobip_realtime_data': 1, 'infobip_start_training_data': 6, 'infobip_training_data': 6}. \n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 74\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_training_data', partition=0), TopicPartition(topic='infobip_training_data', partition=1), TopicPartition(topic='infobip_training_data', partition=4), TopicPartition(topic='infobip_training_data', partition=5), TopicPartition(topic='infobip_training_data', partition=2), TopicPartition(topic='infobip_training_data', partition=3)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 74\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 74\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training_data', partition=5), TopicPartition(topic='infobip_start_training_data', partition=2), TopicPartition(topic='infobip_start_training_data', partition=3), TopicPartition(topic='infobip_start_training_data', partition=0), TopicPartition(topic='infobip_start_training_data', partition=1), TopicPartition(topic='infobip_start_training_data', partition=4)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "INFO:     127.0.0.1:47248 - \"POST /token HTTP/1.1\" 200 OK\n",
      "starting integration tests\n",
      "getting /docs\n",
      "INFO:     127.0.0.1:47264 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "getting /redocs\n",
      "INFO:     127.0.0.1:47268 - \"GET /redoc HTTP/1.1\" 200 OK\n",
      "creating user\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_start_training_data created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_data created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_realitime_data created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_data_status created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_model_status created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_model_metrics created\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_prediction created\n",
      "INFO:     127.0.0.1:47274 - \"POST /user/ HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674209613.005|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674209613.005|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:47288 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:47292 - \"GET /user/mfa/generate HTTP/1.1\" 200 OK\n",
      "Generating mfa url\n",
      "INFO:     127.0.0.1:47294 - \"POST /user/mfa/activate HTTP/1.1\" 200 OK\n",
      "Activate mfa\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:47296 - \"POST /token HTTP/1.1\" 200 OK\n",
      "creating apikey\n",
      "INFO:     127.0.0.1:58270 - \"POST /apikey HTTP/1.1\" 200 OK\n",
      "creating datablob\n",
      "[INFO] botocore.credentials: Found credentials in environment variables.\n",
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('1833f72f-66af-41d6-bdfc-356bc4d26189'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-1.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20230120/eu-west-1/s3/aws4_request', 'x-amz-date': '20230120T101336Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "INFO:     127.0.0.1:58276 - \"POST /datablob/from_local/start HTTP/1.1\" 200 OK\n",
      "downloading csv file\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_au4su3va\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_au4su3va\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_au4su3va\n",
      "uploading csv file using presigned url\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_au4su3va\n",
      "creating datasource\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='process_csv 196 115 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='process_csv 196 115 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:38900 - \"POST /datablob/1833f72f-66af-41d6-bdfc-356bc4d26189/to_datasource HTTP/1.1\" 202 Accepted\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'process_csv 196 115 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "start waiting for steps to complete\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['process_csv', '196', '115', 'PersonId', '[\"OccurredTime\"]', '--blocksize', '256MB', '--deduplicate_data']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'process_csv 196 115 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "INFO:     127.0.0.1:38906 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39044 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39060 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51790 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51792 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56766 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56768 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52898 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for datasource\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:52912 - \"GET /datablob/1833f72f-66af-41d6-bdfc-356bc4d26189 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'process_csv 196 115 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "23-01-20 10:13:53.898 [INFO] airt.data.importers: Module loaded:\n",
      "23-01-20 10:13:53.898 [INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "23-01-20 10:13:53.899 [INFO] airt.data.importers:  - using dask       : 2022.10.0\n",
      "23-01-20 10:13:55.224 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): processing user uploaded csv file for datablob_id=196 and uploading parquet back to S3 for datasource_id=115\n",
      "23-01-20 10:13:55.286 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-20 10:13:57.723 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-1/541/datablob/196\n",
      "23-01-20 10:13:57.723 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/datablob/196\n",
      "23-01-20 10:13:57.724 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u\n",
      "23-01-20 10:13:57.724 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/datablob/196 locally in /tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u\n",
      "23-01-20 10:13:57.724 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/541/datablob/196 to /tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u\n",
      "23-01-20 10:14:02.799 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): step 2/4: running import_csv()\n",
      "23-01-20 10:14:02.800 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/datasource/115\n",
      "23-01-20 10:14:02.800 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg\n",
      "23-01-20 10:14:02.800 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/datasource/115 locally in /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg\n",
      "23-01-20 10:14:02.801 [INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u/file.csv] using blocksize='256MB' and kwargs={} and storing result in /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg\n",
      "23-01-20 10:14:02.809 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:14:03.942 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:36047' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:14:03.942 [INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "23-01-20 10:14:05.445 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:14:05.445 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:14:05.752 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:14:05.753 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:14:06.376 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:44117' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:14:06.376 [INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "23-01-20 10:14:08.319 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:14:08.319 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:14:08.565 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:14:08.566 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:14:09.438 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:34145' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:14:09.438 [INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-20 10:14:11.623 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:14:11.623 [INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "23-01-20 10:14:13.298 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:14:13.298 [INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-20 10:14:15.815 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:14:15.816 [INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg as Parquet files with:\n",
      "23-01-20 10:14:16.041 [INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('O'), 'OccurredTimeTicks': dtype('int64')}\n",
      "23-01-20 10:14:16.041 [INFO] airt.data.importers:  - npartitions=1\n",
      "23-01-20 10:14:16.041 [INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "23-01-20 10:14:16.042 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:14:16.464 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:14:16.840 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-1/541/datasource/115, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg, access_key=None, secret_key=None)\n",
      "23-01-20 10:14:16.840 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg to s3://kumaran-airt-service-eu-west-1/541/datasource/115\n",
      "23-01-20 10:14:25.034 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_xf3cbkgg\n",
      "23-01-20 10:14:25.035 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541datablob196_cached_yle8tv2u\n",
      "23-01-20 10:14:25.039 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "23-01-20 10:14:26.918 [INFO] airt_service.data.csv: process_csv(datablob_id=196, datasource_id=115): completed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'process_csv 196 115 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'process_csv 196 115 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data' with return code 0\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_ba4j_a25\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_ba4j_a25\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_ba4j_a25\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_ba4j_a25\n",
      "INFO:     127.0.0.1:52926 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7/head HTTP/1.1\" 200 OK\n",
      "head of datasource\n",
      "{'data': {'index': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'columns': ['AccountId', 'DefinitionId', 'OccurredTime', 'OccurredTimeTicks'], 'data': [[312571, 'loadTests2', '2019-12-31 21:30:02', 1577836802678], [312571, 'loadTests3', '2020-01-03 23:53:22', 1578104602678], [312571, 'loadTests1', '2020-01-07 02:16:42', 1578372402678], [312571, 'loadTests2', '2020-01-10 04:40:02', 1578640202678], [312571, 'loadTests3', '2020-01-13 07:03:22', 1578908002678], [312571, 'loadTests1', '2020-01-16 09:26:42', 1579175802678], [312571, 'loadTests2', '2020-01-19 11:50:02', 1579443602678], [312571, 'loadTests3', '2020-01-22 14:13:22', 1579711402678], [312571, 'loadTests1', '2020-01-25 16:36:42', 1579979202678], [312571, 'loadTests2', '2020-01-28 19:00:02', 1580247002678]], 'index_names': ['PersonId'], 'column_names': [None]}, 'dtypes': {'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}}\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_8h200kk0\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_8h200kk0\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/541/datasource/115/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_8h200kk0\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541datasource115metadata_by_airt_cached_8h200kk0\n",
      "INFO:     127.0.0.1:52930 - \"GET /datasource/7471b30c-2815-4d95-97a8-45907d6ffbb7/dtypes HTTP/1.1\" 200 OK\n",
      "dtypes of datasource\n",
      "{'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "creating azure datablob\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='azure_blob_storage_pull 197', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='azure_blob_storage_pull 197', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:52940 - \"POST /datablob/from_azure_blob_storage HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'azure_blob_storage_pull 197'\n",
      "start waiting for steps to complete[INFO] airt_service.background_task: Background task command broken into: ['azure_blob_storage_pull', '197']\n",
      "\n",
      "[INFO] airt_service.background_task: Background task started for command: 'azure_blob_storage_pull 197'\n",
      "INFO:     127.0.0.1:51786 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51802 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54926 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54942 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39598 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:39612 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48536 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48550 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53118 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53134 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52072 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52088 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:59734 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'azure_blob_storage_pull 197':\n",
      "23-01-20 10:14:36.079 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:14:36.080 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:14:36.810 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:14:38.841 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:08.979 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:15:08.979 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:15:08.980 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/541/datablob/197\n",
      "23-01-20 10:15:08.980 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope541datablob197_cached_mijgvyr5\n",
      "23-01-20 10:15:08.980 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/541/datablob/197 locally in /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope541datablob197_cached_mijgvyr5\n",
      "23-01-20 10:15:08.980 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:15:08.980 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:15:08.981 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://testairtservice.blob.core.windows.net/test-container/account_312571_events\n",
      "23-01-20 10:15:08.981 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_8hvtopv6\n",
      "23-01-20 10:15:08.981 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://testairtservice.blob.core.windows.net/test-container/account_312571_events locally in /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_8hvtopv6\n",
      "23-01-20 10:15:08.981 [INFO] airt.remote_path: AzureBlobPath.__enter__(): pulling data from https://testairtservice.blob.core.windows.net/test-container/account_312571_events to /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_8hvtopv6\n",
      "23-01-20 10:15:13.988 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_8hvtopv6\n",
      "23-01-20 10:15:13.989 [INFO] airt.remote_path: AzureBlobPath.__exit__(): pushing data from /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope541datablob197_cached_mijgvyr5 to https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/541/datablob/197\n",
      "23-01-20 10:15:14.802 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:16.010 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:17.646 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:29.570 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope541datablob197_cached_mijgvyr5\n",
      "23-01-20 10:15:29.572 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:15:29.572 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:15:30.366 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:32.011 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:15:34.565 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:15:34.565 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:15:35.253 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'azure_blob_storage_pull 197':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'azure_blob_storage_pull 197' with return code 0\n",
      "INFO:     127.0.0.1:59736 - \"GET /datablob/f3e83987-74ac-4c6a-8751-20ca01fcdd65 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for azure datablob\n",
      "training model\n",
      "INFO:     127.0.0.1:59750 - \"POST /model/train HTTP/1.1\" 200 OK\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:59762 - \"GET /model/2e98d357-253a-4450-a34f-24d0c41bf624 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "model training completed\n",
      "INFO:     127.0.0.1:59776 - \"GET /model/2e98d357-253a-4450-a34f-24d0c41bf624/evaluate HTTP/1.1\" 200 OK\n",
      "model evaluation\n",
      "{'accuracy': 0.985, 'recall': 0.962, 'precision': 0.934}\n",
      "running prediction\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='predict 55', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='predict 55', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:59784 - \"POST /model/2e98d357-253a-4450-a34f-24d0c41bf624/predict HTTP/1.1\" 200 OK\n",
      "start waiting for steps to complete[INFO] airt_service.background_task: Background task starting for command: 'predict 55'\n",
      "\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['predict', '55']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'predict 55'\n",
      "INFO:     127.0.0.1:59800 - \"GET /prediction/917b0e02-b9d0-411a-a841-da16d9058e39 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:34006 - \"GET /prediction/917b0e02-b9d0-411a-a841-da16d9058e39 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:34008 - \"GET /prediction/917b0e02-b9d0-411a-a841-da16d9058e39 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:36308 - \"GET /prediction/917b0e02-b9d0-411a-a841-da16d9058e39 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "prediction completed\n",
      "INFO:     127.0.0.1:36316 - \"GET /prediction/917b0e02-b9d0-411a-a841-da16d9058e39/pandas HTTP/1.1\" 200 OK\n",
      "prediction as pandas\n",
      "{'user_id': [520088904, 530496790, 561587266, 518085591, 558856683, 520772685, 514028527, 518574284, 532364121, 532647354], 'Score': [0.979853, 0.979157, 0.979055, 0.978915, 0.97796, 0.004043, 0.00389, 0.001346, 0.001341, 0.001139]}\n",
      "Resetting password for: nsvhwltygv\n",
      "INFO:     127.0.0.1:36330 - \"POST /user/reset_password HTTP/1.1\" 200 OK\n",
      "\"Password reset successful\"\n",
      "authenticating with otp and getting token\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'predict 55':\n",
      "23-01-20 10:15:44.007 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-20 10:15:45.082 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/prediction/55\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541prediction55_cached_9tyxmcn0\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/prediction/55 locally in /tmp/s3kumaran-airt-service-eu-west-1541prediction55_cached_9tyxmcn0\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/541/datasource/115\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_grnry64b\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/541/datasource/115 locally in /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_grnry64b\n",
      "23-01-20 10:15:45.083 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/541/datasource/115 to /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_grnry64b\n",
      "23-01-20 10:15:49.495 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541datasource115_cached_grnry64b\n",
      "23-01-20 10:15:49.496 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1541prediction55_cached_9tyxmcn0 to s3://kumaran-airt-service-eu-west-1/541/prediction/55\n",
      "23-01-20 10:15:56.306 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1541prediction55_cached_9tyxmcn0\n",
      "\n",
      "[INFO] airt_service.background_task: Background task stderr for command: 'predict 55':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'predict 55' with return code 0\n",
      "INFO:     127.0.0.1:36346 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:36348 - \"GET /user/details?user_id_or_name=None HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:36354 - \"DELETE /user/mfa/d0c2a48d-0692-4e11-87d2-a8276f8d3b5a/disable?otp=401036 HTTP/1.1\" 200 OK\n",
      "{\"username\":\"nsvhwltygv\",\"first_name\":\"integration\",\"last_name\":\"user\",\"email\":\"nsvhwltygv@email.com\",\"subscription_type\":\"small\",\"super_user\":false,\"phone_number\":null,\"uuid\":\"d0c2a48d-0692-4e11-87d2-a8276f8d3b5a\",\"disabled\":false,\"created\":\"2023-01-20T10:13:33\",\"is_phone_number_verified\":false,\"is_mfa_active\":false}\n",
      "Deactivate mfa\n",
      "deleting test user\n",
      "[INFO] airt_service.cleanup: deleting predictions\n",
      "[INFO] airt_service.cleanup: deleting models\n",
      "[INFO] airt_service.cleanup: deleting datasources\n",
      "[INFO] airt_service.cleanup: deleting datablobs\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.cleanup: deleting apikeys\n",
      "[INFO] airt_service.cleanup: Deleting user files in s3://kumaran-airt-service-eu-west-1/541\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_start_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_realitime_data deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_data_status deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_training_model_status deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_model_metrics deleted\n",
      "[INFO] airt_service.confluent: Topic nsvhwltygv_prediction deleted\n",
      "[INFO] airt_service.cleanup: deleting user\n",
      "INFO:     127.0.0.1:36360 - \"POST /user/cleanup HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674209771.801|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674209771.801|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [71801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "# from https://github.com/encode/uvicorn/issues/742\n",
    "\n",
    "\n",
    "def test_integration_tests():\n",
    "    # Start integration tests\n",
    "    token = test_auth(\n",
    "        \"http://127.0.0.1:6006\",\n",
    "        username=\"kumaran\",\n",
    "        password=os.environ[\"AIRT_SERVICE_SUPER_USER_PASSWORD\"],\n",
    "    )\n",
    "    with set_env_variable_context(variable=\"AIRT_SERVICE_TOKEN\", value=token):\n",
    "        integration_tests()\n",
    "\n",
    "\n",
    "class Server(uvicorn.Server):\n",
    "    def install_signal_handlers(self):\n",
    "        pass\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def run_in_thread(self):\n",
    "        thread = threading.Thread(target=self.run)\n",
    "        thread.start()\n",
    "        try:\n",
    "            while not self.started:\n",
    "                time.sleep(1e-3)\n",
    "            yield\n",
    "        finally:\n",
    "            self.should_exit = True\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "with posix_ipc.Semaphore(\n",
    "    \"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT, initial_value=1\n",
    ") as sem:\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        app, fast_kafka_api_app = create_ws_server(\n",
    "            assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "        )\n",
    "        config = uvicorn.Config(app, host=\"127.0.0.1\", port=6006, log_level=\"info\")\n",
    "        server = Server(config=config)\n",
    "\n",
    "        with server.run_in_thread():\n",
    "            # Server started.\n",
    "            sanitized_print(\"server started\")\n",
    "\n",
    "            test_integration_tests()\n",
    "\n",
    "        sanitized_print(\"server stopped\")\n",
    "        # Server stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def run_integration_tests(\n",
    "    host: Param(\"hostname\", str),  # type: ignore\n",
    "    port: Param(\"port\", int),  # type: ignore\n",
    "    protocol: Param(\"http or https\", str) = \"https\",  # type: ignore\n",
    "):\n",
    "    \"\"\"Run integration tests against given host and port\n",
    "\n",
    "    Args:\n",
    "        host: Hostname of the webserver to run tests against\n",
    "        port: Port of the webserver\n",
    "        protocol: Protocol to use for testing\n",
    "    \"\"\"\n",
    "    base_url = f\"{protocol}://{host}:{port}\"\n",
    "    integration_tests(base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0087f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [71801]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api._components.asyncapi: Keeping the old async specifications at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Skipping generating async documentation in '/work/airt-service/notebooks/asyncapi/docs'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6006 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authenticating and getting token\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_realtime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_realtime_data'}\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 79) with member_id aiokafka-0.8.0-adcbb220-0407-4905-8e36-d112ef22742e\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1002 for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 80) with member_id aiokafka-0.8.0-4b66e620-6021-468a-a702-28bea0e8cd8f\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 80) with member_id aiokafka-0.8.0-3042da9c-8aae-4ebf-93c9-c5550e3d1fc4\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 80) with member_id aiokafka-0.8.0-adcbb220-0407-4905-8e36-d112ef22742e\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'infobip_start_training_data': 6} to {'infobip_realtime_data': 1, 'infobip_start_training_data': 6, 'infobip_training_data': 6}. \n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 80\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 80\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_training_data', partition=0), TopicPartition(topic='infobip_training_data', partition=1), TopicPartition(topic='infobip_training_data', partition=4), TopicPartition(topic='infobip_training_data', partition=5), TopicPartition(topic='infobip_training_data', partition=2), TopicPartition(topic='infobip_training_data', partition=3)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 80\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training_data', partition=5), TopicPartition(topic='infobip_start_training_data', partition=2), TopicPartition(topic='infobip_start_training_data', partition=3), TopicPartition(topic='infobip_start_training_data', partition=0), TopicPartition(topic='infobip_start_training_data', partition=1), TopicPartition(topic='infobip_start_training_data', partition=4)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "INFO:     127.0.0.1:57984 - \"POST /token HTTP/1.1\" 200 OK\n",
      "starting integration tests\n",
      "getting /docs\n",
      "INFO:     127.0.0.1:57990 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "getting /redocs\n",
      "INFO:     127.0.0.1:58000 - \"GET /redoc HTTP/1.1\" 200 OK\n",
      "creating user\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_start_training_data created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_data created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_realitime_data created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_data_status created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_model_status created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_model_metrics created\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_prediction created\n",
      "INFO:     127.0.0.1:58010 - \"POST /user/ HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674209805.483|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674209805.483|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authenticating and getting token\n",
      "INFO:     127.0.0.1:58014 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58030 - \"GET /user/mfa/generate HTTP/1.1\" 200 OK\n",
      "Generating mfa url\n",
      "INFO:     127.0.0.1:58032 - \"POST /user/mfa/activate HTTP/1.1\" 200 OK\n",
      "Activate mfa\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:58042 - \"POST /token HTTP/1.1\" 200 OK\n",
      "creating apikey\n",
      "INFO:     127.0.0.1:58058 - \"POST /apikey HTTP/1.1\" 200 OK\n",
      "creating datablob\n",
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('d7ad146a-d76d-43de-9750-c1d821fe689e'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-1.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20230120/eu-west-1/s3/aws4_request', 'x-amz-date': '20230120T101647Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "INFO:     127.0.0.1:58072 - \"POST /datablob/from_local/start HTTP/1.1\" 200 OK\n",
      "downloading csv file\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_ufxnz48i\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_ufxnz48i\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_ufxnz48i\n",
      "uploading csv file using presigned url\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_ufxnz48i\n",
      "creating datasource\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='process_csv 198 116 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='process_csv 198 116 PersonId \\'[\"OccurredTime\"]\\' --blocksize 256MB --deduplicate_data', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:52308 - \"POST /datablob/d7ad146a-d76d-43de-9750-c1d821fe689e/to_datasource HTTP/1.1\" 202 Accepted\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'process_csv 198 116 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "start waiting for steps to complete\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['process_csv', '198', '116', 'PersonId', '[\"OccurredTime\"]', '--blocksize', '256MB', '--deduplicate_data']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'process_csv 198 116 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data'\n",
      "INFO:     127.0.0.1:52318 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52330 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56612 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56624 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:48028 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38458 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38472 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'process_csv 198 116 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "23-01-20 10:17:09.713 [INFO] airt.data.importers: Module loaded:\n",
      "23-01-20 10:17:09.713 [INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "23-01-20 10:17:09.713 [INFO] airt.data.importers:  - using dask       : 2022.10.0\n",
      "23-01-20 10:17:10.842 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): processing user uploaded csv file for datablob_id=198 and uploading parquet back to S3 for datasource_id=116\n",
      "23-01-20 10:17:10.903 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-20 10:17:13.229 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-1/544/datablob/198\n",
      "23-01-20 10:17:13.229 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/datablob/198\n",
      "23-01-20 10:17:13.230 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi\n",
      "23-01-20 10:17:13.230 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/datablob/198 locally in /tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi\n",
      "23-01-20 10:17:13.230 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/544/datablob/198 to /tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi\n",
      "23-01-20 10:17:19.699 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): step 2/4: running import_csv()\n",
      "23-01-20 10:17:19.699 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/datasource/116\n",
      "23-01-20 10:17:19.699 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q\n",
      "23-01-20 10:17:19.699 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/datasource/116 locally in /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q\n",
      "23-01-20 10:17:19.699 [INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi/file.csv] using blocksize='256MB' and kwargs={} and storing result in /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q\n",
      "23-01-20 10:17:19.706 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:17:20.950 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:45535' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:17:20.950 [INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "23-01-20 10:17:22.871 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:17:22.871 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:17:23.215 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:17:23.215 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:17:23.835 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:44857' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:17:23.835 [INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "23-01-20 10:17:25.312 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:17:25.312 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:17:25.556 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:17:25.556 [INFO] airt.dask_manager: Starting cluster...\n",
      "23-01-20 10:17:26.273 [INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:40417' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "23-01-20 10:17:26.273 [INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-20 10:17:28.401 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:17:28.401 [INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "23-01-20 10:17:30.083 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:17:30.083 [INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and ['OccurredTime'].\n",
      "23-01-20 10:17:32.030 [INFO] airt.data.importers:  - number of rows: 498,961\n",
      "23-01-20 10:17:32.030 [INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q as Parquet files with:\n",
      "23-01-20 10:17:32.245 [INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('O'), 'OccurredTimeTicks': dtype('int64')}\n",
      "23-01-20 10:17:32.245 [INFO] airt.data.importers:  - npartitions=1\n",
      "23-01-20 10:17:32.246 [INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "23-01-20 10:17:32.246 [INFO] airt.dask_manager: Starting stopping cluster...\n",
      "23-01-20 10:17:32.595 [INFO] airt.dask_manager: Cluster stopped\n",
      "23-01-20 10:17:33.018 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-1/544/datasource/116, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q, access_key=None, secret_key=None)\n",
      "23-01-20 10:17:33.018 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q to s3://kumaran-airt-service-eu-west-1/544/datasource/116\n",
      "23-01-20 10:17:40.207 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_ynz3yv9q\n",
      "23-01-20 10:17:40.208 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544datablob198_cached_ll5pihqi\n",
      "23-01-20 10:17:40.211 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "23-01-20 10:17:41.938 [INFO] airt_service.data.csv: process_csv(datablob_id=198, datasource_id=116): completed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'process_csv 198 116 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'process_csv 198 116 PersonId '[\"OccurredTime\"]' --blocksize 256MB --deduplicate_data' with return code 0\n",
      "INFO:     127.0.0.1:36956 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753 HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for datasource\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:36964 - \"GET /datablob/d7ad146a-d76d-43de-9750-c1d821fe689e HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_5jk_57ji\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_5jk_57ji\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_5jk_57ji\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_5jk_57ji\n",
      "INFO:     127.0.0.1:36978 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753/head HTTP/1.1\" 200 OK\n",
      "head of datasource\n",
      "{'data': {'index': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'columns': ['AccountId', 'DefinitionId', 'OccurredTime', 'OccurredTimeTicks'], 'data': [[312571, 'loadTests2', '2019-12-31 21:30:02', 1577836802678], [312571, 'loadTests3', '2020-01-03 23:53:22', 1578104602678], [312571, 'loadTests1', '2020-01-07 02:16:42', 1578372402678], [312571, 'loadTests2', '2020-01-10 04:40:02', 1578640202678], [312571, 'loadTests3', '2020-01-13 07:03:22', 1578908002678], [312571, 'loadTests1', '2020-01-16 09:26:42', 1579175802678], [312571, 'loadTests2', '2020-01-19 11:50:02', 1579443602678], [312571, 'loadTests3', '2020-01-22 14:13:22', 1579711402678], [312571, 'loadTests1', '2020-01-25 16:36:42', 1579979202678], [312571, 'loadTests2', '2020-01-28 19:00:02', 1580247002678]], 'index_names': ['PersonId'], 'column_names': [None]}, 'dtypes': {'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}}\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_i2kaofk1\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt locally in /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_i2kaofk1\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/544/datasource/116/.metadata_by_airt to /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_i2kaofk1\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544datasource116metadata_by_airt_cached_i2kaofk1\n",
      "INFO:     127.0.0.1:36994 - \"GET /datasource/18687326-bca8-4882-b823-a086cff73753/dtypes HTTP/1.1\" 200 OK\n",
      "dtypes of datasource\n",
      "{'AccountId': 'int64', 'DefinitionId': 'object', 'OccurredTime': 'object', 'OccurredTimeTicks': 'int64'}\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "creating azure datablob\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='azure_blob_storage_pull 199', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='azure_blob_storage_pull 199', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:37002 - \"POST /datablob/from_azure_blob_storage HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'azure_blob_storage_pull 199'\n",
      "start waiting for steps to complete\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['azure_blob_storage_pull', '199']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'azure_blob_storage_pull 199'\n",
      "INFO:     127.0.0.1:37016 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53658 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53666 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:44908 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:44918 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58342 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58356 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53530 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53532 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'azure_blob_storage_pull 199':\n",
      "23-01-20 10:17:51.017 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:17:51.018 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:17:51.798 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:17:53.843 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:17:56.035 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:17:56.036 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:17:56.036 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/544/datablob/199\n",
      "23-01-20 10:17:56.037 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope544datablob199_cached_g_344td5\n",
      "23-01-20 10:17:56.037 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/544/datablob/199 locally in /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope544datablob199_cached_g_344td5\n",
      "23-01-20 10:17:56.037 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:17:56.037 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:17:56.038 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://testairtservice.blob.core.windows.net/test-container/account_312571_events\n",
      "23-01-20 10:17:56.038 [INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_g7y9yh8s\n",
      "23-01-20 10:17:56.038 [INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://testairtservice.blob.core.windows.net/test-container/account_312571_events locally in /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_g7y9yh8s\n",
      "23-01-20 10:17:56.039 [INFO] airt.remote_path: AzureBlobPath.__enter__(): pulling data from https://testairtservice.blob.core.windows.net/test-container/account_312571_events to /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_g7y9yh8s\n",
      "23-01-20 10:18:00.592 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_g7y9yh8s\n",
      "23-01-20 10:18:00.593 [INFO] airt.remote_path: AzureBlobPath.__exit__(): pushing data from /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope544datablob199_cached_g_344td5 to https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/544/datablob/199\n",
      "23-01-20 10:18:01.246 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:18:02.118 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:18:04.081 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:18:23.382 [INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope544datablob199_cached_g_344td5\n",
      "23-01-20 10:18:23.384 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:18:23.384 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:18:24.097 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:18:26.390 [INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "23-01-20 10:18:28.363 [INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "23-01-20 10:18:28.363 [INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "23-01-20 10:18:29.094 [INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.background_task: Background task stderr for command: 'azure_blob_storage_pull 199':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'azure_blob_storage_pull 199' with return code 0\n",
      "INFO:     127.0.0.1:35480 - \"GET /datablob/6dbf609d-4948-49a0-bb71-de96084056fd HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "pull completed for azure datablob\n",
      "training model\n",
      "INFO:     127.0.0.1:35496 - \"POST /model/train HTTP/1.1\" 200 OK\n",
      "start waiting for steps to complete\n",
      "INFO:     127.0.0.1:35498 - \"GET /model/67210950-ff6c-4083-901f-584089f9cded HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "model training completed\n",
      "INFO:     127.0.0.1:35506 - \"GET /model/67210950-ff6c-4083-901f-584089f9cded/evaluate HTTP/1.1\" 200 OK\n",
      "model evaluation\n",
      "{'accuracy': 0.985, 'recall': 0.962, 'precision': 0.934}\n",
      "running prediction\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='predict 56', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='predict 56', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "INFO:     127.0.0.1:35510 - \"POST /model/67210950-ff6c-4083-901f-584089f9cded/predict HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Background task starting for command: 'predict 56'\n",
      "start waiting for steps to complete\n",
      "[INFO] airt_service.background_task: Background task command broken into: ['predict', '56']\n",
      "[INFO] airt_service.background_task: Background task started for command: 'predict 56'\n",
      "INFO:     127.0.0.1:35516 - \"GET /prediction/52a4fe29-205e-4573-8b04-930ecf22254d HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:35524 - \"GET /prediction/52a4fe29-205e-4573-8b04-930ecf22254d HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54998 - \"GET /prediction/52a4fe29-205e-4573-8b04-930ecf22254d HTTP/1.1\" 200 OK\n",
      "[INFO] airt_service.background_task: Command finished with return code 0\n",
      "[INFO] airt_service.background_task: Background task stdout for command: 'predict 56':\n",
      "23-01-20 10:18:37.878 [INFO] botocore.credentials: Found credentials in environment variables.\n",
      "23-01-20 10:18:38.822 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/prediction/56\n",
      "23-01-20 10:18:38.823 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544prediction56_cached_a6lp6alt\n",
      "23-01-20 10:18:38.823 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/prediction/56 locally in /tmp/s3kumaran-airt-service-eu-west-1544prediction56_cached_a6lp6alt\n",
      "23-01-20 10:18:38.823 [INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/544/datasource/116\n",
      "23-01-20 10:18:38.823 [INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_d_ze3t39\n",
      "23-01-20 10:18:38.824 [INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/544/datasource/116 locally in /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_d_ze3t39\n",
      "23-01-20 10:18:38.824 [INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/544/datasource/116 to /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_d_ze3t39\n",
      "23-01-20 10:18:42.312 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544datasource116_cached_d_ze3t39\n",
      "23-01-20 10:18:42.313 [INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-1544prediction56_cached_a6lp6alt to s3://kumaran-airt-service-eu-west-1/544/prediction/56\n",
      "23-01-20 10:18:47.504 [INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-1544prediction56_cached_a6lp6alt\n",
      "\n",
      "[INFO] airt_service.background_task: Background task stderr for command: 'predict 56':\n",
      "\n",
      "[INFO] airt_service.background_task: Background task finished for command: 'predict 56' with return code 0\n",
      "INFO:     127.0.0.1:55008 - \"GET /prediction/52a4fe29-205e-4573-8b04-930ecf22254d HTTP/1.1\" 200 OK\n",
      "stop waiting for steps to complete\n",
      "prediction completed\n",
      "INFO:     127.0.0.1:55014 - \"GET /prediction/52a4fe29-205e-4573-8b04-930ecf22254d/pandas HTTP/1.1\" 200 OK\n",
      "prediction as pandas\n",
      "{'user_id': [520088904, 530496790, 561587266, 518085591, 558856683, 520772685, 514028527, 518574284, 532364121, 532647354], 'Score': [0.979853, 0.979157, 0.979055, 0.978915, 0.97796, 0.004043, 0.00389, 0.001346, 0.001341, 0.001139]}\n",
      "Resetting password for: fwjgngctzs\n",
      "INFO:     127.0.0.1:55016 - \"POST /user/reset_password HTTP/1.1\" 200 OK\n",
      "\"Password reset successful\"\n",
      "authenticating with otp and getting token\n",
      "INFO:     127.0.0.1:55026 - \"POST /token HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55034 - \"GET /user/details?user_id_or_name=None HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55048 - \"DELETE /user/mfa/ef9146fd-6318-4fc1-920e-ac5ce5dae133/disable?otp=339667 HTTP/1.1\" 200 OK\n",
      "{\"username\":\"fwjgngctzs\",\"first_name\":\"integration\",\"last_name\":\"user\",\"email\":\"fwjgngctzs@email.com\",\"subscription_type\":\"small\",\"super_user\":false,\"phone_number\":null,\"uuid\":\"ef9146fd-6318-4fc1-920e-ac5ce5dae133\",\"disabled\":false,\"created\":\"2023-01-20T10:16:45\",\"is_phone_number_verified\":false,\"is_mfa_active\":false}\n",
      "Deactivate mfa\n",
      "deleting test user\n",
      "[INFO] airt_service.cleanup: deleting predictions\n",
      "[INFO] airt_service.cleanup: deleting models\n",
      "[INFO] airt_service.cleanup: deleting datasources\n",
      "[INFO] airt_service.cleanup: deleting datablobs\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.cleanup: deleting apikeys\n",
      "[INFO] airt_service.cleanup: Deleting user files in s3://kumaran-airt-service-eu-west-1/544\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_start_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_data deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_realitime_data deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_data_status deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_training_model_status deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_model_metrics deleted\n",
      "[INFO] airt_service.confluent: Topic fwjgngctzs_prediction deleted\n",
      "[INFO] airt_service.cleanup: deleting user\n",
      "INFO:     127.0.0.1:55058 - \"POST /user/cleanup HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674209944.663|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674209944.663|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "INFO:     Shutting down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [71801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "def test_run_integration_tests(host, port, protocol):\n",
    "    # Start integration tests\n",
    "    token = test_auth(\n",
    "        f\"{protocol}://{host}:{port}\",\n",
    "        username=\"kumaran\",\n",
    "        password=os.environ[\"AIRT_SERVICE_SUPER_USER_PASSWORD\"],\n",
    "    )\n",
    "    with set_env_variable_context(variable=\"AIRT_SERVICE_TOKEN\", value=token):\n",
    "        run_integration_tests(host, port, protocol)\n",
    "\n",
    "\n",
    "with posix_ipc.Semaphore(\n",
    "    \"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT, initial_value=1\n",
    ") as sem:\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        app, fast_kafka_api_app = create_ws_server(\n",
    "            assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "        )\n",
    "        config = uvicorn.Config(app, host=\"127.0.0.1\", port=6006, log_level=\"info\")\n",
    "        server = Server(config=config)\n",
    "\n",
    "        with server.run_in_thread():\n",
    "            test_run_integration_tests(\"127.0.0.1\", port=6006, protocol=\"http\")\n",
    "\n",
    "        sanitized_print(\"server stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2086b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
