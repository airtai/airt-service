{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "{}\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n",
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "[INFO] airt.keras.helpers: Using a single GPU #0 with memory_limit 1024 MB\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import airt_service.sanitizer\n",
    "\n",
    "from airt_service.batch_job_components.base import BatchJobContext\n",
    "\n",
    "from airt_service.batch_job_components.aws import AwsBatchJobContext\n",
    "from airt_service.batch_job_components.azure import AzureBatchJobContext\n",
    "from airt_service.batch_job_components.fastapi import FastAPIBatchJobContext\n",
    "from airt_service.batch_job_components.none import NoneBatchJobContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AwsBatchJobContext': airt_service.batch_job_components.aws.AwsBatchJobContext,\n",
       " 'AzureBatchJobContext': airt_service.batch_job_components.azure.AzureBatchJobContext,\n",
       " 'FastAPIBatchJobContext': airt_service.batch_job_components.fastapi.FastAPIBatchJobContext,\n",
       " 'NoneBatchJobContext': airt_service.batch_job_components.none.NoneBatchJobContext}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(BatchJobContext._factories) > 0\n",
    "BatchJobContext._factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from os import environ\n",
    "\n",
    "from fastapi import BackgroundTasks\n",
    "\n",
    "from airt.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _pytest.monkeypatch import MonkeyPatch\n",
    "\n",
    "from airt_service.background_task import execute_cli\n",
    "from airt_service.helpers import set_env_variable_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def get_environment_vars_for_batch_job() -> dict:\n",
    "    \"\"\"Get the necessary environment variables for creating a batch job\n",
    "\n",
    "    Returns:\n",
    "        The environment variables as a dict\n",
    "    \"\"\"\n",
    "    return {\n",
    "        var: environ[var]\n",
    "        for var in [\n",
    "            \"AWS_ACCESS_KEY_ID\",\n",
    "            \"AWS_SECRET_ACCESS_KEY\",\n",
    "            \"AWS_DEFAULT_REGION\",\n",
    "            \"AZURE_SUBSCRIPTION_ID\",\n",
    "            \"AZURE_TENANT_ID\",\n",
    "            \"AZURE_CLIENT_ID\",\n",
    "            \"AZURE_CLIENT_SECRET\",\n",
    "            \"AZURE_STORAGE_ACCOUNT_PREFIX\",\n",
    "            \"AZURE_RESOURCE_GROUP\",\n",
    "            #             \"AIRT_SERVICE_SUPER_USER_PASSWORD\",\n",
    "            #             \"AIRT_TOKEN_SECRET_KEY\",\n",
    "            \"STORAGE_BUCKET_PREFIX\",\n",
    "            \"DB_USERNAME\",\n",
    "            \"DB_PASSWORD\",\n",
    "            \"DB_HOST\",\n",
    "            \"DB_PORT\",\n",
    "            \"DB_DATABASE\",\n",
    "            \"DB_DATABASE_SERVER\",\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = get_environment_vars_for_batch_job()\n",
    "assert \"STORAGE_BUCKET_PREFIX\" in actual\n",
    "assert actual[\"STORAGE_BUCKET_PREFIX\"]\n",
    "# actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def create_batch_job(\n",
    "    command: str,\n",
    "    task: str,\n",
    "    cloud_provider: str,\n",
    "    region: str,\n",
    "    background_tasks: BackgroundTasks,\n",
    "):\n",
    "    \"\"\"Create a new batch job\n",
    "\n",
    "    Args:\n",
    "        command: The CLI command as a string\n",
    "        task: Task name as a string\n",
    "        cloud_provider: Cloud provider in which to execute batch job\n",
    "        region: Region to execute\n",
    "        background_tasks: An instance of BackgroundTasks\n",
    "    \"\"\"\n",
    "    logger.info(f\"create_batch_job(): {command=}, {task=}\")\n",
    "    with BatchJobContext.create(\n",
    "        task,\n",
    "        cloud_provider=cloud_provider,\n",
    "        region=region,\n",
    "        background_tasks=background_tasks,\n",
    "    ) as batch_ctx:\n",
    "        logger.info(f\"{batch_ctx=}\")\n",
    "        batch_ctx.create_job(\n",
    "            command=command, environment_vars=get_environment_vars_for_batch_job()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: create_batch_job(): command='s3_pull 1', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] __main__: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='s3_pull 1', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.func=<function execute_cli>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.args=()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bg_task.kwargs={'command': 's3_pull 1'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = BackgroundTasks()\n",
    "\n",
    "# Test using FastAPIBatchJobContext with set_env_variable_context\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    test_command = \"s3_pull 1\"\n",
    "    create_batch_job(command=test_command, task=\"csv_processing\", cloud_provider=\"azure\", region=\"eu-west-1\", background_tasks=b)\n",
    "\n",
    "bg_task = b.tasks[-1]\n",
    "display(f\"{bg_task.func=}\", f\"{bg_task.args=}\", f\"{bg_task.kwargs=}\")\n",
    "assert bg_task.func == execute_cli\n",
    "assert bg_task.kwargs[\"command\"] == test_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: create_batch_job(): command='db_pull 1', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering AwsBatchJobContext(task=csv_processing)\n",
      "[INFO] __main__: batch_ctx=AwsBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.aws: AwsBatchJobContext.create_job(self=AwsBatchJobContext(task=csv_processing), command='db_pull 1', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"kwargs={'job_queue_arn': 'aws:job_queue_arn', 'job_definition_arn': 'aws:job_definition_arn', 'region': 'eu-west-1', 'command': 'db_pull 1', 'environment_vars': {'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'}}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job_components.base: Exiting AwsBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    }
   ],
   "source": [
    "# Test using AwsBatchJobContext with MonkeyPatch\n",
    "with MonkeyPatch.context() as monkeypatch:\n",
    "    job_queue_arn = \"aws:job_queue_arn\"\n",
    "    job_definition_arn = \"aws:job_definition_arn\"\n",
    "    cloud_provider = \"aws\"\n",
    "    region = \"eu-west-1\"\n",
    "    monkeypatch.setattr(\n",
    "        \"airt_service.aws.utils.get_queue_definition_arns\",\n",
    "        lambda task, region: (job_queue_arn, job_definition_arn),\n",
    "    )\n",
    "\n",
    "    test_command = \"db_pull 1\"\n",
    "\n",
    "    def test_patch_create_job(*args, **kwargs):\n",
    "        display(f\"{kwargs=}\")\n",
    "        assert kwargs[\"job_queue_arn\"] == job_queue_arn\n",
    "        assert kwargs[\"job_definition_arn\"] == job_definition_arn\n",
    "        assert kwargs[\"command\"] == test_command\n",
    "        assert kwargs[\"region\"] == region\n",
    "        assert \"AWS_ACCESS_KEY_ID\" in kwargs[\"environment_vars\"]\n",
    "        assert \"AWS_SECRET_ACCESS_KEY\" in kwargs[\"environment_vars\"]\n",
    "\n",
    "    monkeypatch.setattr(\n",
    "        \"airt_service.aws.batch_utils.aws_batch_create_job\", test_patch_create_job\n",
    "    )\n",
    "\n",
    "    b = BackgroundTasks()\n",
    "    create_batch_job(\n",
    "        command=test_command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=cloud_provider,\n",
    "        region=region,\n",
    "        background_tasks=b,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: create_batch_job(): command='db_pull 1', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering AzureBatchJobContext(task=csv_processing)\n",
      "[INFO] __main__: batch_ctx=AzureBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.azure: AzureBatchJobContext.create_job(self=AzureBatchJobContext(task=csv_processing), command='db_pull 1', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"kwargs={'command': 'db_pull 1', 'batch_job_name': 'batch_job_name', 'batch_pool_name': 'batch_pool_name', 'batch_account_name': 'batch_account_name', 'region': 'northeurope', 'container_settings': <azure.batch.models._models_py3.TaskContainerSettings object>, 'environment_vars': {'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'}}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job_components.base: Exiting AzureBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    }
   ],
   "source": [
    "with MonkeyPatch.context() as monkeypatch:\n",
    "    batch_account_name = \"batch_account_name\"\n",
    "    batch_pool_name = \"batch_pool_name\"\n",
    "    batch_job_name = \"batch_job_name\"\n",
    "    cloud_provider = \"azure\"\n",
    "    region = \"northeurope\"\n",
    "    monkeypatch.setattr(\n",
    "        \"airt_service.azure.utils.get_batch_account_pool_job_names\",\n",
    "        lambda task, region: (\n",
    "            batch_account_name,\n",
    "            batch_pool_name,\n",
    "            batch_job_name,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    test_command = \"db_pull 1\"\n",
    "\n",
    "    def test_patch_create_job(*args, **kwargs):\n",
    "        display(f\"{kwargs=}\")\n",
    "        assert kwargs[\"batch_account_name\"] == batch_account_name\n",
    "        assert kwargs[\"batch_pool_name\"] == batch_pool_name\n",
    "        assert kwargs[\"batch_job_name\"] == batch_job_name\n",
    "        assert kwargs[\"region\"] == region\n",
    "        assert kwargs[\"command\"] == test_command\n",
    "        assert \"AZURE_SUBSCRIPTION_ID\" in kwargs[\"environment_vars\"]\n",
    "\n",
    "    monkeypatch.setattr(\n",
    "        \"airt_service.azure.batch_utils.azure_batch_create_job\", test_patch_create_job\n",
    "    )\n",
    "\n",
    "    b = BackgroundTasks()\n",
    "    create_batch_job(\n",
    "        command=test_command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=cloud_provider,\n",
    "        region=region,\n",
    "        background_tasks=b,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "\n",
    "def update_all():\n",
    "    global __all__\n",
    "    __all__ = [\n",
    "        \"BatchJobContext\",\n",
    "        \"AwsBatchJobContext\",\n",
    "        \"AzureBatchJobContext\",\n",
    "        \"FastAPIBatchJobContext\",\n",
    "        \"NoneBatchJobContext\",\n",
    "        \"get_environment_vars_for_batch_job\",\n",
    "        \"create_batch_job\",\n",
    "    ]\n",
    "\n",
    "\n",
    "update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
