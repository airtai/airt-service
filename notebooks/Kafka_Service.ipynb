{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4db70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp kafka_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-05-15 07:53:09.680 [INFO] matplotlib.font_manager: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "from os import environ\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from airt.logger import get_logger, supress_timestamps\n",
    "from fastkafka import FastKafka, KafkaEvent\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    EmailStr,\n",
    "    Field,\n",
    "    HttpUrl,\n",
    "    NonNegativeInt,\n",
    "    root_validator,\n",
    "    validator,\n",
    ")\n",
    "\n",
    "import airt_service\n",
    "from airt_service.confluent import aio_kafka_config\n",
    "from airt_service.data.clickhouse import (\n",
    "    get_all_person_ids_for_account_id,\n",
    "    get_count_for_account_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300eb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import functools\n",
    "import importlib\n",
    "import unittest\n",
    "from inspect import signature\n",
    "\n",
    "import asyncer\n",
    "import fastkafka\n",
    "import pytest\n",
    "from fastkafka.testing import Tester\n",
    "from pytest import MonkeyPatch\n",
    "\n",
    "from airt_service.db.models import create_user_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "supress_timestamps(False)\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2204475",
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_timestamps(True)\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heading(title: Optional[str] = None, width: int = 160):\n",
    "    print()\n",
    "    print(\"*\" * width)\n",
    "    print(\"*\" * 3 + \" \" * (width - 6) + \"*\" * 3)\n",
    "    if title:\n",
    "        l = int((width - 6 - len(title)) / 2)\n",
    "        print(\"*\" * 3 + \" \" * l + title + \" \" * l + \"*\" * 3)\n",
    "        print(\"*\" * 3 + \" \" * (width - 6) + \"*\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a72b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_for_account_id_monkey_patch(\n",
    "    *,\n",
    "    total: int = 10_000,\n",
    "    step: int = 1000,\n",
    "    curr_check_shift: Optional[timedelta] = None,\n",
    ") -> Callable[\n",
    "    [int, Optional[Union[int, str]], Optional[Union[int, str]]],\n",
    "    Tuple[Optional[int], Optional[datetime]],\n",
    "]:\n",
    "    def _get_count_for_account_id_monkey_patch(\n",
    "        *,\n",
    "        total: int = total,\n",
    "        step: int = step,\n",
    "        curr_check_shift: Optional[timedelta] = curr_check_shift,\n",
    "    ) -> Tuple[Optional[int], Optional[datetime]]:\n",
    "        if curr_check_shift is None:\n",
    "            curr_check_shift = timedelta(seconds=-3)\n",
    "\n",
    "        yield (None, None)\n",
    "\n",
    "        for i in range(0, total, step):\n",
    "            yield (i, datetime.utcnow() + curr_check_shift)\n",
    "\n",
    "        while True:\n",
    "            yield (total, datetime.utcnow() + curr_check_shift)\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    def _iterate_get_count_for_account_id_monkey_patch(\n",
    "        account_id: int,\n",
    "        model_id: Optional[Union[int, str]],\n",
    "        d=d,\n",
    "    ):\n",
    "        k = (account_id, model_id)\n",
    "        if (account_id, model_id) not in d:\n",
    "            d[k] = _get_count_for_account_id_monkey_patch()\n",
    "\n",
    "        return next(d[k])\n",
    "\n",
    "    return _iterate_get_count_for_account_id_monkey_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62884812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    curr_count\n",
       "0            0\n",
       "1         1000\n",
       "2         2000\n",
       "3         3000\n",
       "4         4000\n",
       "5         5000\n",
       "6         6000\n",
       "7         7000\n",
       "8         8000\n",
       "9         9000\n",
       "10       10000\n",
       "11       10000\n",
       "12       10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = get_count_for_account_id_monkey_patch(curr_check_shift=timedelta(seconds=10))\n",
    "\n",
    "count, timestampt = f(12345, None)\n",
    "assert count == None, count\n",
    "assert timestampt == None, timestampt\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [f(12345, None) for _ in range(13)], columns=[\"curr_count\", \"timestamp\"]\n",
    ")\n",
    "display(df[\"curr_count\"].to_frame())\n",
    "\n",
    "assert df[\"curr_count\"].to_list() == [1000 * i for i in range(10)] + [10_000] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73b4db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   curr_count\n",
       "0           0\n",
       "1        1500\n",
       "2        3000\n",
       "3        4500\n",
       "4        4501\n",
       "5        4501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = get_count_for_account_id_monkey_patch(\n",
    "    curr_check_shift=timedelta(seconds=10), total=4501, step=1500\n",
    ")\n",
    "\n",
    "count, timestampt = f(12345, None)\n",
    "assert count == None, count\n",
    "assert timestampt == None, timestampt\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [f(12345, None) for _ in range(6)], columns=[\"curr_count\", \"timestamp\"]\n",
    ")\n",
    "display(df[\"curr_count\"].to_frame())\n",
    "\n",
    "assert df[\"curr_count\"].to_list() == [1500 * i for i in range(4)] + [4501] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319c18bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infobip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_user_for_testing(username=\"infobip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024c7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def monkeypatch_clickhouse(\n",
    "    curr_check_shift: Optional[timedelta] = None,\n",
    "    total: int = 10_000,\n",
    "    step: int = 1_000,\n",
    ") -> None:\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_for_account_id\",\n",
    "            get_count_for_account_id_monkey_patch(\n",
    "                curr_check_shift=curr_check_shift,\n",
    "                total=total,\n",
    "                step=step,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(42)\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_all_person_ids_for_account_id\",\n",
    "            lambda account_id, model_id: pd.Series(\n",
    "                rng.integers(low=1_000_000, high=10_000_000, size=7), name=\"PersonId\"\n",
    "            ),\n",
    "        )\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1ded22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    curr_count\n",
       "0            0\n",
       "1         1000\n",
       "2         2000\n",
       "3         3000\n",
       "4         4000\n",
       "5         5000\n",
       "6         6000\n",
       "7         7000\n",
       "8         8000\n",
       "9         9000\n",
       "10       10000\n",
       "11       10000\n",
       "12       10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7965604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6891143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4949905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4897137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8727381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1773510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PersonId\n",
       "0   1803258\n",
       "1   7965604\n",
       "2   6891143\n",
       "3   4949905\n",
       "4   4897137\n",
       "5   8727381\n",
       "6   1773510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with monkeypatch_clickhouse():\n",
    "    get_count_for_account_id(account_id=12345, model_id=None)\n",
    "    xs = [get_count_for_account_id(account_id=12345, model_id=None) for _ in range(13)]\n",
    "\n",
    "    pd.DataFrame(xs)\n",
    "    df = pd.DataFrame(xs, columns=[\"curr_count\", \"timestamp\"])\n",
    "    display(df[\"curr_count\"].to_frame())\n",
    "\n",
    "    person_ids = get_all_person_ids_for_account_id(account_id=12345, model_id=None)\n",
    "    display(person_ids.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf2ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def json_datetime_sec_encoder(dt: datetime) -> str:\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.fromisoformat(\"2023-01-01T12:34:56.789012\")\n",
    "expected = \"2023-01-01T12:34:56\"\n",
    "actual = json_datetime_sec_encoder(dt)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58c8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class LogMessage(BaseModel):\n",
    "    \"\"\"\n",
    "    Info, error and warning messages\n",
    "    \"\"\"\n",
    "\n",
    "    level: NonNegativeInt = Field(10, example=10, description=\"level of the message\")\n",
    "    timestamp: datetime = Field(None, description=\"timestamp\")\n",
    "    message: str = Field(..., example=\"something went wrong\", description=\"message\")\n",
    "\n",
    "    original_message: Optional[BaseModel] = Field(...)\n",
    "\n",
    "    @root_validator\n",
    "    def number_validator(cls, values: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        if values[\"timestamp\"] is None:\n",
    "            values[\"timestamp\"] = datetime.now()\n",
    "\n",
    "        return values\n",
    "\n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            datetime: json_datetime_sec_encoder,\n",
    "        }\n",
    "        validate_assignment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b3f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeMessage(BaseModel):\n",
    "    a: int = 12\n",
    "    b: str = \"hello\"\n",
    "\n",
    "\n",
    "original_message = SomeMessage()\n",
    "\n",
    "msg = LogMessage(\n",
    "    level=logging.INFO,\n",
    "    timestamp=\"2021-03-28T00:34:08\",\n",
    "    message=\"something went wrong\",\n",
    "    original_message=original_message,\n",
    ")\n",
    "\n",
    "actual = msg.json()\n",
    "expected = '{\"level\": 20, \"timestamp\": \"2021-03-28T00:34:08\", \"message\": \"something went wrong\", \"original_message\": {\"a\": 12, \"b\": \"hello\"}}'\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4dde077",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = LogMessage(\n",
    "    message=\"something went wrong\",\n",
    "    original_message=original_message,\n",
    ")\n",
    "assert msg.timestamp is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc65518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def add_logging(\n",
    "    app: FastKafka,\n",
    "    *,\n",
    "    username: str = \"infobip\",\n",
    ") -> None:\n",
    "    @app.produces(topic=f\"{username}_logger\")  # type: ignore\n",
    "    async def to_logger(\n",
    "        msg: LogMessage,\n",
    "        key: Optional[Union[bytes, str]] = None,\n",
    "        #     ) -> KafkaEvent[LogMessage]:\n",
    "        #         print(f\"to_logger({msg})\")\n",
    "        #         k = key.encode(\"utf-8\") if isinstance(key, str) else key\n",
    "        #         return KafkaEvent(message=msg, key=k)\n",
    "    ) -> LogMessage:\n",
    "        print(f\"to_logger({msg})\")\n",
    "        k = key.encode(\"utf-8\") if isinstance(key, str) else key\n",
    "        return msg\n",
    "\n",
    "    async def log(\n",
    "        org_msg: BaseModel,\n",
    "        msg: LogMessage,\n",
    "        key: Optional[Union[bytes, str]] = None,\n",
    "        *,\n",
    "        level: int,\n",
    "        app: FastKafka = app,\n",
    "    ) -> None:\n",
    "        log_msg = LogMessage(message=msg, level=10, key=key, original_message=org_msg)\n",
    "        await app.to_logger(log_msg)\n",
    "        logger.info(f\"{msg} while processing {org_msg}.\")\n",
    "\n",
    "    async def info(\n",
    "        org_msg: BaseModel,\n",
    "        msg: LogMessage,\n",
    "        key: Optional[Union[bytes, str]] = None,\n",
    "        *,\n",
    "        app: FastKafka = app,\n",
    "    ) -> None:\n",
    "        await app.log(org_msg, msg=msg, key=key, level=10)\n",
    "\n",
    "    async def warning(\n",
    "        org_msg: BaseModel,\n",
    "        msg: LogMessage,\n",
    "        key: Optional[Union[bytes, str]] = None,\n",
    "        *,\n",
    "        app: FastKafka = app,\n",
    "    ) -> None:\n",
    "        await app.log(org_msg, msg=msg, key=key, level=20)\n",
    "\n",
    "    async def error(\n",
    "        org_msg: BaseModel,\n",
    "        msg: LogMessage,\n",
    "        key: Optional[Union[bytes, str]] = None,\n",
    "        *,\n",
    "        app: FastKafka = app,\n",
    "    ) -> None:\n",
    "        await app.log(org_msg, msg=msg, key=key, level=30)\n",
    "\n",
    "#     app.to_logger = to_logger\n",
    "    app.log = log\n",
    "    app.info = info\n",
    "    app.warning = warning\n",
    "    app.error = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d135c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "*** app.to_logger(level=20 timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) message='something went wrong' original_message=SomeMessage(a=12, b='hello')) ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=20 timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) message='something went wrong' original_message=SomeMessage(a=12, b='hello'))\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                                                 app.info(a=12 b='hello')                                                                 ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 54, 7, 8156) message='something went wrong again' original_message=SomeMessage(a=12, b='hello'))\n",
      "[INFO] __main__: something went wrong again while processing a=12 b='hello'.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "kafka_brokers = {\n",
    "    \"localhost\": {\n",
    "        \"url\": \"localhost\",\n",
    "        \"description\": \"localhost kafka broker\",\n",
    "        \"port\": \"9092\",\n",
    "    }\n",
    "}\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers)\n",
    "\n",
    "add_logging(app)\n",
    "\n",
    "tester = Tester(app)\n",
    "\n",
    "\n",
    "class SomeMessage(BaseModel):\n",
    "    a: int = 12\n",
    "    b: str = \"hello\"\n",
    "\n",
    "\n",
    "original_message = SomeMessage()\n",
    "\n",
    "msg = LogMessage(\n",
    "    level=logging.INFO,\n",
    "    timestamp=\"2021-03-28T00:34:08\",\n",
    "    message=\"something went wrong\",\n",
    "    original_message=original_message,\n",
    ")\n",
    "\n",
    "async with tester:\n",
    "    heading(f\"app.to_logger({msg})\")\n",
    "    msg = await app.to_logger(msg)\n",
    "\n",
    "    await tester.awaited_mocks.on_infobip_logger.assert_awaited(timeout=5)\n",
    "\n",
    "\n",
    "async with tester:\n",
    "    heading(f\"app.info({original_message})\")\n",
    "    msg = await app.info(original_message, \"something went wrong again\")\n",
    "\n",
    "    await tester.awaited_mocks.on_infobip_logger.assert_awaited(timeout=5)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0cdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ModelType(str, Enum):\n",
    "    churn = \"churn\"\n",
    "    propensity_to_buy = \"propensity_to_buy\"\n",
    "\n",
    "\n",
    "class ModelTrainingRequest(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ..., description=\"Model type, only 'churn' is supported right now\"\n",
    "    )\n",
    "    total_no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"approximate total number of records (rows) to be ingested\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b56dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_request = ModelTrainingRequest(\n",
    "    AccountId=12345,\n",
    "    OccurredTime=\"2021-03-28T00:34:08\",\n",
    "    model_type=\"churn\",\n",
    "    total_no_of_records=1000,\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ModelId\": null, \"model_type\": \"churn\", \"total_no_of_records\": 1000}'\n",
    "actual = model_training_request.json()\n",
    "\n",
    "assert actual == expected, actual\n",
    "\n",
    "parsed = ModelTrainingRequest.parse_raw(actual)\n",
    "assert parsed == model_training_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class EventData(BaseModel):\n",
    "    \"\"\"\n",
    "    A sequence of events for a fixed account_id\n",
    "    \"\"\"\n",
    "\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ApplicationId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"TestApplicationId\",\n",
    "        description=\"Id of the application in case there is more than one for the AccountId\",\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "\n",
    "    DefinitionId: str = Field(\n",
    "        ...,\n",
    "        example=\"appLaunch\",\n",
    "        description=\"name of the event\",\n",
    "        min_length=1,\n",
    "    )\n",
    "    OccurredTime: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"local time of the event\",\n",
    "    )\n",
    "    OccurredTimeTicks: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1616891648496,\n",
    "        description=\"local time of the event as the number of ticks\",\n",
    "    )\n",
    "    PersonId: NonNegativeInt = Field(\n",
    "        ..., example=12345678, description=\"ID of a person\"\n",
    "    )\n",
    "\n",
    "\n",
    "class RealtimeData(EventData):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "348fb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = EventData(\n",
    "    AccountId=12345,\n",
    "    DefinitionId=\"BigButton\",\n",
    "    PersonId=123456789,\n",
    "    OccurredTime=\"2021-03-28T00:34:08\",\n",
    "    OccurredTimeTicks=1616891648496,\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ApplicationId\": null, \"ModelId\": null, \"DefinitionId\": \"BigButton\", \"OccurredTime\": \"2021-03-28T00:34:08\", \"OccurredTimeTicks\": 1616891648496, \"PersonId\": 123456789}'\n",
    "actual = event_data.json()\n",
    "\n",
    "assert actual == expected, actual\n",
    "\n",
    "parsed = EventData.parse_raw(actual)\n",
    "assert parsed == event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5771b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TrainingDataStatus(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "\n",
    "    no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=12_345,\n",
    "        description=\"number of records (rows) ingested\",\n",
    "    )\n",
    "    total_no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"total number of records (rows) to be ingested\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92abd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_status = TrainingDataStatus(\n",
    "    AccountId=12345,\n",
    "    no_of_records=23,\n",
    "    total_no_of_records=54,\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ModelId\": null, \"no_of_records\": 23, \"total_no_of_records\": 54}'\n",
    "actual = training_data_status.json()\n",
    "\n",
    "assert actual == expected, actual\n",
    "\n",
    "parsed = TrainingDataStatus.parse_raw(actual)\n",
    "assert parsed == training_data_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8989ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TrainingModelStart(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ..., description=\"Model type, only 'churn' is supported right now\"\n",
    "    )\n",
    "    no_of_records: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=1_000_000,\n",
    "        description=\"number of records (rows) in the DB used for training\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef347339",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_start = TrainingModelStart(\n",
    "    AccountId=12345,\n",
    "    model_type=\"churn\",\n",
    "    no_of_records=100,\n",
    ")\n",
    "\n",
    "expected = (\n",
    "    '{\"AccountId\": 12345, \"ModelId\": null, \"model_type\": \"churn\", \"no_of_records\": 100}'\n",
    ")\n",
    "actual = training_model_start.json()\n",
    "\n",
    "assert actual == expected, actual\n",
    "\n",
    "parsed = TrainingModelStart.parse_raw(actual)\n",
    "assert parsed == training_model_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50815b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_key(msg: BaseModel, attrs: Optional[List[str]] = None) -> bytes:\n",
    "    if attrs is None:\n",
    "        attrs = [\"AccountId\", \"ModelId\"]\n",
    "\n",
    "    sx = [\n",
    "        f\"{attr}='{getattr(msg, attr)}'\" if hasattr(msg, attr) else \"\" for attr in attrs\n",
    "    ]\n",
    "\n",
    "    return \", \".join(sx).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b62f398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_start = TrainingModelStart(\n",
    "    AccountId=12345,\n",
    "    model_type=\"churn\",\n",
    "    no_of_records=100,\n",
    ")\n",
    "\n",
    "actual = get_key(training_model_start)\n",
    "assert actual == b\"AccountId='12345', ModelId='None'\", actual\n",
    "\n",
    "actual = get_key(training_model_start, [\"model_type\"])\n",
    "assert actual == b\"model_type='churn'\", actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f3413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b521650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self, *, limit: int, timeout: int, abort_after: int):\n",
    "        self._limit = limit\n",
    "        self._timeout = timeout\n",
    "        self._abort_after = abort_after\n",
    "        self._count: Optional[int] = None\n",
    "        self._last_updated: Optional[datetime] = None\n",
    "        self._sterted_at: datetime = datetime.now()\n",
    "\n",
    "    def update(self, count: int) -> bool:\n",
    "        if self._count != count:\n",
    "            self._count = count\n",
    "            self._last_updated = datetime.now()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def finished(self) -> bool:\n",
    "        if self._count is not None:\n",
    "            return (self._count >= self._limit) or (\n",
    "                datetime.now() - self._last_updated  # type: ignore\n",
    "            ) > timedelta(seconds=self._timeout)\n",
    "        else:\n",
    "            return self.aborted()\n",
    "\n",
    "    def aborted(self) -> bool:\n",
    "        return self._count is None and (datetime.now() - self._sterted_at) > timedelta(\n",
    "            seconds=self._abort_after\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6990c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(limit=10, timeout=5, abort_after=10)\n",
    "\n",
    "assert not tracker.finished()\n",
    "\n",
    "assert tracker.update(9)\n",
    "assert not tracker.update(9)\n",
    "\n",
    "assert not tracker.finished()\n",
    "\n",
    "assert tracker.update(10)\n",
    "\n",
    "assert tracker.finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24371b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(limit=10, timeout=1, abort_after=10)\n",
    "\n",
    "assert not tracker.finished()\n",
    "\n",
    "tracker.update(9)\n",
    "\n",
    "assert not tracker.finished()\n",
    "\n",
    "await asyncio.sleep(1.1)\n",
    "\n",
    "assert tracker.finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d9d8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(limit=10, timeout=1, abort_after=2)\n",
    "await asyncio.sleep(1.1)\n",
    "\n",
    "assert not tracker.finished()\n",
    "assert not tracker.aborted()\n",
    "\n",
    "await asyncio.sleep(1.1)\n",
    "\n",
    "assert tracker.finished()\n",
    "assert tracker.aborted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69d73eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_process_start_training_data(\n",
    "    app: FastKafka,\n",
    "    *,\n",
    "    username: str = \"infobip\",\n",
    "    stop_on_no_change_interval: int = 60,\n",
    "    abort_on_no_change_interval: int = 120,\n",
    "    sleep_interval: int = 5,\n",
    ") -> None:\n",
    "    @app.produces(topic=f\"{username}_training_data_status\")  # type: ignore\n",
    "    async def to_training_data_status(\n",
    "        training_data_status: TrainingDataStatus,\n",
    "    ) -> TrainingDataStatus:\n",
    "        print(f\"to_training_data_status({training_data_status})\")\n",
    "        return training_data_status\n",
    "\n",
    "    @app.produces(topic=f\"{username}_training_model_start\")  # type: ignore\n",
    "    async def to_training_model_start(\n",
    "        training_model_start: TrainingModelStart,\n",
    "    ) -> TrainingModelStart:\n",
    "        print(f\"to_training_model_start({training_model_start})\")\n",
    "        return training_model_start\n",
    "\n",
    "#     app.to_training_data_status = to_training_data_status\n",
    "#     app.to_training_model_start = to_training_model_start\n",
    "\n",
    "    @app.consumes(topic=f\"{username}_start_training_data\")  # type: ignore\n",
    "    async def on_start_training_data(\n",
    "        msg: ModelTrainingRequest, app: FastKafka = app\n",
    "    ) -> None:\n",
    "        await app.info(msg, f\"on_start_training_data() starting...\")\n",
    "\n",
    "        account_id = msg.AccountId\n",
    "        model_id = msg.ModelId\n",
    "        total_no_of_records = msg.total_no_of_records\n",
    "\n",
    "        tracker = Tracker(\n",
    "            limit=total_no_of_records,\n",
    "            timeout=stop_on_no_change_interval,\n",
    "            abort_after=abort_on_no_change_interval,\n",
    "        )\n",
    "\n",
    "        while not tracker.finished():\n",
    "            curr_count, timestamp = get_count_for_account_id(\n",
    "                account_id=account_id,\n",
    "                model_id=model_id,\n",
    "            )\n",
    "            if curr_count is not None:\n",
    "                if tracker.update(curr_count):\n",
    "                    training_data_status = TrainingDataStatus(\n",
    "                        no_of_records=curr_count, **msg.dict()\n",
    "                    )\n",
    "                    await app.to_training_data_status(training_data_status)\n",
    "            else:\n",
    "                await app.warning(\n",
    "                    msg,\n",
    "                    f\"on_start_training_data(): no data yet received in the database.\",\n",
    "                )\n",
    "\n",
    "            await asyncio.sleep(sleep_interval)\n",
    "\n",
    "        if tracker.aborted():\n",
    "            await app.error(msg, f\"on_start_training_data(): data retrieval aborted!\")\n",
    "        else:\n",
    "            # trigger model training start\n",
    "            training_model_start = TrainingModelStart(\n",
    "                no_of_records=curr_count, **msg.dict()\n",
    "            )\n",
    "            await app.to_training_model_start(training_model_start)\n",
    "\n",
    "            await app.info(msg, f\"on_start_training_data(): finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38166841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_start_training_data']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_data_status']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_start']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***            tester.to_infobip_start_training_data(AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123)            ***\n",
      "***                                                                                                                                                          ***\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                           tester.awaited_mocks.on_infobip_training_data_status.assert_called()                                           ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 55, 13, 908878) message='on_start_training_data() starting...' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data() starting... while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 55, 13, 909917) message='on_start_training_data(): no data yet received in the database.' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data(): no data yet received in the database. while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=0 total_no_of_records=5123)\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                           tester.awaited_mocks.on_infobip_training_model_start.assert_called()                                           ***\n",
      "***                                                                                                                                                          ***\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=1500 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=3000 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=4500 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=5000 total_no_of_records=5123)\n",
      "to_training_model_start(AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=5000)\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 55, 21, 912468) message='on_start_training_data(): finished' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data(): finished while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                                             check final training_data_status                                                             ***\n",
      "***                                                                                                                                                          ***\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "kafka_brokers = {\n",
    "    \"localhost\": {\n",
    "        \"url\": \"localhost\",\n",
    "        \"description\": \"localhost kafka broker\",\n",
    "        \"port\": \"9092\",\n",
    "    }\n",
    "}\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers)\n",
    "\n",
    "add_logging(app)\n",
    "add_process_start_training_data(\n",
    "    app, stop_on_no_change_interval=3, sleep_interval=1, abort_on_no_change_interval=100\n",
    ")\n",
    "\n",
    "tester = Tester(app)\n",
    "\n",
    "total_no_of_records = 5000\n",
    "\n",
    "with monkeypatch_clickhouse(\n",
    "    total=total_no_of_records,\n",
    "    step=1500,\n",
    "):\n",
    "    async with tester:\n",
    "        model_training_request = ModelTrainingRequest(\n",
    "            AccountId=12345,\n",
    "            OccurredTime=\"2021-03-28T00:34:08\",\n",
    "            model_type=\"churn\",\n",
    "            total_no_of_records=total_no_of_records + 123,\n",
    "        )\n",
    "        heading(f\"tester.to_infobip_start_training_data({model_training_request})\")\n",
    "\n",
    "        await tester.to_infobip_start_training_data(model_training_request)\n",
    "\n",
    "        heading(\"tester.awaited_mocks.on_infobip_training_data_status.assert_called()\")\n",
    "\n",
    "        await tester.awaited_mocks.on_infobip_training_data_status.assert_called(\n",
    "            timeout=10\n",
    "        )\n",
    "\n",
    "        heading(\"tester.awaited_mocks.on_infobip_training_model_start.assert_called()\")\n",
    "        await tester.awaited_mocks.on_infobip_training_model_start.assert_called(\n",
    "            timeout=20\n",
    "        )\n",
    "\n",
    "        heading(\"check final training_data_status\")\n",
    "\n",
    "        training_data_statuses = (\n",
    "            tester.awaited_mocks.on_infobip_training_data_status._o.await_args_list\n",
    "        )\n",
    "        final_training_data_status = training_data_statuses[-1]\n",
    "\n",
    "        assert len(training_data_statuses) == 5, training_data_statuses\n",
    "        expected = unittest.mock.call(\n",
    "            TrainingDataStatus(\n",
    "                AccountId=12345,\n",
    "                no_of_records=total_no_of_records,\n",
    "                total_no_of_records=total_no_of_records + 123,\n",
    "            )\n",
    "        )\n",
    "        assert final_training_data_status == expected, training_data_statuses\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85428b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TrainingModelStatus(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "\n",
    "    current_step: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=0,\n",
    "        description=\"number of records (rows) ingested\",\n",
    "    )\n",
    "    current_step_percentage: float = Field(\n",
    "        ...,\n",
    "        example=0.21,\n",
    "        description=\"the percentage of the current step completed\",\n",
    "    )\n",
    "    total_no_of_steps: NonNegativeInt = Field(\n",
    "        ...,\n",
    "        example=20,\n",
    "        description=\"total number of steps for training the model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92077216",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_status = TrainingModelStatus(\n",
    "    AccountId=12345,\n",
    "    current_step=1,\n",
    "    current_step_percentage=0.21,\n",
    "    total_no_of_steps=20,\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ModelId\": null, \"current_step\": 1, \"current_step_percentage\": 0.21, \"total_no_of_steps\": 20}'\n",
    "actual = training_model_status.json()\n",
    "\n",
    "actual\n",
    "\n",
    "assert actual == expected\n",
    "\n",
    "parsed = TrainingModelStatus.parse_raw(actual)\n",
    "assert parsed == training_model_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c68eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ModelMetrics(BaseModel):\n",
    "    \"\"\"The standard metrics for classification models.\n",
    "\n",
    "    The most important metrics is AUC for unbalanced classes such as churn. Metrics such as\n",
    "    accuracy are not very useful since they are easily maximized by outputting the most common\n",
    "    class all the time.\n",
    "    \"\"\"\n",
    "\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "\n",
    "    timestamp: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"UTC time when the model was trained\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ...,\n",
    "        example=\"churn\",\n",
    "        description=\"Name of the model used (churn, propensity to buy)\",\n",
    "    )\n",
    "\n",
    "    auc: float = Field(\n",
    "        ..., example=0.91, description=\"Area under ROC curve\", ge=0.0, le=1.0\n",
    "    )\n",
    "    f1: float = Field(..., example=0.89, description=\"F-1 score\", ge=0.0, le=1.0)\n",
    "    precission: float = Field(\n",
    "        ..., example=0.84, description=\"precission\", ge=0.0, le=1.0\n",
    "    )\n",
    "    recall: float = Field(..., example=0.82, description=\"recall\", ge=0.0, le=1.0)\n",
    "    accuracy: float = Field(..., example=0.82, description=\"accuracy\", ge=0.0, le=1.0)\n",
    "\n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            datetime: json_datetime_sec_encoder,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f0aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    AccountId=12345,\n",
    "    timestamp=\"2021-03-28T00:34:08\",\n",
    "    model_type=\"churn\",\n",
    "    auc=0.95,\n",
    "    recall=0.94,\n",
    "    precission=0.98,\n",
    "    accuracy=0.99,\n",
    "    f1=2 * 0.94 * 0.98 / (0.94 + 0.98),\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ModelId\": null, \"timestamp\": \"2021-03-28T00:34:08\", \"model_type\": \"churn\", \"auc\": 0.95, \"f1\": 0.9595833333333332, \"precission\": 0.98, \"recall\": 0.94, \"accuracy\": 0.99}'\n",
    "actual = model_metrics.json()\n",
    "\n",
    "actual\n",
    "\n",
    "assert actual == expected\n",
    "\n",
    "parsed = ModelMetrics.parse_raw(actual)\n",
    "assert parsed == model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50680121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_process_training_model_start(\n",
    "    app: FastKafka,\n",
    "    *,\n",
    "    username: str = \"infobip\",\n",
    "    total_no_of_steps: int = 10,\n",
    "    substep_interval: Union[int, float] = 2,\n",
    ") -> None:\n",
    "    @app.produces(topic=f\"{username}_training_model_status\")  # type: ignore\n",
    "    async def to_training_model_status(\n",
    "        training_model_status: TrainingModelStatus,\n",
    "    ) -> TrainingModelStatus:\n",
    "        print(f\"to_training_model_status({training_model_status})\")\n",
    "        return training_model_status\n",
    "\n",
    "    @app.produces(topic=f\"{username}_model_metrics\")  # type: ignore\n",
    "    async def to_model_metrics(\n",
    "        model_metrics: ModelMetrics,\n",
    "    ) -> ModelMetrics:\n",
    "        print(f\"to_model_metrics({model_metrics})\")\n",
    "        return model_metrics\n",
    "\n",
    "#     app.to_training_model_status = to_training_model_status\n",
    "#     app.to_model_metrics = to_model_metrics\n",
    "\n",
    "    @app.consumes(topic=f\"{username}_training_model_start\")  # type: ignore\n",
    "    async def on_training_model_start(\n",
    "        msg: TrainingModelStart, app: FastKafka = app\n",
    "    ) -> None:\n",
    "        await app.info(msg, f\"on_training_model_start() starting\")\n",
    "\n",
    "        AccountId = msg.AccountId\n",
    "        ModelId = msg.ModelId\n",
    "        model_type = msg.model_type\n",
    "\n",
    "        for current_step in range(total_no_of_steps):\n",
    "            for current_step_percentage in [0.0, 0.2, 0.5, 0.75, 1.0]:\n",
    "                training_model_status = TrainingModelStatus(\n",
    "                    AccountId=AccountId,\n",
    "                    ModelId=ModelId,\n",
    "                    current_step=current_step,\n",
    "                    current_step_percentage=current_step_percentage,\n",
    "                    total_no_of_steps=total_no_of_steps,\n",
    "                )\n",
    "                await app.to_training_model_status(training_model_status)\n",
    "\n",
    "                await asyncio.sleep(substep_interval)\n",
    "\n",
    "        model_metrics = ModelMetrics(\n",
    "            AccountId=AccountId,\n",
    "            ModelId=ModelId,\n",
    "            model_type=model_type,\n",
    "            timestamp=datetime.now(),\n",
    "            auc=0.951,\n",
    "            recall=0.944,\n",
    "            precission=0.983,\n",
    "            accuracy=0.992,\n",
    "            f1=f\"{2*0.944*0.983/(0.944+0.983):0.3f}\",\n",
    "        )\n",
    "        await app.to_model_metrics(model_metrics)\n",
    "\n",
    "        await app.info(msg, f\"on_training_model_start() finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ca2eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_start_training_data']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_start']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_data_status']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_start']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_status']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_model_metrics']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***              tester.to_infobip_training_model_start(AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=1000)              ***\n",
      "***                                                                                                                                                          ***\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                          tester.awaited_mocks.on_infobip_training_model_status.assert_called()                                          ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 55, 53, 200948) message='on_training_model_start() starting' original_message=TrainingModelStart(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, no_of_records=1000))\n",
      "[INFO] __main__: on_training_model_start() starting while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_model_metrics(AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 7, 55, 53, 712684) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992)\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 55, 53, 712813) message='on_training_model_start() finished' original_message=TrainingModelStart(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, no_of_records=1000))\n",
      "[INFO] __main__: on_training_model_start() finished while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=1000.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                          tester.awaited_mocks.on_infobip_training_model_status.assert_called()                                          ***\n",
      "***                                                                                                                                                          ***\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                                             check final training_model_start                                                             ***\n",
      "***                                                                                                                                                          ***\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "app = FastKafka(kafka_brokers=kafka_brokers)\n",
    "\n",
    "add_logging(app)\n",
    "add_process_start_training_data(app)\n",
    "total_no_of_steps = 10\n",
    "add_process_training_model_start(\n",
    "    app, total_no_of_steps=total_no_of_steps, substep_interval=0.01\n",
    ")\n",
    "\n",
    "tester = Tester(app)\n",
    "\n",
    "async with tester:\n",
    "    training_model_start = TrainingModelStart(\n",
    "        AccountId=12345, no_of_records=1_000, model_type=\"churn\"\n",
    "    )\n",
    "\n",
    "    heading(f\"tester.to_infobip_training_model_start({training_model_start})\")\n",
    "\n",
    "    await tester.to_infobip_training_model_start(training_model_start)\n",
    "\n",
    "    heading(f\"tester.awaited_mocks.on_infobip_training_model_status.assert_called()\")\n",
    "\n",
    "    await tester.awaited_mocks.on_infobip_training_model_status.assert_called(\n",
    "        timeout=10\n",
    "    )\n",
    "\n",
    "    heading(f\"tester.awaited_mocks.on_infobip_training_model_status.assert_called()\")\n",
    "\n",
    "    await tester.awaited_mocks.on_infobip_model_metrics.assert_called(timeout=10)\n",
    "\n",
    "    heading(\"check final training_model_start\")\n",
    "\n",
    "    training_model_status = (\n",
    "        tester.awaited_mocks.on_infobip_training_model_status._o.await_args_list\n",
    "    )\n",
    "    final_training_model_status = training_model_status[-1]\n",
    "\n",
    "    assert len(training_model_status) == 5 * total_no_of_steps, training_model_status\n",
    "    expected = unittest.mock.call(\n",
    "        TrainingModelStatus(\n",
    "            AccountId=12345,\n",
    "            current_step=total_no_of_steps - 1,\n",
    "            current_step_percentage=1.0,\n",
    "            total_no_of_steps=total_no_of_steps,\n",
    "        )\n",
    "    )\n",
    "    assert final_training_model_status == expected, training_model_status\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55242d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    AccountId: NonNegativeInt = Field(\n",
    "        ..., example=202020, description=\"ID of an account\"\n",
    "    )\n",
    "    ModelId: Optional[str] = Field(\n",
    "        default=None,\n",
    "        example=\"ChurnModelForDrivers\",\n",
    "        description=\"User supplied ID of the model trained\",\n",
    "    )\n",
    "\n",
    "    PersonId: NonNegativeInt = Field(\n",
    "        ..., example=12345678, description=\"ID of a person\"\n",
    "    )\n",
    "    prediction_time: datetime = Field(\n",
    "        ...,\n",
    "        example=\"2021-03-28T00:34:08\",\n",
    "        description=\"UTC time of prediction\",\n",
    "    )\n",
    "    model_type: ModelType = Field(\n",
    "        ...,\n",
    "        example=\"churn\",\n",
    "        description=\"Name of the model used (churn, propensity to buy)\",\n",
    "    )\n",
    "    score: float = Field(\n",
    "        ...,\n",
    "        example=0.4321,\n",
    "        description=\"Prediction score (e.g. the probability of churn in the next 28 days)\",\n",
    "        ge=0.0,\n",
    "        le=1.0,\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            datetime: json_datetime_sec_encoder,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "292866e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Prediction(\n",
    "    AccountId=12345,\n",
    "    PersonId=123456789,\n",
    "    prediction_time=\"2021-03-28T00:34:08\",\n",
    "    model_type=\"churn\",\n",
    "    score=0.873,\n",
    ")\n",
    "\n",
    "expected = '{\"AccountId\": 12345, \"ModelId\": null, \"PersonId\": 123456789, \"prediction_time\": \"2021-03-28T00:34:08\", \"model_type\": \"churn\", \"score\": 0.873}'\n",
    "actual = prediction.json()\n",
    "\n",
    "actual\n",
    "\n",
    "assert actual == expected\n",
    "\n",
    "parsed = Prediction.parse_raw(actual)\n",
    "assert parsed == prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc26b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_predictions(\n",
    "    app: FastKafka,\n",
    "    *,\n",
    "    username: str = \"infobip\",\n",
    ") -> None:\n",
    "    @app.produces(topic=f\"{username}_prediction\")  # type: ignore\n",
    "    async def to_prediction(\n",
    "        prediction: Prediction,\n",
    "    ) -> Prediction:\n",
    "        return prediction\n",
    "\n",
    "    app.to_prediction = to_prediction\n",
    "\n",
    "    @app.consumes(topic=f\"{username}_model_metrics\")  # type: ignore\n",
    "    async def on_model_metrics(msg: ModelMetrics, app: FastKafka = app) -> None:\n",
    "        await app.info(msg, \"on_model_metrics() starting\")\n",
    "\n",
    "        AccountId = msg.AccountId\n",
    "        ModelId = msg.ModelId\n",
    "        model_type = msg.model_type\n",
    "        prediction_time = datetime.now()\n",
    "\n",
    "        person_ids = get_all_person_ids_for_account_id(\n",
    "            account_id=AccountId, model_id=ModelId\n",
    "        )\n",
    "\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "        await app.info(msg, f\"Sending predictions for {len(person_ids):,d} PersonIds\")\n",
    "        t0 = datetime.now()\n",
    "        for PersonId in person_ids:\n",
    "            prediction = Prediction(\n",
    "                AccountId=AccountId,\n",
    "                ModelId=ModelId,\n",
    "                model_type=model_type,\n",
    "                prediction_time=prediction_time,\n",
    "                PersonId=PersonId,\n",
    "                score=rng.uniform(),\n",
    "            )\n",
    "            await to_prediction(prediction)\n",
    "        await app.info(\n",
    "            msg,\n",
    "            f\"Sending predictions for {len(person_ids):,d} PersonIds finished in {datetime.now()-t0}.\",\n",
    "        )\n",
    "\n",
    "        await app.info(msg, \"on_model_metrics() finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "201799e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_model_metrics']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_prediction']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***tester.to_infobip_model_metrics(AccountId=12345 ModelId=None timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) model_type=<ModelType.churn: 'churn'> auc=0.95 f1=0.9595833333333332 precission=0.98 recall=0.94 accuracy=0.99)***\n",
      "***                                                                                                                                                          ***\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                                tester.awaited_mocks.on_infobip_prediction.assert_called()                                                ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 56, 17, 781255) message='on_model_metrics() starting' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8), model_type=<ModelType.churn: 'churn'>, auc=0.95, f1=0.9595833333333332, precission=0.98, recall=0.94, accuracy=0.99))\n",
      "[INFO] __main__: on_model_metrics() starting while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) model_type=<ModelType.churn: 'churn'> auc=0.95 f1=0.9595833333333332 precission=0.98 recall=0.94 accuracy=0.99.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 56, 17, 782312) message='Sending predictions for 7 PersonIds' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8), model_type=<ModelType.churn: 'churn'>, auc=0.95, f1=0.9595833333333332, precission=0.98, recall=0.94, accuracy=0.99))\n",
      "[INFO] __main__: Sending predictions for 7 PersonIds while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) model_type=<ModelType.churn: 'churn'> auc=0.95 f1=0.9595833333333332 precission=0.98 recall=0.94 accuracy=0.99.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 56, 17, 783690) message='Sending predictions for 7 PersonIds finished in 0:00:00.000512.' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8), model_type=<ModelType.churn: 'churn'>, auc=0.95, f1=0.9595833333333332, precission=0.98, recall=0.94, accuracy=0.99))\n",
      "[INFO] __main__: Sending predictions for 7 PersonIds finished in 0:00:00.000512. while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) model_type=<ModelType.churn: 'churn'> auc=0.95 f1=0.9595833333333332 precission=0.98 recall=0.94 accuracy=0.99.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 56, 17, 784454) message='on_model_metrics() finished' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8), model_type=<ModelType.churn: 'churn'>, auc=0.95, f1=0.9595833333333332, precission=0.98, recall=0.94, accuracy=0.99))\n",
      "[INFO] __main__: on_model_metrics() finished while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2021, 3, 28, 0, 34, 8) model_type=<ModelType.churn: 'churn'> auc=0.95 f1=0.9595833333333332 precission=0.98 recall=0.94 accuracy=0.99.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "kafka_brokers = {\n",
    "    \"localhost\": {\n",
    "        \"url\": \"localhost\",\n",
    "        \"description\": \"localhost kafka broker\",\n",
    "        \"port\": \"9092\",\n",
    "    }\n",
    "}\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers)\n",
    "\n",
    "add_logging(app)\n",
    "add_predictions(app)\n",
    "\n",
    "tester = Tester(app)\n",
    "\n",
    "total_no_of_records = 5000\n",
    "\n",
    "with monkeypatch_clickhouse(\n",
    "    total=total_no_of_records,\n",
    "    step=1500,\n",
    "):\n",
    "    async with tester:\n",
    "        model_metrics = ModelMetrics(\n",
    "            AccountId=12345,\n",
    "            timestamp=\"2021-03-28T00:34:08\",\n",
    "            model_type=\"churn\",\n",
    "            auc=0.95,\n",
    "            recall=0.94,\n",
    "            precission=0.98,\n",
    "            accuracy=0.99,\n",
    "            f1=2 * 0.94 * 0.98 / (0.94 + 0.98),\n",
    "        )\n",
    "\n",
    "        heading(f\"tester.to_infobip_model_metrics({model_metrics})\")\n",
    "\n",
    "        await tester.to_infobip_model_metrics(model_metrics)\n",
    "\n",
    "        heading(\"tester.awaited_mocks.on_infobip_prediction.assert_called()\")\n",
    "\n",
    "        await tester.awaited_mocks.on_infobip_prediction.assert_called(timeout=10)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18beb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _construct_kafka_brokers() -> Dict[str, Dict[str, Any]]:\n",
    "    url, port = aio_kafka_config[\"bootstrap_servers\"].split(\":\")\n",
    "\n",
    "    kafka_brokers = {\n",
    "        \"staging\": {\n",
    "            \"url\": \"kafka.staging.airt.ai\",\n",
    "            \"description\": \"Staging Kafka broker\",\n",
    "            \"port\": 9092,\n",
    "            \"protocol\": \"kafka-secure\",\n",
    "            \"security\": {\"type\": \"scramSha256\"},\n",
    "        },\n",
    "        \"production\": {\n",
    "            \"url\": \"pkc-1wvvj.westeurope.azure.confluent.cloud\",\n",
    "            \"description\": \"Production Kafka broker\",\n",
    "            \"port\": 9092,\n",
    "            \"protocol\": \"kafka-secure\",\n",
    "            \"security\": {\"type\": \"plain\"},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if (url != kafka_brokers[\"staging\"][\"url\"]) and (\n",
    "        url != kafka_brokers[\"production\"][\"url\"]\n",
    "    ):\n",
    "        kafka_brokers[\"dev\"] = {\n",
    "            \"url\": url,\n",
    "            \"description\": \"Development Kafka broker\",\n",
    "            \"port\": port,\n",
    "        }\n",
    "\n",
    "    return kafka_brokers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b6e6480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'staging': {'url': 'kafka.staging.airt.ai',\n",
       "  'description': 'Staging Kafka broker',\n",
       "  'port': 9092,\n",
       "  'protocol': 'kafka-secure',\n",
       "  'security': {'type': 'scramSha256'}},\n",
       " 'production': {'url': 'pkc-1wvvj.westeurope.azure.confluent.cloud',\n",
       "  'description': 'Production Kafka broker',\n",
       "  'port': 9092,\n",
       "  'protocol': 'kafka-secure',\n",
       "  'security': {'type': 'plain'}},\n",
       " 'dev': {'url': 'davor-redpanda',\n",
       "  'description': 'Development Kafka broker',\n",
       "  'port': '9092'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_construct_kafka_brokers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11184b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_fastkafka_application(\n",
    "    start_process_for_username: Optional[str] = \"infobip\",\n",
    ") -> FastKafka:\n",
    "    \"\"\"Create a FastKafka service\n",
    "\n",
    "    Args:\n",
    "        start_process_for_username: prefix for topics used\n",
    "\n",
    "    Returns:\n",
    "        A FastKafka application\n",
    "    \"\"\"\n",
    "\n",
    "    kafka_brokers = _construct_kafka_brokers()\n",
    "\n",
    "    exclude_keys = [\"bootstrap_servers\"]\n",
    "    kafka_config = {\n",
    "        k: aio_kafka_config[k]\n",
    "        for k in set(list(aio_kafka_config.keys())) - set(exclude_keys)\n",
    "    }\n",
    "\n",
    "    logger.info(f\"create_fastkafka_application(): {kafka_config=}\")\n",
    "\n",
    "    # global description\n",
    "    version = airt_service.__version__\n",
    "    contact = dict(name=\"airt.ai\", url=\"https://airt.ai\", email=\"info@airt.ai\")\n",
    "\n",
    "    app = FastKafka(\n",
    "        title=\"airt service kafka api\",\n",
    "        description=\"kafka api for airt service\",\n",
    "        kafka_brokers=kafka_brokers,\n",
    "        version=version,\n",
    "        contact=contact,\n",
    "        enable_idempotence=True,\n",
    "        request_timeout_ms=120_000,\n",
    "        max_batch_size=120_000,\n",
    "        #         auto_offset_reset=\"earliest\",\n",
    "        **kafka_config,\n",
    "    )\n",
    "\n",
    "    add_logging(app)\n",
    "    add_process_start_training_data(app)\n",
    "    add_process_training_model_start(app)\n",
    "    add_predictions(app)\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8d6dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastkafka._application.app._get_kafka_config(client_id=whatever)\n",
      "fastkafka._application.app._get_kafka_config(client_id=whatever) returned {'client_id': 'whatever', 'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n"
     ]
    }
   ],
   "source": [
    "def import_symbol(s: str) -> Tuple[str, str]:\n",
    "    xs = s.split(\".\")\n",
    "    for i in range(len(xs)):\n",
    "        try:\n",
    "            mname = \".\".join(xs[: i + 1])\n",
    "            importlib.import_module(mname)\n",
    "        except Exception as e:\n",
    "            mname, fname = \".\".join(xs[:i]), \".\".join(xs[i:])\n",
    "            imported_module = importlib.import_module(mname)\n",
    "            imported_symbol = getattr(imported_module, fname)\n",
    "            return imported_symbol\n",
    "    raise ValueError()\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def print_params(fqn: str):\n",
    "    f = import_symbol(fqn)\n",
    "    assert fqn == f\"{f.__module__}.{f.__qualname__}\", f\"{f.__module__}.{f.__qualname__}\"\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def _f(*args, **kwargs):\n",
    "        call = f\"{f.__module__}.{f.__qualname__}({', '.join([str(x) for x in args] + [str(k)+'='+str(v) for k, v in kwargs.items()])})\"\n",
    "        print(call)\n",
    "        retval = f(*args, **kwargs)\n",
    "        print(f\"{call} returned {retval}\")\n",
    "\n",
    "        return retval\n",
    "\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(fqn, _f)\n",
    "        yield\n",
    "\n",
    "\n",
    "with print_params(\"fastkafka._application.app._get_kafka_config\"):\n",
    "    fastkafka._application.app._get_kafka_config(client_id=\"whatever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "150b381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: create_fastkafka_application(): kafka_config={'auto_offset_reset': 'earliest', 'group_id': 'davor-redpanda:9092_group'}\n",
      "fastkafka._application.app._get_kafka_config(enable_idempotence=True, request_timeout_ms=120000, max_batch_size=120000, auto_offset_reset=earliest, group_id=davor-redpanda:9092_group)\n",
      "fastkafka._application.app._get_kafka_config(enable_idempotence=True, request_timeout_ms=120000, max_batch_size=120000, auto_offset_reset=earliest, group_id=davor-redpanda:9092_group) returned {'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'auto_offset_reset': 'earliest', 'group_id': 'davor-redpanda:9092_group', 'bootstrap_servers': 'localhost:9092', 'max_poll_records': 100}\n",
      "fastkafka._application.app._get_kafka_config()\n",
      "fastkafka._application.app._get_kafka_config() returned {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "Starting test...\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'enable_idempotence': True, 'request_timeout_ms': 120000, 'max_batch_size': 120000, 'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'localhost:9092'}'\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'request_timeout_ms': 120000, 'auto_offset_reset': 'earliest', 'group_id': 'davor-redpanda:9092_group', 'bootstrap_servers': 'localhost:9092', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_start_training_data']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'request_timeout_ms': 120000, 'auto_offset_reset': 'earliest', 'group_id': 'davor-redpanda:9092_group', 'bootstrap_servers': 'localhost:9092', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_start']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'request_timeout_ms': 120000, 'auto_offset_reset': 'earliest', 'group_id': 'davor-redpanda:9092_group', 'bootstrap_servers': 'localhost:9092', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_model_metrics']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_logger']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_data_status']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_start']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_training_model_status']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_model_metrics']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'localhost:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['infobip_prediction']\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***            tester.to_infobip_start_training_data(AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123)            ***\n",
      "***                                                                                                                                                          ***\n",
      "\n",
      "****************************************************************************************************************************************************************\n",
      "***                                                                                                                                                          ***\n",
      "***                                                tester.awaited_mocks.on_infobip_prediction.assert_called()                                                ***\n",
      "***                                                                                                                                                          ***\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 58, 47, 570978) message='on_start_training_data() starting...' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data() starting... while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 7, 58, 47, 571779) message='on_start_training_data(): no data yet received in the database.' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data(): no data yet received in the database. while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=0 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=1500 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=3000 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=4500 total_no_of_records=5123)\n",
      "to_training_data_status(AccountId=12345 ModelId=None no_of_records=5000 total_no_of_records=5123)\n",
      "to_training_model_start(AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=5000)\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 0, 12, 576385) message='on_start_training_data(): finished' original_message=ModelTrainingRequest(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, total_no_of_records=5123))\n",
      "[INFO] __main__: on_start_training_data(): finished while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> total_no_of_records=5123.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 0, 12, 577725) message='on_training_model_start() starting' original_message=TrainingModelStart(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, no_of_records=5000))\n",
      "[INFO] __main__: on_training_model_start() starting while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=5000.\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=0 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=1 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=2 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=3 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.0 total_no_of_steps=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=4 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=5 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=6 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=7 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=8 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.0 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.2 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.5 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=0.75 total_no_of_steps=10)\n",
      "to_training_model_status(AccountId=12345 ModelId=None current_step=9 current_step_percentage=1.0 total_no_of_steps=10)\n",
      "to_model_metrics(AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 591456) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992)\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 591633) message='on_training_model_start() finished' original_message=TrainingModelStart(AccountId=12345, ModelId=None, model_type=<ModelType.churn: 'churn'>, no_of_records=5000))\n",
      "[INFO] __main__: on_training_model_start() finished while processing AccountId=12345 ModelId=None model_type=<ModelType.churn: 'churn'> no_of_records=5000.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 593007) message='on_model_metrics() starting' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52), model_type=<ModelType.churn: 'churn'>, auc=0.951, f1=0.963, precission=0.983, recall=0.944, accuracy=0.992))\n",
      "[INFO] __main__: on_model_metrics() starting while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 594090) message='Sending predictions for 7 PersonIds' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52), model_type=<ModelType.churn: 'churn'>, auc=0.951, f1=0.963, precission=0.983, recall=0.944, accuracy=0.992))\n",
      "[INFO] __main__: Sending predictions for 7 PersonIds while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 595331) message='Sending predictions for 7 PersonIds finished in 0:00:00.000494.' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52), model_type=<ModelType.churn: 'churn'>, auc=0.951, f1=0.963, precission=0.983, recall=0.944, accuracy=0.992))\n",
      "[INFO] __main__: Sending predictions for 7 PersonIds finished in 0:00:00.000494. while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992.\n",
      "to_logger(level=10 timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52, 596032) message='on_model_metrics() finished' original_message=ModelMetrics(AccountId=12345, ModelId=None, timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52), model_type=<ModelType.churn: 'churn'>, auc=0.951, f1=0.963, precission=0.983, recall=0.944, accuracy=0.992))\n",
      "[INFO] __main__: on_model_metrics() finished while processing AccountId=12345 ModelId=None timestamp=datetime.datetime(2023, 5, 15, 8, 1, 52) model_type=<ModelType.churn: 'churn'> auc=0.951 f1=0.963 precission=0.983 recall=0.944 accuracy=0.992.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "[INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "with print_params(\"fastkafka._application.app._get_kafka_config\"):\n",
    "    app = create_fastkafka_application()\n",
    "\n",
    "    tester = Tester(app)\n",
    "\n",
    "    total_no_of_records = 5000\n",
    "\n",
    "    print(\"Starting test...\")\n",
    "    with monkeypatch_clickhouse(\n",
    "        total=total_no_of_records,\n",
    "        step=1500,\n",
    "    ):\n",
    "        async with tester:\n",
    "            model_training_request = ModelTrainingRequest(\n",
    "                AccountId=12345,\n",
    "                OccurredTime=\"2021-03-28T00:34:08\",\n",
    "                model_type=\"churn\",\n",
    "                total_no_of_records=total_no_of_records + 123,\n",
    "            )\n",
    "            heading(f\"tester.to_infobip_start_training_data({model_training_request})\")\n",
    "\n",
    "            await tester.to_infobip_start_training_data(model_training_request)\n",
    "\n",
    "            heading(\"tester.awaited_mocks.on_infobip_prediction.assert_called()\")\n",
    "\n",
    "            await tester.awaited_mocks.on_infobip_prediction.assert_called(timeout=500)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567121e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
