{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2942a5a5",
   "metadata": {},
   "source": [
    "# Confluent notebook\n",
    "> Notebook to store confluent related functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp confluent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dee009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "from aiokafka.helpers import create_ssl_context\n",
    "from airt.logger import get_logger\n",
    "from confluent_kafka.admin import AdminClient, NewTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from airt_service.db.models import create_user_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d56162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mrvjqtxdzr'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dc30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbac403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_bootstrap_servers = f\":{kafka_server_port},\".join(kafka_server_url.split(\",\")) + f\":{kafka_server_port}\"\n",
    "\n",
    "aio_kafka_config = {\n",
    "    \"bootstrap_servers\": kafka_bootstrap_servers,\n",
    "    \"group_id\": f\"{kafka_bootstrap_servers}_as_group\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "}\n",
    "if \"KAFKA_API_KEY\" in environ:\n",
    "    aio_kafka_config = {\n",
    "        **aio_kafka_config,\n",
    "        **{\n",
    "            \"security_protocol\": \"SASL_SSL\",\n",
    "            \"sasl_mechanism\": environ[\"KAFKA_SASL_MECHANISM\"],\n",
    "            \"sasl_plain_username\": environ[\"KAFKA_API_KEY\"],\n",
    "            \"sasl_plain_password\": environ[\"KAFKA_API_SECRET\"],\n",
    "            \"ssl_context\": create_ssl_context(),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092',\n",
       " 'group_id': 'kumaran-airt-service-kafka-1:9092_group',\n",
       " 'auto_offset_reset': 'earliest'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, _ in aio_kafka_config.items():\n",
    "    assert \"_\" in key and \".\" not in key, key\n",
    "aio_kafka_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# confluent_kafka_config = {key.replace(\"_\", \".\"):value for key, value in aio_kafka_config.items()}\n",
    "confluent_kafka_config = {\n",
    "    key.replace(\"_\", \".\"): aio_kafka_config[key]\n",
    "    for key in [\"bootstrap_servers\", \"group_id\", \"auto_offset_reset\"]\n",
    "}\n",
    "if \"KAFKA_API_KEY\" in environ:\n",
    "    confluent_kafka_config[\"security.protocol\"] = aio_kafka_config[\"security_protocol\"]\n",
    "    confluent_kafka_config[\"sasl.mechanisms\"] = aio_kafka_config[\"sasl_mechanism\"]\n",
    "    confluent_kafka_config[\"sasl.username\"] = aio_kafka_config[\"sasl_plain_username\"]\n",
    "    confluent_kafka_config[\"sasl.password\"] = aio_kafka_config[\"sasl_plain_password\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap.servers': 'kumaran-airt-service-kafka-1:9092',\n",
       " 'group.id': 'kumaran-airt-service-kafka-1:9092_group',\n",
       " 'auto.offset.reset': 'earliest'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, _ in confluent_kafka_config.items():\n",
    "    assert \"_\" not in key and \".\" in key, key\n",
    "confluent_kafka_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_topic_names_to_create(username: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of topic names to create for given username\n",
    "\n",
    "    Args:\n",
    "        username: username of user for whom the list of topic names is required\n",
    "    Returns:\n",
    "        A list of topic names unique to the username\n",
    "    \"\"\"\n",
    "    topic_names = [\n",
    "        \"start_training_data\",\n",
    "        \"training_data\",\n",
    "        \"realtime_data\",\n",
    "        \"training_data_status\",\n",
    "        \"training_model_status\",\n",
    "        \"model_metrics\",\n",
    "        \"prediction\",\n",
    "    ]\n",
    "    return [f\"{username}_{topic_name}\" for topic_name in topic_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mrvjqtxdzr_start_training_data',\n",
       " 'mrvjqtxdzr_training_data',\n",
       " 'mrvjqtxdzr_realitime_data',\n",
       " 'mrvjqtxdzr_training_data_status',\n",
       " 'mrvjqtxdzr_training_model_status',\n",
       " 'mrvjqtxdzr_model_metrics',\n",
       " 'mrvjqtxdzr_prediction']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = [\n",
    "    f\"{test_username}_start_training_data\",\n",
    "    f\"{test_username}_training_data\",\n",
    "    f\"{test_username}_realtime_data\",\n",
    "    f\"{test_username}_training_data_status\",\n",
    "    f\"{test_username}_training_model_status\",\n",
    "    f\"{test_username}_model_metrics\",\n",
    "    f\"{test_username}_prediction\",\n",
    "]\n",
    "actual = get_topic_names_to_create(username=test_username)\n",
    "assert actual == expected, actual\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_topics_for_user(username: str) -> None:\n",
    "    \"\"\"\n",
    "    Create necessary topics for given user\n",
    "\n",
    "    Args:\n",
    "        username: username of user for whom the topics needs to be created\n",
    "    \"\"\"\n",
    "\n",
    "    topic_names_to_create = get_topic_names_to_create(username)\n",
    "    admin_client = AdminClient(confluent_kafka_config)\n",
    "\n",
    "    num_partitions = 6\n",
    "    replication_factor = 3 if \"KAFKA_API_KEY\" in environ else 1\n",
    "\n",
    "    existing_topics = admin_client.list_topics().topics\n",
    "\n",
    "    topics_to_create = [\n",
    "        NewTopic(topic_name, num_partitions, replication_factor)\n",
    "        for topic_name in topic_names_to_create\n",
    "        if topic_name not in existing_topics\n",
    "    ]\n",
    "    if not topics_to_create:\n",
    "        return\n",
    "\n",
    "    futures = admin_client.create_topics(topics_to_create)\n",
    "\n",
    "    for topic, future in futures.items():\n",
    "        try:\n",
    "            future.result()\n",
    "            logger.info(f\"Topic {topic} created\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Topic {topic} creation failed\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c126e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-12 06:29:39.570 [INFO] __main__: Topic mrvjqtxdzr_start_training_data created\n",
      "23-01-12 06:29:39.571 [INFO] __main__: Topic mrvjqtxdzr_training_data created\n",
      "23-01-12 06:29:39.571 [INFO] __main__: Topic mrvjqtxdzr_realitime_data created\n",
      "23-01-12 06:29:39.572 [INFO] __main__: Topic mrvjqtxdzr_training_data_status created\n",
      "23-01-12 06:29:39.573 [INFO] __main__: Topic mrvjqtxdzr_training_model_status created\n",
      "23-01-12 06:29:39.574 [INFO] __main__: Topic mrvjqtxdzr_model_metrics created\n",
      "23-01-12 06:29:39.575 [INFO] __main__: Topic mrvjqtxdzr_prediction created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1673504979.449|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504979.449|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504980.580|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504980.580|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "topic_names = get_topic_names_to_create(username=test_username)\n",
    "create_topics_for_user(username=test_username)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "admin_client = AdminClient(confluent_kafka_config)\n",
    "topic_metadata = admin_client.list_topics()\n",
    "\n",
    "for topic_name in topic_names:\n",
    "    assert (\n",
    "        topic_metadata.topics.get(topic_name) is not None\n",
    "    ), f\"Topic {topic_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def delete_topics_for_user(username: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete necessary topics for given user\n",
    "\n",
    "    Args:\n",
    "        username: username of user for whom the topics needs to be deleted\n",
    "    \"\"\"\n",
    "\n",
    "    topic_names_to_delete = get_topic_names_to_create(username)\n",
    "    admin_client = AdminClient(confluent_kafka_config)\n",
    "\n",
    "    existing_topics = admin_client.list_topics().topics\n",
    "\n",
    "    topics_to_delete = [\n",
    "        topic_name\n",
    "        for topic_name in topic_names_to_delete\n",
    "        if topic_name in existing_topics\n",
    "    ]\n",
    "    if not topics_to_delete:\n",
    "        return\n",
    "\n",
    "    futures = admin_client.delete_topics(topics_to_delete)\n",
    "\n",
    "    for topic, future in futures.items():\n",
    "        try:\n",
    "            future.result()\n",
    "            logger.info(f\"Topic {topic} deleted\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Topic {topic} deletion failed\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd26e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-12 06:29:40.617 [INFO] __main__: Topic mrvjqtxdzr_start_training_data deleted\n",
      "23-01-12 06:29:40.617 [INFO] __main__: Topic mrvjqtxdzr_training_data deleted\n",
      "23-01-12 06:29:40.618 [INFO] __main__: Topic mrvjqtxdzr_realitime_data deleted\n",
      "23-01-12 06:29:40.619 [INFO] __main__: Topic mrvjqtxdzr_training_data_status deleted\n",
      "23-01-12 06:29:40.619 [INFO] __main__: Topic mrvjqtxdzr_training_model_status deleted\n",
      "23-01-12 06:29:40.620 [INFO] __main__: Topic mrvjqtxdzr_model_metrics deleted\n",
      "23-01-12 06:29:40.620 [INFO] __main__: Topic mrvjqtxdzr_prediction deleted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1673504980.595|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504980.595|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504981.624|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1673504981.624|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "topic_names = get_topic_names_to_create(username=test_username)\n",
    "delete_topics_for_user(username=test_username)\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "admin_client = AdminClient(confluent_kafka_config)\n",
    "topic_metadata = admin_client.list_topics()\n",
    "\n",
    "for topic_name in topic_names:\n",
    "    assert (\n",
    "        topic_metadata.topics.get(topic_name) is None\n",
    "    ), f\"Topic {topic_name} found and not deleted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba0bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41753b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
