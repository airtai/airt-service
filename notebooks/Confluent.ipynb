{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2942a5a5",
   "metadata": {},
   "source": [
    "# Confluent notebook\n",
    "> Notebook to store confluent related functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp confluent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dee009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "from airt.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airt_service.db.models import create_user_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d56162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rjbgncixxh'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dc30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbac403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "aio_kafka_config = {\n",
    "    \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    \"group_id\": f\"{kafka_server_url}:{kafka_server_port}_group\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "}\n",
    "if \"KAFKA_API_KEY\" in environ:\n",
    "    aio_kafka_config = {\n",
    "        **aio_kafka_config,\n",
    "        **{\n",
    "            \"security_protocol\": \"SASL_SSL\",\n",
    "            \"sasl_mechanisms\": \"PLAIN\",\n",
    "            \"sasl_username\": environ[\"KAFKA_API_KEY\"],\n",
    "            \"sasl_password\": environ[\"KAFKA_API_SECRET\"],\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092',\n",
       " 'group_id': 'kumaran-airt-service-kafka-1:9092_group',\n",
       " 'auto_offset_reset': 'earliest'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, _ in aio_kafka_config.items():\n",
    "    assert \"_\" in key and \".\" not in key, key\n",
    "aio_kafka_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "confluent_kafka_config = {key.replace(\"_\", \".\"):value for key, value in aio_kafka_config.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap.servers': 'kumaran-airt-service-kafka-1:9092',\n",
       " 'group.id': 'kumaran-airt-service-kafka-1:9092_group',\n",
       " 'auto.offset.reset': 'earliest'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, _ in confluent_kafka_config.items():\n",
    "    assert \"_\" not in key and \".\" in key, key\n",
    "confluent_kafka_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_topic_names_to_create(username: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of topic names to create for given username\n",
    "    \n",
    "    Args:\n",
    "        username: username of user for whom the list of topic names is required\n",
    "    Returns:\n",
    "        A list of topic names unique to the username\n",
    "    \"\"\"\n",
    "    return [f\"airt_service_{username}_training_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airt_service_rjbgncixxh_training_data']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = [f\"airt_service_{test_username}_training_data\"]\n",
    "actual = get_topic_names_to_create(username=test_username)\n",
    "assert actual == expected, actual\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_topics_for_user(username: str):\n",
    "    \"\"\"\n",
    "    Create necessary topics for given user\n",
    "\n",
    "    Args:\n",
    "        username: username of user for whom the topics needs to be created\n",
    "    \"\"\"\n",
    "\n",
    "    topic_names_to_create = get_topic_names_to_create(username)\n",
    "    admin_client = AdminClient(confluent_kafka_config)\n",
    "\n",
    "    num_partitions = 6\n",
    "    replication_factor = 2 if \"KAFKA_API_KEY\" in environ else 1\n",
    "\n",
    "    existing_topics = admin_client.list_topics().topics\n",
    "\n",
    "    topics_to_create = [\n",
    "        NewTopic(topic_name, num_partitions, replication_factor)\n",
    "        for topic_name in topic_names_to_create\n",
    "        if topic_name not in existing_topics\n",
    "    ]\n",
    "    if not topics_to_create:\n",
    "        return\n",
    "\n",
    "    futures = admin_client.create_topics(topics_to_create)\n",
    "\n",
    "    for topic, future in futures.items():\n",
    "        try:\n",
    "            future.result()\n",
    "            logger.info(f\"Topic {topic} created\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Topic {topic} creation failed\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c126e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-05 11:40:01.934 [INFO] __main__: Topic airt_service_rjbgncixxh_training_data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1672918801.903|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.903|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.935|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.935|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "topic_names = get_topic_names_to_create(username=test_username)\n",
    "create_topics_for_user(username=test_username)\n",
    "\n",
    "admin_client = AdminClient(confluent_kafka_config)\n",
    "topic_metadata = admin_client.list_topics()\n",
    "\n",
    "for topic_name in topic_names:\n",
    "    assert topic_metadata.topics.get(topic_name) is not None, f\"Topic {topic_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def delete_topics_for_user(username: str):\n",
    "    \"\"\"\n",
    "    Delete necessary topics for given user\n",
    "\n",
    "    Args:\n",
    "        username: username of user for whom the topics needs to be deleted\n",
    "    \"\"\"\n",
    "\n",
    "    topic_names_to_delete = get_topic_names_to_create(username)\n",
    "    admin_client = AdminClient(confluent_kafka_config)\n",
    "\n",
    "    existing_topics = admin_client.list_topics().topics\n",
    "\n",
    "    topics_to_delete = [\n",
    "        topic_name\n",
    "        for topic_name in topic_names_to_delete\n",
    "        if topic_name in existing_topics\n",
    "    ]\n",
    "    if not topics_to_delete:\n",
    "        return\n",
    "\n",
    "    futures = admin_client.delete_topics(topics_to_delete)\n",
    "\n",
    "    for topic, future in futures.items():\n",
    "        try:\n",
    "            future.result()\n",
    "            logger.info(f\"Topic {topic} deleted\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Topic {topic} deletion failed\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd26e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-05 11:40:01.955 [INFO] __main__: Topic airt_service_rjbgncixxh_training_data deleted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1672918801.947|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.947|CONFWARN|rdkafka#producer-3| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.956|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1672918801.956|CONFWARN|rdkafka#producer-4| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    }
   ],
   "source": [
    "topic_names = get_topic_names_to_create(username=test_username)\n",
    "delete_topics_for_user(username=test_username)\n",
    "\n",
    "admin_client = AdminClient(confluent_kafka_config)\n",
    "topic_metadata = admin_client.list_topics()\n",
    "\n",
    "for topic_name in topic_names:\n",
    "    assert topic_metadata.topics.get(topic_name) is None, f\"Topic {topic_name} found and not deleted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba0bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41753b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
