{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Notebook to have DataSource and DataBlob utilities functions\n",
    "output-file: data_utils.html\n",
    "title: Data Utilities\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n",
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "[INFO] airt.keras.helpers: Using a single GPU #0 with memory_limit 1024 MB\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "from urllib.parse import unquote_plus as urlunquote\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from mypy_boto3_s3.service_resource import Bucket\n",
    "\n",
    "import airt_service.sanitizer\n",
    "from airt.logger import get_logger\n",
    "from airt_service.db.models import (\n",
    "    create_connection_string,\n",
    "    DataSource,\n",
    "    DataBlob,\n",
    "    Model,\n",
    "    Prediction,\n",
    ")\n",
    "from airt_service.aws.utils import (\n",
    "    create_s3_datablob_path,\n",
    "    create_s3_datasource_path,\n",
    "    get_s3_bucket_and_path_from_uri,\n",
    "    get_s3_bucket_name_and_folder_from_uri,\n",
    ")\n",
    "from airt_service.azure.utils import (\n",
    "    create_azure_blob_storage_datablob_path,\n",
    "    create_azure_blob_storage_datasource_path,\n",
    "    get_azure_blob_storage_container,\n",
    ")\n",
    "from airt_service.constants import METADATA_FOLDER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.data.importers: Module loaded:\n",
      "[INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "[INFO] airt.data.importers:  - using dask       : 2022.10.0\n",
      "[INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from time import sleep\n",
    "\n",
    "from sqlmodel import select\n",
    "import pandas as pd\n",
    "\n",
    "from airt.remote_path import RemotePath\n",
    "from airt_service.aws.utils import upload_to_s3_with_retry\n",
    "from airt_service.data.csv import process_csv\n",
    "from airt_service.data.datablob import FromLocalRequest, from_local_start_route\n",
    "from airt_service.db.models import (\n",
    "    get_session,\n",
    "    get_session_with_context,\n",
    "    User,\n",
    "    create_user_for_testing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdgdzpegvs'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def create_db_uri_for_s3_datablob(uri: str, access_key: str, secret_key: str) -> str:\n",
    "    \"\"\"Create db_uri for s3 datablob based on s3 connection params\n",
    "\n",
    "    Args:\n",
    "        uri: URI of s3 datablob\n",
    "        access_key: Access key of s3 datablob\n",
    "        secret_key: Secret key of s3 datablob\n",
    "\n",
    "    Returns:\n",
    "        The uri for the s3 datablob\n",
    "    \"\"\"\n",
    "    return f\"s3://{access_key}:{secret_key}@{uri.replace('s3://', '')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='s3://****************************************@bucket/hello/world'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='s3://****************************************@test-airt-service/account_312571_events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='s3://****************************************@bucket/hello/world/again'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='s3://****************************************@bucket/hello/world?qwe1=3#ddd'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='s3://****************************************@bucket/hello/world#foo?bar=2'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_test_cases = [\n",
    "    {\n",
    "        \"uri\": \"s3://bucket/hello/world\",\n",
    "        \"access_key\": \"AIKEA987SDFADF\",\n",
    "        \"secret_key\": \"9UVSadsalfajJJHGUIYGjhsdfaf+0\",\n",
    "        \"db_uri\": \"s3://AIKEA987SDFADF:9UVSadsalfajJJHGUIYGjhsdfaf+0@bucket/hello/world\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"s3://test-airt-service/account_312571_events\",\n",
    "        \"access_key\": \"AIKEA987SDFADF\",\n",
    "        \"secret_key\": \"9UVSadsalfajJJHGUIYGjhsdfaf+0\",\n",
    "        \"db_uri\": \"s3://AIKEA987SDFADF:9UVSadsalfajJJHGUIYGjhsdfaf+0@test-airt-service/account_312571_events\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"s3://bucket/hello/world/again\",\n",
    "        \"access_key\": \"AIKEA987SDFADF\",\n",
    "        \"secret_key\": \"9UVSadsalfajJJHGUIYGjhsdfaf+0\",\n",
    "        \"db_uri\": \"s3://AIKEA987SDFADF:9UVSadsalfajJJHGUIYGjhsdfaf+0@bucket/hello/world/again\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"s3://bucket/hello/world?qwe1=3#ddd\",\n",
    "        \"access_key\": \"AIKEA987SDFADF\",\n",
    "        \"secret_key\": \"9UVSadsalfajJJHGUIYGjhsdfaf+0\",\n",
    "        \"db_uri\": \"s3://AIKEA987SDFADF:9UVSadsalfajJJHGUIYGjhsdfaf+0@bucket/hello/world?qwe1=3#ddd\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"s3://bucket/hello/world#foo?bar=2\",\n",
    "        \"access_key\": \"AIKEA987SDFADF\",\n",
    "        \"secret_key\": \"9UVSadsalfajJJHGUIYGjhsdfaf+0\",\n",
    "        \"db_uri\": \"s3://AIKEA987SDFADF:9UVSadsalfajJJHGUIYGjhsdfaf+0@bucket/hello/world#foo?bar=2\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for test_case in s3_test_cases:\n",
    "    actual_db_uri = create_db_uri_for_s3_datablob(\n",
    "        uri=test_case[\"uri\"],\n",
    "        access_key=test_case[\"access_key\"],\n",
    "        secret_key=test_case[\"secret_key\"],\n",
    "    )\n",
    "    display(f\"{actual_db_uri=}\")\n",
    "    assert actual_db_uri == test_case[\"db_uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def get_s3_connection_params_from_db_uri(db_uri: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"Get S3 connection params from db_uri of the s3 datablob\n",
    "\n",
    "    Args:\n",
    "        db_uri: DB uri of s3 datablob\n",
    "\n",
    "    Returns:\n",
    "        The uri, access key and secret key of the s3 datablob as a tuple\n",
    "    \"\"\"\n",
    "    result = re.search(\"s3:\\/\\/(.*):(.*)@(.*)\", db_uri)\n",
    "    access_key = result.group(1)  # type: ignore\n",
    "    secret_key = result.group(2)  # type: ignore\n",
    "    uri = f\"s3://{result.group(3)}\"  # type: ignore\n",
    "    return uri, access_key, secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_uri='s3://bucket/hello/world'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_access_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_secret_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='s3://test-airt-service/account_312571_events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_access_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_secret_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='s3://bucket/hello/world/again'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_access_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_secret_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='s3://bucket/hello/world?qwe1=3#ddd'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_access_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_secret_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='s3://bucket/hello/world#foo?bar=2'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_access_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_secret_key = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for test_case in s3_test_cases:\n",
    "    (\n",
    "        actual_uri,\n",
    "        actual_access_key,\n",
    "        actual_secret_key,\n",
    "    ) = get_s3_connection_params_from_db_uri(db_uri=test_case[\"db_uri\"])\n",
    "    display(f\"{actual_uri=}\", f\"{actual_access_key=}\", f\"{actual_secret_key=}\")\n",
    "\n",
    "    assert actual_uri == test_case[\"uri\"]\n",
    "    assert actual_access_key == test_case[\"access_key\"]\n",
    "    assert actual_secret_key == test_case[\"secret_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def create_db_uri_for_azure_blob_storage_datablob(uri: str, credential: str) -> str:\n",
    "    \"\"\"Create db_uri for azure datablob based on azure blob storage connection params\n",
    "\n",
    "    Args:\n",
    "        uri: URI of azure blob storage datablob\n",
    "        credential: Credential of azure blob storage datablob\n",
    "\n",
    "    Returns:\n",
    "        The uri for the azure blob storage datablob\n",
    "    \"\"\"\n",
    "    return f\"https://{credential}@{uri.replace('https://', '')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='https://****************************************@testairtservice.blob.core.windows.net/test-container/account_312571_events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='https://****************************************@testairtservice.blob.core.windows.net/test-container/account_312571_events/folder'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='https://****************************************@testairtservice.blob.core.windows.net/test-container'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "azure_test_cases = [\n",
    "    {\n",
    "        \"uri\": \"https://testairtservice.blob.core.windows.net/test-container/account_312571_events\",\n",
    "        \"credential\": \"xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==\",\n",
    "        \"db_uri\": \"https://xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==@testairtservice.blob.core.windows.net/test-container/account_312571_events\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"https://testairtservice.blob.core.windows.net/test-container/account_312571_events/folder\",\n",
    "        \"credential\": \"xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==\",\n",
    "        \"db_uri\": \"https://xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==@testairtservice.blob.core.windows.net/test-container/account_312571_events/folder\",\n",
    "    },\n",
    "    {\n",
    "        \"uri\": \"https://testairtservice.blob.core.windows.net/test-container\",\n",
    "        \"credential\": \"xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==\",\n",
    "        \"db_uri\": \"https://xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q==@testairtservice.blob.core.windows.net/test-container\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for test_case in azure_test_cases:\n",
    "    actual_db_uri = create_db_uri_for_azure_blob_storage_datablob(\n",
    "        uri=test_case[\"uri\"],\n",
    "        credential=test_case[\"credential\"],\n",
    "    )\n",
    "    display(f\"{actual_db_uri=}\")\n",
    "    assert actual_db_uri == test_case[\"db_uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def get_azure_blob_storage_connection_params_from_db_uri(\n",
    "    db_uri: str,\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"Get azure blob storage connection params from db_uri of the azure blob storage datablob\n",
    "\n",
    "    Args:\n",
    "        db_uri: DB uri of azure blob storage datablob\n",
    "\n",
    "    Returns:\n",
    "        The uri and credential of the azure blob storage datablob as a tuple\n",
    "    \"\"\"\n",
    "    result = re.search(\"https:\\/\\/(.*)@(.*)\", db_uri)\n",
    "    credential = result.group(1)  # type: ignore\n",
    "    uri = f\"https://{result.group(2)}\"  # type: ignore\n",
    "    return uri, credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_uri='https://testairtservice.blob.core.windows.net/test-container/account_312571_events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_credential='xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q=='\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='https://testairtservice.blob.core.windows.net/test-container/account_312571_events/folder'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_credential='xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q=='\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_uri='https://testairtservice.blob.core.windows.net/test-container'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_credential='xFLcltokRem1ADQaM4PP81XXkmvb21rZQhUqbo3C4RjIG4yeMneOJLLc9AWQOa9LeNLH6EuMLe4H+ALp7kFM+Q=='\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for test_case in azure_test_cases:\n",
    "    (\n",
    "        actual_uri,\n",
    "        actual_credential,\n",
    "    ) = get_azure_blob_storage_connection_params_from_db_uri(db_uri=test_case[\"db_uri\"])\n",
    "    display(f\"{actual_uri=}\", f\"{actual_credential=}\")\n",
    "\n",
    "    assert actual_uri == test_case[\"uri\"]\n",
    "    assert actual_credential == test_case[\"credential\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def create_db_uri_for_db_datablob(\n",
    "    username: str,\n",
    "    password: str,\n",
    "    host: str,\n",
    "    port: int,\n",
    "    table: str,\n",
    "    database: str,\n",
    "    database_server: str,\n",
    ") -> str:\n",
    "    \"\"\"Create db_uri for the datablob based on connection params\n",
    "\n",
    "    Args:\n",
    "        username: Username of db datablob\n",
    "        password: Password of db datablob\n",
    "        host: Host of db datablob\n",
    "        port: Port of db datablob\n",
    "        table: Table of db datablob\n",
    "        database: Database to use\n",
    "        database_server: Server/engine of db datablob\n",
    "    Returns:\n",
    "        The db_uri for the db datasource\n",
    "    \"\"\"\n",
    "    db_uri = create_connection_string(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port,\n",
    "        database=database,\n",
    "        database_server=database_server,\n",
    "    )\n",
    "    db_uri = f\"{db_uri}/{table}\"\n",
    "    return db_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_db_uri='mysql://****************************************@db.example.com:3306/airt_service/events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db_test_cases = [\n",
    "    dict(\n",
    "        username=\"johndoe\",\n",
    "        password=\"special1@\",\n",
    "        host=\"db.example.com\",\n",
    "        port=3306,\n",
    "        table=\"events\",\n",
    "        database=\"airt_service\",\n",
    "        database_server=\"mysql\",\n",
    "        db_uri=\"mysql://johndoe:special1%40@db.example.com:3306/airt_service/events\",\n",
    "    )\n",
    "]\n",
    "\n",
    "for test_case in db_test_cases:\n",
    "    actual_db_uri = create_db_uri_for_db_datablob(\n",
    "        username=test_case[\"username\"],\n",
    "        password=test_case[\"password\"],\n",
    "        host=test_case[\"host\"],\n",
    "        port=test_case[\"port\"],\n",
    "        table=test_case[\"table\"],\n",
    "        database=test_case[\"database\"],\n",
    "        database_server=test_case[\"database_server\"],\n",
    "    )\n",
    "    display(f\"{actual_db_uri=}\")\n",
    "    assert actual_db_uri == test_case[\"db_uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def get_db_connection_params_from_db_uri(\n",
    "    db_uri: str,\n",
    ") -> Tuple[str, str, str, int, str, str, str]:\n",
    "    \"\"\"Get db connection params from db_uri\n",
    "\n",
    "    Args:\n",
    "        db_uri: DB uri of db datablob\n",
    "    Returns:\n",
    "        The username, password, host, port, table, database, database_server of the datablob as a tuple\n",
    "    \"\"\"\n",
    "    result = re.search(\"(.*):\\/\\/(.*):(.*)@(.*):(.*)\\/(.*)\\/(.*)\", db_uri)\n",
    "    database_server = result.group(1)  # type: ignore\n",
    "    username = result.group(2)  # type: ignore\n",
    "    password = urlunquote(result.group(3))  # type: ignore\n",
    "    host = result.group(4)  # type: ignore\n",
    "    port = int(result.group(5))  # type: ignore\n",
    "    database = result.group(6)  # type: ignore\n",
    "    table = result.group(7)  # type: ignore\n",
    "    return username, password, host, port, table, database, database_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"actual_username='johndoe'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_password = '****************************************'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_host='db.example.com'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'actual_port=3306'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_table='events'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_database='airt_service'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"actual_database_server='mysql'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for test_case in db_test_cases:\n",
    "    (\n",
    "        actual_username,\n",
    "        actual_password,\n",
    "        actual_host,\n",
    "        actual_port,\n",
    "        actual_table,\n",
    "        actual_database,\n",
    "        actual_database_server,\n",
    "    ) = get_db_connection_params_from_db_uri(db_uri=test_case[\"db_uri\"])\n",
    "    display(\n",
    "        f\"{actual_username=}\",\n",
    "        f\"{actual_password=}\",\n",
    "        f\"{actual_host=}\",\n",
    "        f\"{actual_port=}\",\n",
    "        f\"{actual_table=}\",\n",
    "        f\"{actual_database=}\",\n",
    "        f\"{actual_database_server=}\",\n",
    "    )\n",
    "\n",
    "    assert actual_username == test_case[\"username\"]\n",
    "    assert actual_password == test_case[\"password\"]\n",
    "    assert actual_host == test_case[\"host\"]\n",
    "    assert actual_port == test_case[\"port\"]\n",
    "    assert actual_table == test_case[\"table\"]\n",
    "    assert actual_database == test_case[\"database\"]\n",
    "    assert actual_database_server == test_case[\"database_server\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def create_db_uri_for_local_datablob(bucket: Bucket, s3_path: str) -> str:\n",
    "    \"\"\"Create db_uri for csv datablob\n",
    "\n",
    "    Args:\n",
    "        bucket: S3 bucket object\n",
    "        s3_path: S3 path in which uploaded csv is stored\n",
    "\n",
    "    Returns:\n",
    "        The db uri for the csv datablob\n",
    "    \"\"\"\n",
    "    return f\"s3://{bucket.name}/{s3_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] botocore.credentials: Found credentials in environment variables.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://kumaran-airt-service-eu-west-1/999/datablob/999'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bucket, s3_path = create_s3_datablob_path(\n",
    "    user_id=999, datablob_id=999, region=\"eu-west-1\"\n",
    ")\n",
    "\n",
    "actual = create_db_uri_for_local_datablob(bucket=bucket, s3_path=s3_path)\n",
    "display(actual)\n",
    "assert actual == f\"s3://{bucket.name}/{s3_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def calculate_azure_data_object_folder_size_and_path(\n",
    "    data_object: Union[DataBlob, DataSource]\n",
    "):\n",
    "    \"\"\"Calculate datasource/datablob folder size based on azure blob storage object size and its path\n",
    "\n",
    "    Args:\n",
    "        data_object: DataBlob or DataSource object\n",
    "    \"\"\"\n",
    "    if isinstance(data_object, DataBlob):\n",
    "        (\n",
    "            container_client,\n",
    "            azure_blob_storage_path,\n",
    "        ) = create_azure_blob_storage_datablob_path(\n",
    "            user_id=data_object.user.id, datablob_id=data_object.id, region=data_object.region  # type: ignore\n",
    "        )\n",
    "    elif isinstance(data_object, DataSource):\n",
    "        (\n",
    "            container_client,\n",
    "            azure_blob_storage_path,\n",
    "        ) = create_azure_blob_storage_datasource_path(\n",
    "            user_id=data_object.user.id, datasource_id=data_object.id, region=data_object.region  # type: ignore\n",
    "        )\n",
    "    destination_container_objects = list(\n",
    "        container_client.list_blobs(name_starts_with=azure_blob_storage_path + \"/\")\n",
    "    )\n",
    "    data_object.completed_steps = 1\n",
    "    data_object.folder_size = sum(\n",
    "        obj[\"size\"]\n",
    "        for obj in destination_container_objects\n",
    "        if METADATA_FOLDER_PATH not in obj[\"name\"]\n",
    "    )\n",
    "    data_object.path = f\"{container_client.url}/{azure_blob_storage_path}\"  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://testairtservice.blob.core.windows.net/test-container/account_312571_events\n",
      "[INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_6owgds7v\n",
      "[INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://testairtservice.blob.core.windows.net/test-container/account_312571_events locally in /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_6owgds7v\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] airt.remote_path: AzureBlobPath.__enter__(): pulling data from https://testairtservice.blob.core.windows.net/test-container/account_312571_events to /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_6owgds7v\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/7/datasource/1\n",
      "[INFO] airt.remote_path: AzureBlobPath._create_cache_path(): created cache path: /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope7datasource1_cached_tshumtu3\n",
      "[INFO] airt.remote_path: AzureBlobPath.__init__(): created object for accessing https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/7/datasource/1 locally in /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope7datasource1_cached_tshumtu3\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] airt.remote_path: AzureBlobPath.__exit__(): pushing data from /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope7datasource1_cached_tshumtu3 to https://kumsairtsdevwesteurope.blob.core.windows.net/kumsairtsdevwesteurope/7/datasource/1\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpskumsairtsdevwesteuropeblobcorewindowsnetkumsairtsdevwesteurope7datasource1_cached_tshumtu3\n",
      "[INFO] airt.remote_path: AzureBlobPath._clean_up(): removing local cache path /tmp/httpstestairtserviceblobcorewindowsnettest-containeraccount_312571_events_cached_6owgds7v\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.default: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n"
     ]
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    datasource = DataSource(\n",
    "        cloud_provider=\"azure\",\n",
    "        region=\"westeurope\",\n",
    "        total_steps=1,\n",
    "        user=user,\n",
    "    )\n",
    "\n",
    "    session.add(datasource)\n",
    "    session.commit()\n",
    "    session.refresh(datasource)\n",
    "\n",
    "    assert not datasource.folder_size\n",
    "    assert not datasource.no_of_rows\n",
    "    assert not datasource.path\n",
    "    assert not datasource.hash\n",
    "\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=\"https://testairtservice.blob.core.windows.net/test-container/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "    ) as test_s3_path:\n",
    "        (\n",
    "            destination_container_client,\n",
    "            azure_blob_storage_path,\n",
    "        ) = create_azure_blob_storage_datasource_path(\n",
    "            user_id=datasource.user.id,\n",
    "            datasource_id=datasource.id,\n",
    "            region=datasource.region,\n",
    "        )\n",
    "        sleep(10)\n",
    "        with RemotePath.from_url(\n",
    "            remote_url=f\"{destination_container_client.url}/{azure_blob_storage_path}\",\n",
    "            pull_on_enter=False,\n",
    "            push_on_exit=True,\n",
    "            exist_ok=True,\n",
    "            parents=True,\n",
    "        ) as destination_s3_path:\n",
    "            ddf = dd.read_parquet(test_s3_path.as_path()).set_index(\"PersonId\")\n",
    "            ddf.to_parquet(destination_s3_path.as_path())\n",
    "\n",
    "    calculate_azure_data_object_folder_size_and_path(data_object=datasource)\n",
    "\n",
    "    assert datasource.folder_size\n",
    "    assert datasource.completed_steps == 1\n",
    "    assert (\n",
    "        f\"westeurope/{user.id}/datasource/{datasource.id}\" in datasource.path\n",
    "    ), datasource.path\n",
    "    datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def calculate_s3_data_object_folder_size_and_path(\n",
    "    data_object: Union[DataBlob, DataSource]\n",
    "):\n",
    "    \"\"\"Calculate datasource/datablob folder size based on s3 object size and its s3 path\n",
    "\n",
    "    Args:\n",
    "        data_object: DataBlob or DataSource object\n",
    "    \"\"\"\n",
    "    if isinstance(data_object, DataBlob):\n",
    "        destination_bucket, s3_path = create_s3_datablob_path(\n",
    "            user_id=data_object.user.id, datablob_id=data_object.id, region=data_object.region  # type: ignore\n",
    "        )\n",
    "    elif isinstance(data_object, DataSource):\n",
    "        destination_bucket, s3_path = create_s3_datasource_path(\n",
    "            user_id=data_object.user.id, datasource_id=data_object.id, region=data_object.region  # type: ignore\n",
    "        )\n",
    "    destination_bucket_objects = list(\n",
    "        destination_bucket.objects.filter(Prefix=s3_path + \"/\")\n",
    "    )\n",
    "    data_object.completed_steps = 1\n",
    "    data_object.folder_size = sum(\n",
    "        obj.size\n",
    "        for obj in destination_bucket_objects\n",
    "        if METADATA_FOLDER_PATH not in obj.key\n",
    "    )\n",
    "    data_object.path = f\"s3://{destination_bucket.name}/{s3_path}\"  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_qdgh24xo\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_qdgh24xo\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_qdgh24xo\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/7/datasource/4\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-17datasource4_cached_x6eax_y2\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/7/datasource/4 locally in /tmp/s3kumaran-airt-service-eu-west-17datasource4_cached_x6eax_y2\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-17datasource4_cached_x6eax_y2 to s3://kumaran-airt-service-eu-west-1/7/datasource/4\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-17datasource4_cached_x6eax_y2\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_qdgh24xo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSource(id=4, uuid=UUID('58852fab-236f-4360-9d95-f9b733dad8ec'), hash=None, total_steps=1, completed_steps=1, folder_size=8153852, no_of_rows=None, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-1', error=None, disabled=False, path='s3://kumaran-airt-service-eu-west-1/7/datasource/4', created=datetime.datetime(2022, 11, 7, 9, 10, 46), user_id=7, pulled_on=None, tags=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    datasource = DataSource(\n",
    "        cloud_provider=\"aws\",\n",
    "        region=\"eu-west-1\",\n",
    "        total_steps=1,\n",
    "        user=user,\n",
    "    )\n",
    "\n",
    "    session.add(datasource)\n",
    "    session.commit()\n",
    "    session.refresh(datasource)\n",
    "\n",
    "    assert not datasource.folder_size\n",
    "    assert not datasource.no_of_rows\n",
    "    assert not datasource.path\n",
    "    assert not datasource.hash\n",
    "\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        destination_bucket, s3_path = create_s3_datasource_path(\n",
    "            user_id=datasource.user.id,\n",
    "            datasource_id=datasource.id,\n",
    "            region=datasource.region,\n",
    "        )\n",
    "        sleep(10)\n",
    "        with RemotePath.from_url(\n",
    "            remote_url=f\"s3://{destination_bucket.name}/{s3_path}\",\n",
    "            pull_on_enter=False,\n",
    "            push_on_exit=True,\n",
    "            exist_ok=True,\n",
    "            parents=True,\n",
    "        ) as destination_s3_path:\n",
    "            ddf = dd.read_parquet(test_s3_path.as_path()).set_index(\"PersonId\")\n",
    "            ddf.to_parquet(destination_s3_path.as_path())\n",
    "\n",
    "    calculate_s3_data_object_folder_size_and_path(data_object=datasource)\n",
    "\n",
    "    assert datasource.folder_size\n",
    "    assert datasource.completed_steps == 1\n",
    "    assert (\n",
    "        datasource.path\n",
    "        == f\"s3://{os.environ['STORAGE_BUCKET_PREFIX']}-eu-west-1/{user.id}/datasource/{datasource.id}\"\n",
    "    ), datasource.path\n",
    "    display(datasource)\n",
    "    datasource_id = datasource.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def calculate_data_object_folder_size_and_path(\n",
    "    data_object: Union[DataBlob, DataSource]\n",
    "):\n",
    "    \"\"\"Calculate datasource/datablob folder size for both aws and azure data objects\n",
    "\n",
    "    Args:\n",
    "        data_object: DataBlob or DataSource object\n",
    "    \"\"\"\n",
    "    if data_object.cloud_provider == \"aws\":\n",
    "        calculate_s3_data_object_folder_size_and_path(data_object=data_object)\n",
    "    elif data_object.cloud_provider == \"azure\":\n",
    "        calculate_azure_data_object_folder_size_and_path(data_object=data_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_m037i2ul\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_m037i2ul\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_m037i2ul\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/7/datasource/6\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-17datasource6_cached_6xhxozi1\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/7/datasource/6 locally in /tmp/s3kumaran-airt-service-eu-west-17datasource6_cached_6xhxozi1\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-17datasource6_cached_6xhxozi1 to s3://kumaran-airt-service-eu-west-1/7/datasource/6\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-17datasource6_cached_6xhxozi1\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_m037i2ul\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSource(id=6, uuid=UUID('b2e4b635-f674-49c0-8997-8725f5e3934a'), hash=None, total_steps=1, completed_steps=1, folder_size=8158102, no_of_rows=None, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-1', error=None, disabled=False, path='s3://kumaran-airt-service-eu-west-1/7/datasource/6', created=datetime.datetime(2022, 11, 7, 9, 11, 11), user_id=7, pulled_on=None, tags=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    datasource = DataSource(\n",
    "        cloud_provider=\"aws\",\n",
    "        region=\"eu-west-1\",\n",
    "        total_steps=1,\n",
    "        user=user,\n",
    "    )\n",
    "\n",
    "    session.add(datasource)\n",
    "    session.commit()\n",
    "    session.refresh(datasource)\n",
    "\n",
    "    assert not datasource.folder_size\n",
    "    assert not datasource.no_of_rows\n",
    "    assert not datasource.path\n",
    "    assert not datasource.hash\n",
    "\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        destination_bucket, s3_path = create_s3_datasource_path(\n",
    "            user_id=datasource.user.id,\n",
    "            datasource_id=datasource.id,\n",
    "            region=datasource.region,\n",
    "        )\n",
    "        sleep(10)\n",
    "        with RemotePath.from_url(\n",
    "            remote_url=f\"s3://{destination_bucket.name}/{s3_path}\",\n",
    "            pull_on_enter=False,\n",
    "            push_on_exit=True,\n",
    "            exist_ok=True,\n",
    "            parents=True,\n",
    "        ) as destination_s3_path:\n",
    "            ddf = dd.read_parquet(test_s3_path.as_path()).set_index(\"PersonId\")\n",
    "            ddf.to_parquet(destination_s3_path.as_path())\n",
    "\n",
    "    calculate_data_object_folder_size_and_path(data_object=datasource)\n",
    "\n",
    "    assert datasource.folder_size\n",
    "    assert datasource.completed_steps == 1\n",
    "    assert (\n",
    "        datasource.path\n",
    "        == f\"s3://{os.environ['STORAGE_BUCKET_PREFIX']}-eu-west-1/{user.id}/datasource/{datasource.id}\"\n",
    "    ), datasource.path\n",
    "    display(datasource)\n",
    "    datasource_id = datasource.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def calculate_data_object_pulled_on(data_object: Union[DataBlob, DataSource]):\n",
    "    \"\"\"Calculate datasource/datablob's pulled_on datetime\n",
    "\n",
    "    Args:\n",
    "        data_object: DataBlob or DataSource object\n",
    "    \"\"\"\n",
    "    data_object.pulled_on = datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataSource(id=6, uuid=UUID('b2e4b635-f674-49c0-8997-8725f5e3934a'), hash=None, total_steps=1, completed_steps=0, folder_size=None, no_of_rows=None, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-1', error=None, disabled=False, path=None, created=datetime.datetime(2022, 11, 7, 9, 11, 11), user_id=7, pulled_on=datetime.datetime(2022, 11, 7, 9, 11, 39, 779266), tags=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    datasource = session.exec(\n",
    "        select(DataSource).where(DataSource.id == datasource_id)\n",
    "    ).one()\n",
    "    calculate_data_object_pulled_on(data_object=datasource)\n",
    "\n",
    "    display(datasource)\n",
    "    assert isinstance(datasource.pulled_on, datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def delete_data_object_files_in_cloud(\n",
    "    data_object: Union[DataBlob, DataSource, Model, Prediction]\n",
    "):\n",
    "    \"\"\"\n",
    "    Delete files for data object stored in cloud - aws or azure\n",
    "\n",
    "    Args:\n",
    "        data_object: object of type DataBlob, DataSource, Model, Prediction\n",
    "    \"\"\"\n",
    "\n",
    "    if (\n",
    "        data_object.completed_steps != data_object.total_steps\n",
    "        or data_object.disabled == True\n",
    "    ):\n",
    "        return\n",
    "\n",
    "    if data_object.cloud_provider == \"aws\":\n",
    "        bucket, s3_path = get_s3_bucket_and_path_from_uri(data_object.path)  # type: ignore\n",
    "        bucket.objects.filter(Prefix=s3_path + \"/\").delete()\n",
    "    elif data_object.cloud_provider == \"azure\":\n",
    "        container_client, _ = get_azure_blob_storage_container(\n",
    "            region=data_object.region\n",
    "        )\n",
    "        blob_folder = \"/\".join(\n",
    "            get_s3_bucket_name_and_folder_from_uri(data_object.path)[1].split(\"/\")[1:]\n",
    "        )\n",
    "        for blob in container_client.list_blobs(name_starts_with=blob_folder + \"/\"):\n",
    "            container_client.delete_blob(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('281b0e1d-4b09-4bc0-8540-b123c9c74d5a'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-1.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20221107/eu-west-1/s3/aws4_request', 'x-amz-date': '20221107T091140Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>DefinitionId</th>\n",
       "      <th>OccurredTime</th>\n",
       "      <th>OccurredTimeTicks</th>\n",
       "      <th>PersonId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__null_dask_index__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests2</td>\n",
       "      <td>2019-12-31 21:30:02</td>\n",
       "      <td>1577836802678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests3</td>\n",
       "      <td>2020-01-03 23:53:22</td>\n",
       "      <td>1578104602678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests1</td>\n",
       "      <td>2020-01-07 02:16:42</td>\n",
       "      <td>1578372402678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests2</td>\n",
       "      <td>2020-01-10 04:40:02</td>\n",
       "      <td>1578640202678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests3</td>\n",
       "      <td>2020-01-13 07:03:22</td>\n",
       "      <td>1578908002678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AccountId DefinitionId        OccurredTime  \\\n",
       "__null_dask_index__                                               \n",
       "0                       312571   loadTests2 2019-12-31 21:30:02   \n",
       "1                       312571   loadTests3 2020-01-03 23:53:22   \n",
       "2                       312571   loadTests1 2020-01-07 02:16:42   \n",
       "3                       312571   loadTests2 2020-01-10 04:40:02   \n",
       "4                       312571   loadTests3 2020-01-13 07:03:22   \n",
       "\n",
       "                     OccurredTimeTicks  PersonId  \n",
       "__null_dask_index__                               \n",
       "0                        1577836802678         2  \n",
       "1                        1578104602678         2  \n",
       "2                        1578372402678         2  \n",
       "3                        1578640202678         2  \n",
       "4                        1578908002678         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/_metadata'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/_common_metadata'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/file.csv'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/part.3.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/part.0.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/part.1.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/part.4.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym/part.2.parquet')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccountId,DefinitionId,OccurredTime,OccurredTimeTicks,PersonId\n",
      "312571,loadTests2,2019-12-31 21:30:02,1577836802678,2\n",
      "312571,loadTests3,2020-01-03 23:53:22,1578104602678,2\n",
      "312571,loadTests1,2020-01-07 02:16:42,1578372402678,2\n",
      "312571,loadTests2,2020-01-10 04:40:02,1578640202678,2\n",
      "312571,loadTests3,2020-01-13 07:03:22,1578908002678,2\n",
      "312571,loadTests1,2020-01-16 09:26:42,1579175802678,2\n",
      "312571,loadTests2,2020-01-19 11:50:02,1579443602678,2\n",
      "312571,loadTests3,2020-01-22 14:13:22,1579711402678,2\n",
      "312571,loadTests1,2020-01-25 16:36:42,1579979202678,2\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_1qgwyrym\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): processing user uploaded csv file for datablob_id=15 and uploading parquet back to S3 for datasource_id=8\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-1/7/datablob/15\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/7/datablob/15\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/7/datablob/15 locally in /tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-1/7/datablob/15 to /tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): step 2/4: running import_csv()\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-1/7/datasource/8\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-1/7/datasource/8 locally in /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21\n",
      "[INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_/file.csv] using blocksize='256MB' and kwargs={'usecols': [0, 1, 2, 3, 4], 'parse_dates': ['OccurredTime']} and storing result in /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21\n",
      "[INFO] airt.dask_manager: Starting cluster...\n",
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:43985' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "[INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt.dask_manager: Starting cluster...\n",
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:38055' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "[INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt.dask_manager: Starting cluster...\n",
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:45629' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:8787/status\n",
      "[INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and OccurredTime.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and OccurredTime.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21 as Parquet files with:\n",
      "[INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('<M8[ns]'), 'OccurredTimeTicks': dtype('int64')}\n",
      "[INFO] airt.data.importers:  - npartitions=1\n",
      "[INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-1/7/datasource/8, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21, access_key=None, secret_key=None)\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21 to s3://kumaran-airt-service-eu-west-1/7/datasource/8\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-17datasource8_cached_yauzgp21\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-17datablob15_cached_atzsz56_\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=15, datasource_id=8): completed\n"
     ]
    }
   ],
   "source": [
    "# Create and pull datablob, datasource to use in following tests\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "    from_local_request = FromLocalRequest(\n",
    "        path=\"tmp/test-folder/\", tag=\"my_csv_datasource_tag\"\n",
    "    )\n",
    "    from_local_response = from_local_start_route(\n",
    "        from_local_request=from_local_request,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        df = pd.read_parquet(test_s3_path.as_path())\n",
    "        display(df.head())\n",
    "        df.to_csv(test_s3_path.as_path() / \"file.csv\", index=False)\n",
    "        display(list(test_s3_path.as_path().glob(\"*\")))\n",
    "        !head -n 10 {test_s3_path.as_path()/\"file.csv\"}\n",
    "\n",
    "        upload_to_s3_with_retry(\n",
    "            test_s3_path.as_path() / \"file.csv\",\n",
    "            from_local_response.presigned[\"url\"],\n",
    "            from_local_response.presigned[\"fields\"],\n",
    "        )\n",
    "\n",
    "    datablob_id = session.exec(select(DataBlob).where(DataBlob.uuid == from_local_response.uuid)).one().id\n",
    "    datasource = DataSource(\n",
    "        datablob_id=datablob_id,\n",
    "        cloud_provider=\"aws\",\n",
    "        region=\"eu-west-1\",\n",
    "        total_steps=1,\n",
    "        user=user,\n",
    "    )\n",
    "    session.add(datasource)\n",
    "    session.commit()\n",
    "\n",
    "    process_csv(\n",
    "        datablob_id=datablob_id,\n",
    "        datasource_id=datasource.id,\n",
    "        deduplicate_data=True,\n",
    "        index_column=\"PersonId\",\n",
    "        sort_by=\"OccurredTime\",\n",
    "        blocksize=\"256MB\",\n",
    "        kwargs_json=json.dumps(\n",
    "            dict(\n",
    "                usecols=[0, 1, 2, 3, 4],\n",
    "                parse_dates=[\"OccurredTime\"],\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "datasource_id = datasource.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBlob(id=15, uuid=UUID('281b0e1d-4b09-4bc0-8540-b123c9c74d5a'), type='local', uri='s3://kumaran-airt-service-eu-west-1/7/datablob/15', source='tmp/test-folder/', total_steps=1, completed_steps=1, folder_size=28884010, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-1', error=None, disabled=False, path='s3://kumaran-airt-service-eu-west-1/7/datablob/15', created=datetime.datetime(2022, 11, 7, 9, 11, 40), user_id=7, pulled_on=None, tags=[Tag(id=1, name='my_csv_datasource_tag', created=datetime.datetime(2022, 11, 7, 9, 9, 59), uuid=UUID('d55a8018-b13c-4244-bbea-09ef8ee1483c')), Tag(id=2, name='latest', created=datetime.datetime(2022, 11, 7, 9, 9, 59), uuid=UUID('487ec313-1f51-498e-ad17-c29a9a10aa25'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'objects_in_bucket=[]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataSource(id=8, uuid=UUID('c60531e9-eafe-4076-af2d-2467c9d8e82e'), hash='1dd8ee7a0f96a48110dec6e25891d18d', total_steps=1, completed_steps=1, folder_size=6619982, no_of_rows=498961, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-1', error=None, disabled=False, path='s3://kumaran-airt-service-eu-west-1/7/datasource/8', created=datetime.datetime(2022, 11, 7, 9, 11, 51), user_id=7, pulled_on=datetime.datetime(2022, 11, 7, 9, 11, 57), tags=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'objects_in_bucket=[]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    datablob = session.exec(select(DataBlob).where(DataBlob.id == datablob_id)).one()\n",
    "    display(datablob)\n",
    "    delete_data_object_files_in_cloud(data_object=datablob)\n",
    "    bucket, s3_path = get_s3_bucket_and_path_from_uri(datablob.path)\n",
    "    objects_in_bucket = list(bucket.objects.filter(Prefix=s3_path + \"/\"))\n",
    "    display(f\"{objects_in_bucket=}\")\n",
    "    assert len(objects_in_bucket) == 0\n",
    "\n",
    "    datasource = session.exec(\n",
    "        select(DataSource).where(DataSource.id == datasource_id)\n",
    "    ).one()\n",
    "    display(datasource)\n",
    "    delete_data_object_files_in_cloud(data_object=datasource)\n",
    "    bucket, s3_path = get_s3_bucket_and_path_from_uri(datasource.path)\n",
    "    objects_in_bucket = list(bucket.objects.filter(Prefix=s3_path + \"/\"))\n",
    "    display(f\"{objects_in_bucket=}\")\n",
    "    assert len(objects_in_bucket) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
