{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7689dc52",
   "metadata": {},
   "source": [
    "---\n",
    "description: Router to have routes to get details for prediction_id\n",
    "output-file: model_prediction.html\n",
    "title: Model Prediction Router\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp model.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.testing.activate_by_import: Testing environment activated.\n",
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "[INFO] airt.keras.helpers: Using a single GPU #0 with memory_limit 1024 MB\n"
     ]
    }
   ],
   "source": [
    "from airt.testing import activate_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d1cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import airt_service.sanitizer\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from airt.logger import get_logger\n",
    "from airt.patching import patch\n",
    "from airt_service.auth import get_current_active_user\n",
    "from airt_service.aws.utils import get_s3_bucket_and_path_from_uri\n",
    "from airt_service.batch_job import create_batch_job\n",
    "from airt_service.data.clickhouse import create_db_uri_for_clickhouse_datablob\n",
    "from airt_service.data.datablob import (\n",
    "    AzureBlobStorageRequest,\n",
    "    ClickHouseRequest,\n",
    "    DBRequest,\n",
    "    S3Request,\n",
    ")\n",
    "from airt_service.data.utils import (\n",
    "    create_db_uri_for_azure_blob_storage_datablob,\n",
    "    create_db_uri_for_db_datablob,\n",
    "    create_db_uri_for_s3_datablob,\n",
    "    delete_data_object_files_in_cloud,\n",
    ")\n",
    "from airt_service.db.models import (\n",
    "    Model,\n",
    "    Prediction,\n",
    "    PredictionPush,\n",
    "    PredictionPushRead,\n",
    "    PredictionRead,\n",
    "    User,\n",
    "    get_session,\n",
    ")\n",
    "from airt_service.errors import ERRORS, HTTPError\n",
    "from airt_service.helpers import commit_or_rollback\n",
    "from botocore.client import Config\n",
    "from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Query, status\n",
    "from sqlalchemy.exc import NoResultFound\n",
    "from sqlmodel import Session, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.data.importers: Module loaded:\n",
      "[INFO] airt.data.importers:  - using pandas     : 1.5.1\n",
      "[INFO] airt.data.importers:  - using dask       : 2022.10.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import timedelta\n",
    "from os import environ\n",
    "\n",
    "import pytest\n",
    "import requests\n",
    "from airt.remote_path import RemotePath\n",
    "from airt_service.aws.utils import create_s3_prediction_path, upload_to_s3_with_retry\n",
    "from airt_service.background_task import execute_cli\n",
    "from airt_service.data.csv import process_csv\n",
    "from airt_service.data.datablob import FromLocalRequest, from_local_start_route\n",
    "from airt_service.data.s3 import copy_between_s3\n",
    "from airt_service.db.models import (\n",
    "    DataBlob,\n",
    "    DataSource,\n",
    "    create_user_for_testing,\n",
    "    get_session_with_context,\n",
    ")\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.model.train import TrainRequest, predict, predict_model, train_model\n",
    "from airt_service.users import (\n",
    "    ActivateMFARequest,\n",
    "    activate_mfa,\n",
    "    disable_mfa,\n",
    "    generate_mfa_url,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "from fastapi import BackgroundTasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed0d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbzinylejm'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing(subscription_type=\"small\")\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVALID_UUID_FOR_TESTING = \"00000000-0000-0000-0000-000000000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] botocore.credentials: Found credentials in environment variables.\n",
      "[INFO] airt_service.data.datablob: DataBlob.from_local(): FromLocalResponse(uuid=UUID('0199be8a-33ea-4faf-a128-e98b9b6ab2d2'), type='local', presigned={'url': 'https://kumaran-airt-service-eu-west-3.s3.amazonaws.com/', 'fields': {'key': '****************************************', 'x-amz-algorithm': 'AWS4-HMAC-SHA256', 'x-amz-credential': '********************/20221107/eu-west-3/s3/aws4_request', 'x-amz-date': '20221107T091002Z', 'policy': '************************************************************************************************************************************************************************************************************************************************************', 'x-amz-signature': '****************************'}})\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>DefinitionId</th>\n",
       "      <th>OccurredTime</th>\n",
       "      <th>OccurredTimeTicks</th>\n",
       "      <th>PersonId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__null_dask_index__</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests2</td>\n",
       "      <td>2019-12-31 21:30:02</td>\n",
       "      <td>1577836802678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests3</td>\n",
       "      <td>2020-01-03 23:53:22</td>\n",
       "      <td>1578104602678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests1</td>\n",
       "      <td>2020-01-07 02:16:42</td>\n",
       "      <td>1578372402678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests2</td>\n",
       "      <td>2020-01-10 04:40:02</td>\n",
       "      <td>1578640202678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312571</td>\n",
       "      <td>loadTests3</td>\n",
       "      <td>2020-01-13 07:03:22</td>\n",
       "      <td>1578908002678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AccountId DefinitionId        OccurredTime  \\\n",
       "__null_dask_index__                                               \n",
       "0                       312571   loadTests2 2019-12-31 21:30:02   \n",
       "1                       312571   loadTests3 2020-01-03 23:53:22   \n",
       "2                       312571   loadTests1 2020-01-07 02:16:42   \n",
       "3                       312571   loadTests2 2020-01-10 04:40:02   \n",
       "4                       312571   loadTests3 2020-01-13 07:03:22   \n",
       "\n",
       "                     OccurredTimeTicks  PersonId  \n",
       "__null_dask_index__                               \n",
       "0                        1577836802678         2  \n",
       "1                        1578104602678         2  \n",
       "2                        1578372402678         2  \n",
       "3                        1578640202678         2  \n",
       "4                        1578908002678         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/_metadata'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/_common_metadata'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/file.csv'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/part.3.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/part.0.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/part.1.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/part.4.parquet'),\n",
       " Path('/tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd/part.2.parquet')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccountId,DefinitionId,OccurredTime,OccurredTimeTicks,PersonId\n",
      "312571,loadTests2,2019-12-31 21:30:02,1577836802678,2\n",
      "312571,loadTests3,2020-01-03 23:53:22,1578104602678,2\n",
      "312571,loadTests1,2020-01-07 02:16:42,1578372402678,2\n",
      "312571,loadTests2,2020-01-10 04:40:02,1578640202678,2\n",
      "312571,loadTests3,2020-01-13 07:03:22,1578908002678,2\n",
      "312571,loadTests1,2020-01-16 09:26:42,1579175802678,2\n",
      "312571,loadTests2,2020-01-19 11:50:02,1579443602678,2\n",
      "312571,loadTests3,2020-01-22 14:13:22,1579711402678,2\n",
      "312571,loadTests1,2020-01-25 16:36:42,1579979202678,2\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached_hkhk7mdd\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): processing user uploaded csv file for datablob_id=2 and uploading parquet back to S3 for datasource_id=3\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): step 1/4: downloading user uploaded file from bucket s3://kumaran-airt-service-eu-west-3/5/datablob/2\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-3/5/datablob/2\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-3/5/datablob/2 locally in /tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-3/5/datablob/2 to /tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): step 2/4: running import_csv()\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-3/5/datasource/3\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-3/5/datasource/3 locally in /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87\n",
      "[INFO] airt.data.importers: import_csv(): importing CSV file(s) from [/tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc/file.csv,..., /tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc/file.csv] using blocksize='256MB' and kwargs={'usecols': [0, 1, 2, 3, 4], 'parse_dates': ['OccurredTime']} and storing result in /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87\n",
      "[INFO] airt.dask_manager: Starting cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/distributed/node.py:183: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39823 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:37791' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:39823/status\n",
      "[INFO] airt.data.importers: import_csv(): step 1/5: importing data and storing it into partitioned Parquet files\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt.dask_manager: Starting cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/distributed/node.py:183: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34097 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:35949' processes=4 threads=4, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:34097/status\n",
      "[INFO] airt.data.importers: import_csv(): step 2/5: indexing data by PersonId.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt.dask_manager: Starting cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.8/site-packages/distributed/node.py:183: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37737 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.dask_manager: Cluster started: <Client: 'tcp://127.0.0.1:43525' processes=8 threads=8, memory=22.89 GiB>\n",
      "Cluster dashboard: http://127.0.0.1:37737/status\n",
      "[INFO] airt.data.importers: import_csv(): step 3/5: deduplicating and sorting data by PersonId and OccurredTime.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): step 4/5: repartitioning data.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): step 5/5: sorting data by PersonId and OccurredTime.\n",
      "[INFO] airt.data.importers:  - number of rows: 498,961\n",
      "[INFO] airt.data.importers: import_csv(): completed, the final data is stored in /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87 as Parquet files with:\n",
      "[INFO] airt.data.importers:  - dtypes={'AccountId': dtype('int64'), 'DefinitionId': dtype('O'), 'OccurredTime': dtype('<M8[ns]'), 'OccurredTimeTicks': dtype('int64')}\n",
      "[INFO] airt.data.importers:  - npartitions=1\n",
      "[INFO] airt.data.importers:  - partition_sizes={0: 498961}\n",
      "[INFO] airt.dask_manager: Starting stopping cluster...\n",
      "[INFO] airt.dask_manager: Cluster stopped\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): step 3/4: uploading parquet files back to path S3Path(enter_count=1, remote_url=s3://kumaran-airt-service-eu-west-3/5/datasource/3, pull_on_enter=False, push_on_exit=True, cache_path=/tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87, access_key=None, secret_key=None)\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87 to s3://kumaran-airt-service-eu-west-3/5/datasource/3\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_nxg1zl87\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-35datablob2_cached_drb1c5jc\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): step 4/4: calculating datasource attributes - folder_size, no_of_rows, head, hash\n",
      "[INFO] airt_service.data.csv: process_csv(datablob_id=2, datasource_id=3): completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataSource(id=3, uuid=UUID('e0fc386d-c3a8-4651-b233-11f2a8f4a0bc'), hash='1dd8ee7a0f96a48110dec6e25891d18d', total_steps=1, completed_steps=1, folder_size=6619982, no_of_rows=498961, cloud_provider=<CloudProvider.aws: 'aws'>, region='eu-west-3', error=None, disabled=False, path='s3://kumaran-airt-service-eu-west-3/5/datasource/3', created=datetime.datetime(2022, 11, 7, 9, 10, 14), user_id=5, pulled_on=datetime.datetime(2022, 11, 7, 9, 10, 21), tags=[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Model(total_steps=5, path=None, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=0, datasource_id=3, client_column='AccountId', error=None, user_id=5, target_column='DefinitionId', region='eu-west-3', target='load*', disabled=False, predict_after=datetime.timedelta(days=20), created=datetime.datetime(2022, 11, 7, 9, 10, 42), timestamp_column=None, id=2, uuid=UUID('6c7cc50e-19be-4169-a1b5-8dbd5281a3d0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job: create_batch_job(): command='predict 2', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='predict 2', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-3/5/prediction/2\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_q24dpqqe\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-3/5/prediction/2 locally in /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_q24dpqqe\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-3/5/datasource/3\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_o30m774d\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-3/5/datasource/3 locally in /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_o30m774d\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://kumaran-airt-service-eu-west-3/5/datasource/3 to /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_o30m774d\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-35datasource3_cached_o30m774d\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_q24dpqqe to s3://kumaran-airt-service-eu-west-3/5/prediction/2\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_q24dpqqe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(disabled=False, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), error=None, total_steps=3, datasource_id=3, id=2, path=None, created=datetime.datetime(2022, 11, 7, 9, 10, 42), completed_steps=0, cloud_provider=<CloudProvider.aws: 'aws'>, model_id=2, region='eu-west-3')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and pull datasource to use in following tests\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "    from_local_request = FromLocalRequest(\n",
    "        path=\"tmp/test-folder/\", tag=\"my_csv_datasource_tag\", region=\"eu-west-3\"\n",
    "    )\n",
    "    from_local_response = from_local_start_route(\n",
    "        from_local_request=from_local_request,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    with RemotePath.from_url(\n",
    "        remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        pull_on_enter=True,\n",
    "        push_on_exit=False,\n",
    "        exist_ok=True,\n",
    "        parents=False,\n",
    "        access_key=environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        secret_key=environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    ) as test_s3_path:\n",
    "        df = pd.read_parquet(test_s3_path.as_path())\n",
    "        display(df.head())\n",
    "        df.to_csv(test_s3_path.as_path() / \"file.csv\", index=False)\n",
    "        display(list(test_s3_path.as_path().glob(\"*\")))\n",
    "        !head -n 10 {test_s3_path.as_path()/\"file.csv\"}\n",
    "\n",
    "        upload_to_s3_with_retry(\n",
    "            test_s3_path.as_path() / \"file.csv\",\n",
    "            from_local_response.presigned[\"url\"],\n",
    "            from_local_response.presigned[\"fields\"],\n",
    "        )\n",
    "\n",
    "    datablob_id = (\n",
    "        session.exec(select(DataBlob).where(DataBlob.uuid == from_local_response.uuid))\n",
    "        .one()\n",
    "        .id\n",
    "    )\n",
    "    datasource = DataSource(\n",
    "        datablob_id=datablob_id,\n",
    "        cloud_provider=\"aws\",\n",
    "        region=\"eu-west-3\",\n",
    "        total_steps=1,\n",
    "        user=user,\n",
    "    )\n",
    "    session.add(datasource)\n",
    "    session.commit()\n",
    "\n",
    "    process_csv(\n",
    "        datablob_id=datablob_id,\n",
    "        datasource_id=datasource.id,\n",
    "        deduplicate_data=True,\n",
    "        index_column=\"PersonId\",\n",
    "        sort_by=\"OccurredTime\",\n",
    "        blocksize=\"256MB\",\n",
    "        kwargs_json=json.dumps(\n",
    "            dict(\n",
    "                usecols=[0, 1, 2, 3, 4],\n",
    "                parse_dates=[\"OccurredTime\"],\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    datasource = session.exec(\n",
    "        select(DataSource).where(DataSource.id == datasource.id)\n",
    "    ).one()\n",
    "    display(datasource)\n",
    "\n",
    "    train_request = TrainRequest(\n",
    "        data_uuid=datasource.uuid,\n",
    "        client_column=\"AccountId\",\n",
    "        target_column=\"DefinitionId\",\n",
    "        target=\"load*\",\n",
    "        predict_after=timedelta(seconds=20 * 24 * 60 * 60),\n",
    "    )\n",
    "\n",
    "    model = train_model(train_request=train_request, user=user, session=session)\n",
    "    display(model)\n",
    "    # Call exec_cli train_model\n",
    "\n",
    "    b = BackgroundTasks()\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        predicted = predict_model(\n",
    "            model_uuid=model.uuid, user=user, session=session, background_tasks=b\n",
    "        )\n",
    "\n",
    "        predict(prediction_id=predicted.id)\n",
    "    display(predicted)\n",
    "    # Call exec_cli predict_model\n",
    "\n",
    "    datasource_id = datasource.id\n",
    "    datasource_cloud_provider = datasource.cloud_provider\n",
    "    datasource_region = datasource.region\n",
    "    predicted_id = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Default router for all train routes\n",
    "model_prediction_router = APIRouter(\n",
    "    prefix=\"/prediction\",\n",
    "    tags=[\"prediction\"],\n",
    "    #     dependencies=[Depends(get_current_active_user)],\n",
    "    responses={\n",
    "        404: {\"description\": \"Not found\"},\n",
    "        500: {\n",
    "            \"model\": HTTPError,\n",
    "            \"description\": ERRORS[\"INTERNAL_SERVER_ERROR\"],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "get_prediction_responses = {\n",
    "    400: {\"model\": HTTPError, \"description\": ERRORS[\"INCORRECT_PREDICTION_ID\"]}\n",
    "}\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "def get(cls: Prediction, uuid: str, user: User, session: Session) -> Prediction:\n",
    "    \"\"\"Get prediction object for given prediction uuid\n",
    "\n",
    "    Args:\n",
    "        uuid: UUID of prediction\n",
    "        user: User object\n",
    "        session: Sqlmodel session\n",
    "    Returns:\n",
    "        The prediction object for given prediction uuid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prediction = session.exec(\n",
    "            select(Prediction)\n",
    "            .where(Prediction.uuid == uuid)\n",
    "            .join(Model)\n",
    "            .where(Model.user == user)\n",
    "        ).one()\n",
    "    except NoResultFound:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=ERRORS[\"INCORRECT_PREDICTION_ID\"],\n",
    "        )\n",
    "\n",
    "    if prediction.disabled:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=ERRORS[\"PREDICTION_IS_DELETED\"],\n",
    "        )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(total_steps=3, error=None, disabled=False, id=2, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=3, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 42), path='s3://kumaran-airt-service-eu-west-3/5/prediction/2', model_id=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ExceptionInfo HTTPException(status_code=400, detail='The prediction uuid is incorrect. Please try again.') tblen=2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ExceptionInfo HTTPException(status_code=400, detail='The prediction uuid is incorrect. Please try again.') tblen=2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "\n",
    "    expected = predicted\n",
    "    actual = Prediction.get(uuid=expected.uuid, user=user, session=session)\n",
    "    display(actual)\n",
    "    assert actual == expected\n",
    "\n",
    "    with pytest.raises(HTTPException) as e:\n",
    "        Prediction.get(uuid=INVALID_UUID_FOR_TESTING, user=user, session=session)\n",
    "    display(e)\n",
    "\n",
    "    user_kumaran = session.exec(select(User).where(User.username == \"kumaran\")).one()\n",
    "    with pytest.raises(HTTPException) as e:\n",
    "        Prediction.get(uuid=expected.uuid, user=user_kumaran, session=session)\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6050315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExceptionInfo HTTPException(status_code=400, detail='The prediction has already been deleted.') tblen=2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "    datasource = user.datasources[0]\n",
    "    model = user.models[0]\n",
    "    prediction_disabled = Prediction(\n",
    "        total_steps=3,\n",
    "        user=user,\n",
    "        model=model,\n",
    "        datasource_id=datasource.id,\n",
    "        cloud_provider=datasource.cloud_provider,\n",
    "        region=datasource.region,\n",
    "        disabled=True,\n",
    "    )\n",
    "    session.add(prediction_disabled)\n",
    "    session.commit()\n",
    "    session.refresh(prediction_disabled)\n",
    "\n",
    "    with pytest.raises(HTTPException) as e:\n",
    "        Prediction.get(uuid=prediction_disabled.uuid, user=user, session=session)\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed95d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.get(\n",
    "    \"/{prediction_uuid}\",\n",
    "    response_model=PredictionRead,\n",
    "    responses={\n",
    "        **get_prediction_responses,  # type: ignore\n",
    "        422: {\"model\": HTTPError, \"description\": \"Prediction error\"},\n",
    "    },\n",
    ")\n",
    "def get_details_of_prediction(\n",
    "    prediction_uuid: str,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> Prediction:\n",
    "    \"\"\"Get details of the prediction\"\"\"\n",
    "    user = session.merge(user)\n",
    "    # get details from the internal db for prediction_id\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    if prediction.error is not None:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail=prediction.error\n",
    "        )\n",
    "\n",
    "    session.add(prediction)\n",
    "    session.commit()\n",
    "    session.refresh(prediction)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc8f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(total_steps=3, error=None, disabled=False, id=2, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=3, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 42), path='s3://kumaran-airt-service-eu-west-3/5/prediction/2', model_id=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "    # predicted = session.merge(predicted)\n",
    "\n",
    "    expected = predicted\n",
    "    actual = get_details_of_prediction(\n",
    "        prediction_uuid=expected.uuid, user=user, session=session\n",
    "    )\n",
    "    display(actual)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448d992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExceptionInfo HTTPException(status_code=422, detail='test error') tblen=2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    model = session.merge(model)\n",
    "    prediction_errored = Prediction(\n",
    "        total_steps=3,\n",
    "        user=user,\n",
    "        model=model,\n",
    "        datasource_id=datasource_id,\n",
    "        cloud_provider=datasource_cloud_provider,\n",
    "        region=datasource_region,\n",
    "        error=\"test error\",\n",
    "    )\n",
    "\n",
    "    session.add(prediction_errored)\n",
    "    session.commit()\n",
    "    session.refresh(prediction_errored)\n",
    "\n",
    "    with pytest.raises(HTTPException) as e:\n",
    "        get_details_of_prediction(\n",
    "            prediction_uuid=prediction_errored.uuid, user=user, session=session\n",
    "        )\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aba9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.delete(\n",
    "    \"/{prediction_uuid}\",\n",
    "    response_model=PredictionRead,\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def delete_prediction(\n",
    "    prediction_uuid: str,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> Prediction:\n",
    "    \"\"\"Delete prediction\"\"\"\n",
    "    user = session.merge(user)\n",
    "    # get details from the internal db for prediction_id\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    delete_data_object_files_in_cloud(data_object=prediction)\n",
    "    prediction.disabled = True\n",
    "\n",
    "    session.add(prediction)\n",
    "    session.commit()\n",
    "    session.refresh(prediction)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575de27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(total_steps=3, error=None, disabled=True, id=5, uuid=UUID('16700048-68b8-4293-9982-faf4e03b3d3f'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=0, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 57), path=None, model_id=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    model = session.merge(model)\n",
    "    prediction = Prediction(\n",
    "        total_steps=3,\n",
    "        user=user,\n",
    "        model=model,\n",
    "        datasource_id=datasource_id,\n",
    "        cloud_provider=datasource_cloud_provider,\n",
    "        region=datasource_region,\n",
    "    )\n",
    "    session.add(prediction)\n",
    "    session.commit()\n",
    "    session.refresh(prediction)\n",
    "\n",
    "    actual = delete_prediction(\n",
    "        prediction_uuid=prediction.uuid, user=user, session=session\n",
    "    )\n",
    "    display(actual)\n",
    "    assert actual.disabled == True\n",
    "    # assert not Path(actual.path).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcff22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.get(\n",
    "    \"/{prediction_uuid}/pandas\", responses=get_prediction_responses  # type: ignore\n",
    ")\n",
    "def prediction_pandas(\n",
    "    prediction_uuid: str,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> Dict[str, List[Any]]:\n",
    "    \"\"\"Get prediction result as dictionary\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "    # return prediction pandas as list\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_id\": [\n",
    "                520088904,\n",
    "                530496790,\n",
    "                561587266,\n",
    "                518085591,\n",
    "                558856683,\n",
    "                520772685,\n",
    "                514028527,\n",
    "                518574284,\n",
    "                532364121,\n",
    "                532647354,\n",
    "            ],\n",
    "            \"Score\": [\n",
    "                0.979853,\n",
    "                0.979157,\n",
    "                0.979055,\n",
    "                0.978915,\n",
    "                0.977960,\n",
    "                0.004043,\n",
    "                0.003890,\n",
    "                0.001346,\n",
    "                0.001341,\n",
    "                0.001139,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    return df.to_dict(\"list\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca1726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': [520088904,\n",
       "  530496790,\n",
       "  561587266,\n",
       "  518085591,\n",
       "  558856683,\n",
       "  520772685,\n",
       "  514028527,\n",
       "  518574284,\n",
       "  532364121,\n",
       "  532647354],\n",
       " 'Score': [0.979853,\n",
       "  0.979157,\n",
       "  0.979055,\n",
       "  0.978915,\n",
       "  0.97796,\n",
       "  0.004043,\n",
       "  0.00389,\n",
       "  0.001346,\n",
       "  0.001341,\n",
       "  0.001139]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "\n",
    "    actual = prediction_pandas(\n",
    "        prediction_uuid=predicted.uuid, user=user, session=session\n",
    "    )\n",
    "    display(actual)\n",
    "    assert isinstance(actual, dict)\n",
    "    assert \"user_id\" in actual\n",
    "    assert \"Score\" in actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9682acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_local(\n",
    "    self: Prediction,\n",
    "    session: Session,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Download prediction results to local\n",
    "\n",
    "    Args:\n",
    "        session: Session object\n",
    "\n",
    "    Returns:\n",
    "        The Download url of the prediction as a dict\n",
    "    \"\"\"\n",
    "    bucket, s3_path = get_s3_bucket_and_path_from_uri(self.path)  # type: ignore\n",
    "\n",
    "    client = boto3.client(\n",
    "        \"s3\",\n",
    "        region_name=self.region,\n",
    "        config=Config(signature_version=\"s3v4\"),\n",
    "        endpoint_url=f\"https://s3.{self.region}.amazonaws.com\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        Path(s3_file.key).name: client.generate_presigned_url(\n",
    "            \"get_object\",\n",
    "            Params={\n",
    "                \"Bucket\": str(bucket.name).strip(),\n",
    "                \"Key\": str(s3_file.key).strip(),\n",
    "            },\n",
    "            ExpiresIn=60 * 60 * 24,\n",
    "        )\n",
    "        for s3_file in bucket.objects.filter(Prefix=s3_path + \"/\")\n",
    "        if Path(s3_file.key).name != str(self.id)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.get(\n",
    "    \"/{prediction_uuid}/to_local\",\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def prediction_to_local_route(\n",
    "    prediction_uuid: str,\n",
    "    *,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Get dict of filename, presigned url to download prediction parquet files\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    return prediction.to_local(session)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d70d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://kumaran-airt-service-eu-west-3/5/prediction/2\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_kfl2nrzu\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://kumaran-airt-service-eu-west-3/5/prediction/2 locally in /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_kfl2nrzu\n",
      "[INFO] airt.remote_path: RemotePath.from_url(): creating remote path with the following url s3://test-airt-service/account_312571_events\n",
      "[INFO] airt.remote_path: S3Path._create_cache_path(): created cache path: /tmp/s3test-airt-serviceaccount_312571_events_cached__b6pb_87\n",
      "[INFO] airt.remote_path: S3Path.__init__(): created object for accessing s3://test-airt-service/account_312571_events locally in /tmp/s3test-airt-serviceaccount_312571_events_cached__b6pb_87\n",
      "[INFO] airt.remote_path: S3Path.__enter__(): pulling data from s3://test-airt-service/account_312571_events to /tmp/s3test-airt-serviceaccount_312571_events_cached__b6pb_87\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3test-airt-serviceaccount_312571_events_cached__b6pb_87\n",
      "[INFO] airt.remote_path: S3Path.__exit__(): pushing data from /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_kfl2nrzu to s3://kumaran-airt-service-eu-west-3/5/prediction/2\n",
      "[INFO] airt.remote_path: S3Path._clean_up(): removing local cache path /tmp/s3kumaran-airt-service-eu-west-35prediction2_cached_kfl2nrzu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_common_metadata': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/_common_metadata?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=53edc87e55dc0a1bc0beccd6697d08ced20dd609e93a48a91c576278222158e8',\n",
       " '_metadata': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/_metadata?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=859b0a0ba10218a84242f35ce16ce7f1f0686817636c6e2768752e365731ded9',\n",
       " 'part.0.parquet': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/part.0.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=902d193eba3055d3932cf49d1c20e2dfe14c43126b5d93c32f4218cafacd7946',\n",
       " 'part.1.parquet': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/part.1.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f4eda2f41d787b1876429f34ec712963bfb5fb8d70ae8a8b96f88dde6fb498bc',\n",
       " 'part.2.parquet': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/part.2.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5f7d38c71e2b1f67d955f79e3599b4969d139203bde9d75aee020f915491b87b',\n",
       " 'part.3.parquet': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/part.3.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b4d9d338eea85eacb4afbed32d8a92af84eafabef1800bfb480a1a2036ca0180',\n",
       " 'part.4.parquet': 'https://s3.eu-west-3.amazonaws.com/kumaran-airt-service-eu-west-3/5/prediction/2/part.4.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=********************%2F20221107%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221107T091113Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=f4e88f9bb2fdcd12f7b812e65904d7498b455fa15744968708e4b4264d98c0c3'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "    bucket, s3_path = create_s3_prediction_path(\n",
    "        user_id=predicted.model.user_id,\n",
    "        prediction_id=predicted.id,\n",
    "        region=predicted.region,\n",
    "    )\n",
    "    copy_between_s3(\n",
    "        source_remote_url=f\"s3://test-airt-service/account_312571_events\",\n",
    "        destination_remote_url=f\"s3://{bucket.name}/{s3_path}\",\n",
    "    )\n",
    "\n",
    "    actual = prediction_to_local_route(\n",
    "        prediction_uuid=predicted.uuid,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    display(actual)\n",
    "\n",
    "    expected_keys = [\n",
    "        \"_common_metadata\",\n",
    "        \"_metadata\",\n",
    "        \"part.0.parquet\",\n",
    "        \"part.1.parquet\",\n",
    "        \"part.2.parquet\",\n",
    "        \"part.3.parquet\",\n",
    "        \"part.4.parquet\",\n",
    "    ]\n",
    "    assert sorted(actual.keys()) == sorted(expected_keys)\n",
    "\n",
    "    for filename, presigned_url in actual.items():\n",
    "        resp = requests.get(presigned_url)\n",
    "        assert resp.ok, f\"{resp=}, {resp.text=}, {filename=}, {presigned_url=}\"\n",
    "\n",
    "    display(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e65675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_s3(\n",
    "    self: Prediction,\n",
    "    s3_request: S3Request,\n",
    "    session: Session,\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to S3\n",
    "\n",
    "    Args:\n",
    "        s3_request: S3Request object\n",
    "        session: session\n",
    "\n",
    "    Returns:\n",
    "        An object of PredictionPush\n",
    "    \"\"\"\n",
    "    uri = create_db_uri_for_s3_datablob(\n",
    "        uri=s3_request.uri,\n",
    "        access_key=s3_request.access_key,\n",
    "        secret_key=s3_request.secret_key,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with commit_or_rollback(session):\n",
    "            prediction_push = PredictionPush(\n",
    "                total_steps=1,\n",
    "                prediction_id=self.id,\n",
    "                uri=uri,\n",
    "            )\n",
    "            session.add(prediction_push)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        error_message = (\n",
    "            e._message() if callable(getattr(e, \"_message\", None)) else str(e)  # type: ignore\n",
    "        )\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=error_message,\n",
    "        )\n",
    "\n",
    "    command = f\"s3_push {prediction_push.id}\"\n",
    "\n",
    "    create_batch_job(\n",
    "        command=command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=self.cloud_provider,\n",
    "        region=self.region,\n",
    "        background_tasks=background_tasks,\n",
    "    )\n",
    "\n",
    "    return prediction_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f06bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.post(\n",
    "    \"/{prediction_uuid}/to_s3\",\n",
    "    response_model=PredictionPushRead,\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def prediction_to_s3_route(\n",
    "    prediction_uuid: str,\n",
    "    *,\n",
    "    s3_request: S3Request,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to s3\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    return prediction.to_s3(s3_request, session, background_tasks)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f38b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(total_steps=3, error=None, disabled=False, id=2, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=3, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 42), path='s3://kumaran-airt-service-eu-west-3/5/prediction/2', model_id=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job: create_batch_job(): command='s3_push 1', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='s3_push 1', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionPush(id=1, uuid=UUID('18fcf4d5-2e01-498b-b91c-5281066acde4'), uri='s3://****************************************@bucket', total_steps=1, completed_steps=0, error=None, created=datetime.datetime(2022, 11, 7, 9, 11, 24), prediction_id=2, )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.func=<function execute_cli>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.args=()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bg_task.kwargs={'command': 's3_push 1'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from time import sleep\n",
    "# sleep(5)\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "    display(predicted)\n",
    "    # predicted = session.merge(predicted)\n",
    "\n",
    "    s3_request = S3Request(\n",
    "        uri=\"s3://bucket\",\n",
    "        access_key=\"access\",\n",
    "        secret_key=\"secret\",\n",
    "    )\n",
    "    b = BackgroundTasks()\n",
    "\n",
    "    # Test using FastAPIBatchJobContext with set_env_variable_context\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        actual = prediction_to_s3_route(\n",
    "            prediction_uuid=predicted.uuid,\n",
    "            s3_request=s3_request,\n",
    "            user=user,\n",
    "            session=session,\n",
    "            background_tasks=b,\n",
    "        )\n",
    "    display(actual)\n",
    "    assert isinstance(actual, PredictionPush)\n",
    "    assert actual.prediction_id == predicted.id\n",
    "\n",
    "    bg_task = b.tasks[-1]\n",
    "    display(f\"{bg_task.func=}\", f\"{bg_task.args=}\", f\"{bg_task.kwargs=}\")\n",
    "    assert bg_task.func == execute_cli\n",
    "    assert bg_task.kwargs[\"command\"] == f\"s3_push {actual.id}\"\n",
    "\n",
    "    prediction_push = actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11950db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_azure_blob_storage(\n",
    "    self: Prediction,\n",
    "    azure_blob_storage_request: AzureBlobStorageRequest,\n",
    "    session: Session,\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction reslults to azure blob storage\n",
    "\n",
    "    Args:\n",
    "        azure_blob_storage_request: AzureBlobStorageRequest object\n",
    "        session: session\n",
    "\n",
    "    Returns:\n",
    "        An object of PredictionPush\n",
    "    \"\"\"\n",
    "    uri = create_db_uri_for_azure_blob_storage_datablob(\n",
    "        uri=azure_blob_storage_request.uri,\n",
    "        credential=azure_blob_storage_request.credential,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with commit_or_rollback(session):\n",
    "            prediction_push = PredictionPush(\n",
    "                total_steps=1,\n",
    "                prediction_id=self.id,\n",
    "                uri=uri,\n",
    "            )\n",
    "            session.add(prediction_push)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        error_message = (\n",
    "            e._message() if callable(getattr(e, \"_message\", None)) else str(e)  # type: ignore\n",
    "        )\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=error_message,\n",
    "        )\n",
    "\n",
    "    command = f\"azure_blob_storage_push {prediction_push.id}\"\n",
    "\n",
    "    create_batch_job(\n",
    "        command=command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=self.cloud_provider,\n",
    "        region=self.region,\n",
    "        background_tasks=background_tasks,\n",
    "    )\n",
    "\n",
    "    return prediction_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.post(\n",
    "    \"/{prediction_uuid}/to_azure_blob_storage\",\n",
    "    response_model=PredictionPushRead,\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def prediction_to_azure_blob_storage_route(\n",
    "    prediction_uuid: str,\n",
    "    *,\n",
    "    azure_blob_storage_request: AzureBlobStorageRequest,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to s3\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    return prediction.to_azure_blob_storage(azure_blob_storage_request, session, background_tasks)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64962c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(total_steps=3, error=None, disabled=False, id=2, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=3, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 42), path='s3://kumaran-airt-service-eu-west-3/5/prediction/2', model_id=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] azure.identity._credentials.environment: Environment is configured for ClientSecretCredential\n",
      "[INFO] azure.identity._credentials.managed_identity: ManagedIdentityCredential will use IMDS\n",
      "[INFO] azure.identity._credentials.chained: DefaultAzureCredential acquired a token from EnvironmentCredential\n",
      "[INFO] airt_service.batch_job: create_batch_job(): command='azure_blob_storage_push 2', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='azure_blob_storage_push 2', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionPush(id=2, uuid=UUID('144f70c8-2375-4fec-90e4-568bb7c0799d'), uri='https://****************************************@testairtservice.blob.core.windows.net/push-container', total_steps=1, completed_steps=0, error=None, created=datetime.datetime(2022, 11, 7, 9, 11, 25), prediction_id=2, )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.func=<function execute_cli>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.args=()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bg_task.kwargs={'command': 'azure_blob_storage_push 2'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "    display(predicted)\n",
    "    # predicted = session.merge(predicted)\n",
    "\n",
    "    storage_client = StorageManagementClient(\n",
    "        DefaultAzureCredential(), environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "    )\n",
    "    keys = storage_client.storage_accounts.list_keys(\n",
    "        \"test-airt-service\", \"testairtservice\"\n",
    "    )\n",
    "    credential = keys.keys[0].value\n",
    "\n",
    "    azure_blob_storage_request = AzureBlobStorageRequest(\n",
    "        uri=\"https://testairtservice.blob.core.windows.net/push-container\",\n",
    "        credential=credential,\n",
    "    )\n",
    "    b = BackgroundTasks()\n",
    "\n",
    "    # Test using FastAPIBatchJobContext with set_env_variable_context\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        actual = prediction_to_azure_blob_storage_route(\n",
    "            prediction_uuid=predicted.uuid,\n",
    "            azure_blob_storage_request=azure_blob_storage_request,\n",
    "            user=user,\n",
    "            session=session,\n",
    "            background_tasks=b,\n",
    "        )\n",
    "    display(actual)\n",
    "    assert isinstance(actual, PredictionPush)\n",
    "    assert actual.prediction_id == predicted.id\n",
    "\n",
    "    bg_task = b.tasks[-1]\n",
    "    display(f\"{bg_task.func=}\", f\"{bg_task.args=}\", f\"{bg_task.kwargs=}\")\n",
    "    assert bg_task.func == execute_cli\n",
    "    assert bg_task.kwargs[\"command\"] == f\"azure_blob_storage_push {actual.id}\"\n",
    "\n",
    "    prediction_push = actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_rdbms(\n",
    "    self: Prediction,\n",
    "    db_request: DBRequest,\n",
    "    database_server: str,\n",
    "    session: Session,\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction resluts to a relational database\n",
    "\n",
    "    Args:\n",
    "        db_request: DBRequest object\n",
    "        database_server: Database server to push the results\n",
    "        session: Session object\n",
    "\n",
    "    Returns:\n",
    "        An object of PredictionPush\n",
    "    \"\"\"\n",
    "    if database_server not in [\"mysql\", \"postgresql\"]:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_501_NOT_IMPLEMENTED,\n",
    "            detail=f\"{ERRORS['PUSH_NOT_AVAILABLE']} for database server {database_server}\",\n",
    "        )\n",
    "\n",
    "    uri = create_db_uri_for_db_datablob(\n",
    "        username=db_request.username,\n",
    "        password=db_request.password,\n",
    "        host=db_request.host,\n",
    "        port=db_request.port,\n",
    "        table=db_request.table,\n",
    "        database=db_request.database,\n",
    "        database_server=database_server,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with commit_or_rollback(session):\n",
    "            prediction_push = PredictionPush(\n",
    "                total_steps=1,\n",
    "                prediction_id=self.id,\n",
    "                uri=uri,\n",
    "            )\n",
    "            session.add(prediction_push)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        error_message = (\n",
    "            e._message() if callable(getattr(e, \"_message\", None)) else str(e)  # type: ignore\n",
    "        )\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=error_message,\n",
    "        )\n",
    "\n",
    "    command = f\"db_push {prediction_push.id}\"\n",
    "\n",
    "    create_batch_job(\n",
    "        command=command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=self.cloud_provider,\n",
    "        region=self.region,\n",
    "        background_tasks=background_tasks,\n",
    "    )\n",
    "\n",
    "    return prediction_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.post(\n",
    "    \"/{prediction_uuid}/to_mysql\",\n",
    "    response_model=PredictionPushRead,\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def prediction_to_mysql_route(\n",
    "    prediction_uuid: str,\n",
    "    *,\n",
    "    db_request: DBRequest,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to mysql database\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    return prediction.to_rdbms(  # type: ignore\n",
    "        db_request=db_request,\n",
    "        database_server=\"mysql\",\n",
    "        session=session,\n",
    "        background_tasks=background_tasks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eb93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job: create_batch_job(): command='db_push 3', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='db_push 3', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionPush(id=3, uuid=UUID('58c4a36e-d17a-4a54-bdf3-eb84335a3ec3'), uri='mysql://****************************************@db.example.com:3306/database_to_import/events', total_steps=1, completed_steps=0, error=None, created=datetime.datetime(2022, 11, 7, 9, 11, 25), prediction_id=2, )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.func=<function execute_cli>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.args=()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bg_task.kwargs={'command': 'db_push 3'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "\n",
    "    db_request = DBRequest(\n",
    "        host=\"db.example.com\",\n",
    "        port=3306,\n",
    "        username=\"username\",\n",
    "        password=\"password\",\n",
    "        database=\"database_to_import\",\n",
    "        table=\"events\",\n",
    "    )\n",
    "    b = BackgroundTasks()\n",
    "\n",
    "    # Test using FastAPIBatchJobContext with set_env_variable_context\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        actual = prediction_to_mysql_route(\n",
    "            prediction_uuid=predicted.uuid,\n",
    "            db_request=db_request,\n",
    "            user=user,\n",
    "            session=session,\n",
    "            background_tasks=b,\n",
    "        )\n",
    "    display(actual)\n",
    "    assert isinstance(actual, PredictionPush)\n",
    "    assert actual.prediction_id == predicted.id\n",
    "\n",
    "    bg_task = b.tasks[-1]\n",
    "    display(f\"{bg_task.func=}\", f\"{bg_task.args=}\", f\"{bg_task.kwargs=}\")\n",
    "    assert bg_task.func == execute_cli\n",
    "    assert bg_task.kwargs[\"command\"] == f\"db_push {actual.id}\"\n",
    "\n",
    "    prediction_push = actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dabdaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@patch\n",
    "def to_clickhouse(\n",
    "    self: Prediction,\n",
    "    clickhouse_request: ClickHouseRequest,\n",
    "    session: Session,\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to a clickhouse database\n",
    "\n",
    "    Args:\n",
    "        clickhouse_request: ClickHouseRequest object\n",
    "        session: Session object\n",
    "        background_tasks: BackgroundTasks object\n",
    "\n",
    "    Returns:\n",
    "        An object of PredictionPush\n",
    "    \"\"\"\n",
    "\n",
    "    uri = create_db_uri_for_clickhouse_datablob(\n",
    "        username=clickhouse_request.username,\n",
    "        password=clickhouse_request.password,\n",
    "        host=clickhouse_request.host,\n",
    "        port=clickhouse_request.port,\n",
    "        table=clickhouse_request.table,\n",
    "        database=clickhouse_request.database,\n",
    "        protocol=clickhouse_request.protocol,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with commit_or_rollback(session):\n",
    "            prediction_push = PredictionPush(\n",
    "                total_steps=1,\n",
    "                prediction_id=self.id,\n",
    "                uri=uri,\n",
    "            )\n",
    "            session.add(prediction_push)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        error_message = (\n",
    "            e._message() if callable(getattr(e, \"_message\", None)) else str(e)  # type: ignore\n",
    "        )\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=error_message,\n",
    "        )\n",
    "\n",
    "    command = f\"clickhouse_push {prediction_push.id}\"\n",
    "\n",
    "    create_batch_job(\n",
    "        command=command,\n",
    "        task=\"csv_processing\",\n",
    "        cloud_provider=self.cloud_provider,\n",
    "        region=self.region,\n",
    "        background_tasks=background_tasks,\n",
    "    )\n",
    "\n",
    "    return prediction_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad73469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.post(\n",
    "    \"/{prediction_uuid}/to_clickhouse\",\n",
    "    response_model=PredictionPushRead,\n",
    "    responses=get_prediction_responses,  # type: ignore\n",
    ")\n",
    "def prediction_to_clickhouse_route(\n",
    "    prediction_uuid: str,\n",
    "    *,\n",
    "    clickhouse_request: ClickHouseRequest,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    "    background_tasks: BackgroundTasks,\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to clickhouse database\"\"\"\n",
    "    user = session.merge(user)\n",
    "    prediction = Prediction.get(uuid=prediction_uuid, user=user, session=session)  # type: ignore\n",
    "\n",
    "    return prediction.to_clickhouse(  # type: ignore\n",
    "        clickhouse_request=clickhouse_request,\n",
    "        session=session,\n",
    "        background_tasks=background_tasks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a7b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] airt_service.batch_job: create_batch_job(): command='clickhouse_push 4', task='csv_processing'\n",
      "[INFO] airt_service.batch_job_components.base: Entering FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job: batch_ctx=FastAPIBatchJobContext(task=csv_processing)\n",
      "[INFO] airt_service.batch_job_components.fastapi: FastAPIBatchJobContext.create_job(self=FastAPIBatchJobContext(task=csv_processing), command='clickhouse_push 4', environment_vars={'AWS_ACCESS_KEY_ID': '********************', 'AWS_SECRET_ACCESS_KEY': '****************************************', 'AWS_DEFAULT_REGION': 'eu-west-1', 'AZURE_SUBSCRIPTION_ID': '************************************', 'AZURE_TENANT_ID': '************************************', 'AZURE_CLIENT_ID': '************************************', 'AZURE_CLIENT_SECRET': '****************************************', 'AZURE_STORAGE_ACCOUNT_PREFIX': 'kumsairtsdev', 'AZURE_RESOURCE_GROUP': 'kumaran-airt-service-dev', 'STORAGE_BUCKET_PREFIX': 'kumaran-airt-service', 'DB_USERNAME': 'root', 'DB_PASSWORD': '****************************************', 'DB_HOST': 'kumaran-mysql', 'DB_PORT': '3306', 'DB_DATABASE': 'airt_service', 'DB_DATABASE_SERVER': 'mysql'})\n",
      "[INFO] airt_service.batch_job_components.base: Exiting FastAPIBatchJobContext(task=csv_processing): exc_type=None, exc=None, None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionPush(id=4, uuid=UUID('162d40a0-318f-45f7-b2aa-9a3e1b9b2123'), uri='clickhouse+native://****************************************@db.example.com:3306/database_to_import/events', total_steps=1, completed_steps=0, error=None, created=datetime.datetime(2022, 11, 7, 9, 11, 25), prediction_id=2, )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.func=<function execute_cli>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bg_task.args=()'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bg_task.kwargs={'command': 'clickhouse_push 4'}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    predicted = session.exec(\n",
    "        select(Prediction).where(Prediction.id == predicted.id)\n",
    "    ).one()\n",
    "\n",
    "    clickhouse_request = ClickHouseRequest(\n",
    "        host=\"db.example.com\",\n",
    "        port=3306,\n",
    "        username=\"username\",\n",
    "        password=\"password\",\n",
    "        database=\"database_to_import\",\n",
    "        table=\"events\",\n",
    "        protocol=\"native\",\n",
    "    )\n",
    "    b = BackgroundTasks()\n",
    "\n",
    "    # Test using FastAPIBatchJobContext with set_env_variable_context\n",
    "    with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "        actual = prediction_to_clickhouse_route(\n",
    "            prediction_uuid=predicted.uuid,\n",
    "            clickhouse_request=clickhouse_request,\n",
    "            user=user,\n",
    "            session=session,\n",
    "            background_tasks=b,\n",
    "        )\n",
    "    display(actual)\n",
    "    assert isinstance(actual, PredictionPush)\n",
    "    assert actual.prediction_id == predicted.id\n",
    "\n",
    "    bg_task = b.tasks[-1]\n",
    "    display(f\"{bg_task.func=}\", f\"{bg_task.args=}\", f\"{bg_task.kwargs=}\")\n",
    "    assert bg_task.func == execute_cli\n",
    "    assert bg_task.kwargs[\"command\"] == f\"clickhouse_push {actual.id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.get(\n",
    "    \"/push/{prediction_push_uuid}\",\n",
    "    response_model=PredictionPushRead,\n",
    "    responses={\n",
    "        400: {\n",
    "            \"model\": HTTPError,\n",
    "            \"description\": ERRORS[\"INCORRECT_PREDICTION_PUSH_ID\"],\n",
    "        },\n",
    "        422: {\"model\": HTTPError, \"description\": \"Prediction push error\"},\n",
    "    },\n",
    ")\n",
    "def get_details_of_prediction_push(\n",
    "    prediction_push_uuid: str,\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> PredictionPush:\n",
    "    \"\"\"Push prediction results to the given datasource\"\"\"\n",
    "    user = session.merge(user)\n",
    "\n",
    "    try:\n",
    "        prediction_push = session.exec(\n",
    "            select(PredictionPush)\n",
    "            .where(PredictionPush.uuid == prediction_push_uuid)\n",
    "            .join(Prediction)\n",
    "            .join(Model)\n",
    "            .where(Model.user == user)\n",
    "        ).one()\n",
    "    except NoResultFound:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_400_BAD_REQUEST,\n",
    "            detail=ERRORS[\"INCORRECT_PREDICTION_PUSH_ID\"],\n",
    "        )\n",
    "\n",
    "    if prediction_push.error is not None:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n",
    "            detail=prediction_push.error,\n",
    "        )\n",
    "\n",
    "    session.add(prediction_push)\n",
    "    session.commit()\n",
    "    session.refresh(prediction_push)\n",
    "\n",
    "    return prediction_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a2d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionPush(id=3, uuid=UUID('58c4a36e-d17a-4a54-bdf3-eb84335a3ec3'), uri='mysql://****************************************@db.example.com:3306/database_to_import/events', total_steps=1, completed_steps=0, error=None, created=datetime.datetime(2022, 11, 7, 9, 11, 25), prediction_id=2, )"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    prediction_push = session.merge(prediction_push)\n",
    "\n",
    "    expected = prediction_push\n",
    "    actual = get_details_of_prediction_push(\n",
    "        prediction_push_uuid=expected.uuid, user=user, session=session\n",
    "    )\n",
    "    display(actual)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@model_prediction_router.get(\"/\", response_model=List[PredictionRead])\n",
    "def get_all_prediction(\n",
    "    disabled: bool = False,\n",
    "    completed: bool = False,\n",
    "    offset: int = 0,\n",
    "    limit: int = Query(default=100, lte=100),\n",
    "    user: User = Depends(get_current_active_user),\n",
    "    session: Session = Depends(get_session),\n",
    ") -> List[Prediction]:\n",
    "    \"\"\"Get all predictions created by user\"\"\"\n",
    "    user = session.merge(user)\n",
    "    statement = select(Prediction)\n",
    "    statement = statement.where(Prediction.disabled == disabled)\n",
    "    if completed:\n",
    "        statement = statement.where(\n",
    "            Prediction.completed_steps == Prediction.total_steps\n",
    "        )\n",
    "    # get all predictions from db\n",
    "    predictions = session.exec(\n",
    "        statement.join(Model).where(Model.user == user).offset(offset).limit(limit)\n",
    "    ).all()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b2331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(total_steps=3, error=None, disabled=False, id=2, uuid=UUID('c4e3c152-91f2-4628-bc8e-f268a0dda748'), datasource_id=3, cloud_provider=<CloudProvider.aws: 'aws'>, completed_steps=3, region='eu-west-3', created=datetime.datetime(2022, 11, 7, 9, 10, 42), path='s3://kumaran-airt-service-eu-west-3/5/prediction/2', model_id=2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    actual = get_all_prediction(\n",
    "        disabled=False, completed=False, offset=0, limit=1, user=user, session=session\n",
    "    )\n",
    "    display(actual)\n",
    "\n",
    "    assert len(actual) == 1\n",
    "    assert isinstance(actual[0], Prediction)\n",
    "    model = session.exec(select(Model).where(Model.id == actual[0].model_id)).one()\n",
    "    assert actual[0] == model.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'len(actual)=2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(actual)=2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'len(actual)=1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual = get_all_prediction(\n",
    "    disabled=False, completed=False, offset=0, limit=10, user=user, session=session\n",
    ")\n",
    "display(f\"{len(actual)=}\")\n",
    "for prediction in actual:\n",
    "    assert not prediction.disabled\n",
    "\n",
    "actual = get_all_prediction(\n",
    "    disabled=True, completed=False, offset=0, limit=10, user=user, session=session\n",
    ")\n",
    "display(f\"{len(actual)=}\")\n",
    "for prediction in actual:\n",
    "    assert prediction.disabled\n",
    "\n",
    "actual = get_all_prediction(\n",
    "    disabled=False, completed=True, offset=0, limit=10, user=user, session=session\n",
    ")\n",
    "display(f\"{len(actual)=}\")\n",
    "for prediction in actual:\n",
    "    assert prediction.completed_steps == prediction.total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3939f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
