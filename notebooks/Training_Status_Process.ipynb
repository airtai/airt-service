{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24fe3dc",
   "metadata": {},
   "source": [
    "# Training Status Process\n",
    "> Process to handle training data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training_status_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc957a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:20:30.430 [INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timedelta\n",
    "from os import environ\n",
    "from time import sleep\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from airt.logger import get_logger\n",
    "from airt.patching import patch\n",
    "from asyncer import asyncify, create_task_group\n",
    "from fastapi import FastAPI\n",
    "from fastcore.meta import delegates\n",
    "from fastkafka import FastKafka\n",
    "from sqlalchemy import create_engine as sqlalchemy_create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.exc import NoResultFound\n",
    "from sqlmodel import Session, func, select\n",
    "\n",
    "import airt_service\n",
    "from airt_service.data.clickhouse import get_count_for_account_ids\n",
    "from airt_service.db.models import (\n",
    "    TrainingStreamStatus,\n",
    "    User,\n",
    "    create_connection_string,\n",
    "    get_db_params_from_env_vars,\n",
    "    get_engine,\n",
    "    get_session_with_context,\n",
    ")\n",
    "from airt_service.users import User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0806d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from unittest.mock import AsyncMock, MagicMock, call\n",
    "\n",
    "import pytest\n",
    "import uvicorn\n",
    "from _pytest.monkeypatch import MonkeyPatch\n",
    "from confluent_kafka import Consumer, Producer\n",
    "from fastkafka.testing import Tester\n",
    "\n",
    "from airt_service.confluent import confluent_kafka_config, create_topics_for_user\n",
    "from airt_service.db.models import create_user_for_testing\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.sanitizer import sanitized_print\n",
    "from airt_service.server import (\n",
    "    EventData,\n",
    "    ModelTrainingRequest,\n",
    "    TrainingDataStatus,\n",
    "    create_ws_server,\n",
    ")\n",
    "from airt_service.uvicorn_helpers import run_uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f23d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hlzmyvhrib'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0affdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3957af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>total</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>count</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>None</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>1000</td>\n",
       "      <td>76</td>\n",
       "      <td>churn</td>\n",
       "      <td>10</td>\n",
       "      <td>upload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23</td>\n",
       "      <td>Whatever</td>\n",
       "      <td>1000</td>\n",
       "      <td>76</td>\n",
       "      <td>churn</td>\n",
       "      <td>670</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           application_id              model_id  total  user_id model_type  \\\n",
       "account_id                                                                   \n",
       "666                  None  ChurnModelForDrivers   1000       76      churn   \n",
       "999                    23              Whatever   1000       76      churn   \n",
       "\n",
       "            count   event  \n",
       "account_id                 \n",
       "666            10  upload  \n",
       "999           670     end  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_test_update_table() -> Tuple[pd.DataFrame, User]:\n",
    "    throwaway_username = create_user_for_testing()\n",
    "\n",
    "    with get_session_with_context() as session:\n",
    "        user = session.exec(\n",
    "            select(User).where(User.username == throwaway_username)\n",
    "        ).one()\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"account_id\": [666, 999],\n",
    "                \"application_id\": [None, \"23\"],\n",
    "                \"model_id\": [\"ChurnModelForDrivers\", \"Whatever\"],\n",
    "                \"total\": [1000, 1000],\n",
    "                \"user_id\": [user.id] * 2,\n",
    "                \"model_type\": [\"churn\", \"churn\"],\n",
    "                \"count\": [10, 670],\n",
    "                \"event\": [\"upload\", \"end\"],\n",
    "            }\n",
    "        ).set_index(\"account_id\"),\n",
    "        user,\n",
    "    )\n",
    "\n",
    "\n",
    "update_table, user = create_test_update_table()\n",
    "update_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de071bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def update_mysql(\n",
    "    update_table: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Method to create event\n",
    "\n",
    "    Args:\n",
    "        account_id: account id\n",
    "        application_id: Id of the application in case there is more than one for the AccountId\n",
    "        model_id: User supplied ID of the model trained\n",
    "        model_type: Model type\n",
    "        event: one of start, upload, end\n",
    "        count: current count of rows in clickhouse db\n",
    "        total: total no. of rows sent by user\n",
    "        user: user object\n",
    "        session: session object\n",
    "\n",
    "    \"\"\"\n",
    "    training_events = [\n",
    "        TrainingStreamStatus(**kwargs)  # type: ignore\n",
    "        for kwargs in update_table.reset_index().to_dict(orient=\"records\")\n",
    "    ]\n",
    "\n",
    "    with get_session_with_context() as session:\n",
    "        for training_event in training_events:\n",
    "            session.add(training_event)\n",
    "\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a2db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=999, model_id='Whatever', count=670, total=1000, user_id=77, id=212, uuid=UUID('f9f25b4c-5c10-4c4a-b96e-65e12936c9ee'), application_id='23', model_type='churn', created=datetime.datetime(2023, 3, 30, 13, 20, 32)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=666, model_id='ChurnModelForDrivers', count=10, total=1000, user_id=77, id=211, uuid=UUID('1b4f1927-6881-4dc3-9aaa-ac4e621db193'), application_id=None, model_type='churn', created=datetime.datetime(2023, 3, 30, 13, 20, 32))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_table, user = create_test_update_table()\n",
    "\n",
    "update_mysql(update_table=update_table)\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    most_recent_events = session.exec(\n",
    "        select(TrainingStreamStatus)\n",
    "        .where(TrainingStreamStatus.user == user)\n",
    "        .order_by(TrainingStreamStatus.id.desc())\n",
    "    ).all()\n",
    "\n",
    "display(most_recent_events)\n",
    "\n",
    "expected = update_table.sort_index().reindex(sorted(update_table.columns), axis=1)\n",
    "\n",
    "actual = (\n",
    "    pd.DataFrame([e.dict() for e in most_recent_events])\n",
    "    .set_index(\"account_id\")\n",
    "    .drop(columns=[\"id\", \"uuid\", \"created\"])\n",
    "    .sort_index()\n",
    "    .reindex(sorted(update_table.columns), axis=1)\n",
    ")\n",
    "pd.testing.assert_frame_equal(actual, expected)\n",
    "np.testing.assert_array_equal(actual[\"application_id\"], (None, \"23\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f2d5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>start</td>\n",
       "      <td>33</td>\n",
       "      <td>b465060fa1da4af8b9d597ec3c8f8e07</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-03-30 13:20:30.654478</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23</td>\n",
       "      <td>Whatever</td>\n",
       "      <td>upload</td>\n",
       "      <td>66</td>\n",
       "      <td>9999990fa1da4af8b9d597ec3c999999</td>\n",
       "      <td>670</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-03-30 13:19:31.654480</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>some app</td>\n",
       "      <td>CoolModel</td>\n",
       "      <td>upload</td>\n",
       "      <td>1000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2023-03-30 13:20:30.654481</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          application_id              model_id   event    id  \\\n",
       "AccountId                                                      \n",
       "666                  NaN  ChurnModelForDrivers   start    33   \n",
       "999                   23              Whatever  upload    66   \n",
       "1000            some app             CoolModel  upload  1000   \n",
       "\n",
       "                                       uuid  prev_count    total  \\\n",
       "AccountId                                                          \n",
       "666        b465060fa1da4af8b9d597ec3c8f8e07           0     1000   \n",
       "999        9999990fa1da4af8b9d597ec3c999999         670     1000   \n",
       "1000                       0000000000000000     1000000  1000000   \n",
       "\n",
       "                             created  user_id model_type  \n",
       "AccountId                                                 \n",
       "666       2023-03-30 13:20:30.654478       18      churn  \n",
       "999       2023-03-30 13:19:31.654480       18      churn  \n",
       "1000      2023-03-30 13:20:30.654481       18      churn  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mysql_test_table() -> pd.DataFrame:\n",
    "    d = {\n",
    "        \"application_id\": {666: np.nan, 999: \"23\", 1000: \"some app\"},\n",
    "        \"model_id\": {666: \"ChurnModelForDrivers\", 999: \"Whatever\", 1000: \"CoolModel\"},\n",
    "        \"event\": {666: \"start\", 999: \"upload\", 1000: \"upload\"},\n",
    "        \"id\": {666: 33, 999: 66, 1000: 1000},\n",
    "        \"uuid\": {\n",
    "            666: \"b465060fa1da4af8b9d597ec3c8f8e07\",\n",
    "            999: \"9999990fa1da4af8b9d597ec3c999999\",\n",
    "            1000: \"0\" * 16,\n",
    "        },\n",
    "        \"prev_count\": {666: 0, 999: 670, 1000: 1_000_000},\n",
    "        \"total\": {666: 1000, 999: 1000, 1000: 1_000_000},\n",
    "        \"created\": {\n",
    "            666: datetime.utcnow() - timedelta(seconds=1),\n",
    "            999: datetime.utcnow() - timedelta(seconds=60),\n",
    "            1000: datetime.utcnow() - timedelta(seconds=1),\n",
    "        },\n",
    "        \"user_id\": {666: 18, 999: 18, 1000: 18},\n",
    "        \"model_type\": {666: \"churn\", 999: \"churn\", 1000: \"churn\"},\n",
    "    }\n",
    "    return (\n",
    "        pd.DataFrame(d)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"AccountId\"})\n",
    "        .set_index(\"AccountId\")\n",
    "    )\n",
    "\n",
    "\n",
    "get_mysql_test_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7074a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>10</td>\n",
       "      <td>2023-03-30 13:20:31.666331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>670</td>\n",
       "      <td>2023-03-30 13:20:31.666331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000000</td>\n",
       "      <td>2023-03-30 13:20:31.666331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           curr_count              curr_check_on\n",
       "AccountId                                       \n",
       "666                10 2023-03-30 13:20:31.666331\n",
       "999               670 2023-03-30 13:20:31.666331\n",
       "1000          1000000 2023-03-30 13:20:31.666331"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clickhouse_test_table() -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"curr_count\": [10, 670, 1_000_000],\n",
    "                \"AccountId\": [666, 999, 1000],\n",
    "                \"curr_check_on\": [datetime.utcnow()] * 3,\n",
    "            },\n",
    "            index=[666, 999, 1000],\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "        .set_index(\"AccountId\")\n",
    "    )\n",
    "\n",
    "\n",
    "get_clickhouse_test_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8608f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def create_sqlalchemy_engine(\n",
    "    url: str, **kwargs: Dict[str, Any]\n",
    ") -> Generator[Engine, None, None]:\n",
    "    sqlalchemy_engine = sqlalchemy_create_engine(url, **kwargs)  # type: ignore\n",
    "    try:\n",
    "        yield sqlalchemy_engine\n",
    "    finally:\n",
    "        sqlalchemy_engine.dispose()\n",
    "\n",
    "\n",
    "def get_recent_events_for_user(user: User) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get recent event for user\n",
    "\n",
    "    Args:\n",
    "        user: user object to get recent events\n",
    "\n",
    "    Returns:\n",
    "        A list of recent events for given user\n",
    "    \"\"\"\n",
    "    conn_str = create_connection_string(**get_db_params_from_env_vars())  # type: ignore\n",
    "\n",
    "    with create_sqlalchemy_engine(conn_str) as engine:\n",
    "        # Get all rows from table\n",
    "        df = pd.read_sql_table(table_name=\"trainingstreamstatus\", con=engine)\n",
    "\n",
    "    # Filter events for given user and group by account_id\n",
    "    events_for_user = (\n",
    "        df.loc[df[\"user_id\"] == user.id]\n",
    "        .sort_values(\"id\", ascending=False)\n",
    "        .groupby(\n",
    "            by=[\"account_id\", \"application_id\", \"model_id\"],\n",
    "            as_index=False,\n",
    "            dropna=False,\n",
    "        )\n",
    "        .first()\n",
    "    )\n",
    "\n",
    "    events_for_user = events_for_user.rename(\n",
    "        columns={\"count\": \"prev_count\", \"account_id\": \"AccountId\"}\n",
    "    )\n",
    "\n",
    "    events_for_user = events_for_user.set_index(\"AccountId\")\n",
    "\n",
    "    # Leave 'end' events\n",
    "    events_for_user = events_for_user.loc[\n",
    "        events_for_user[\"event\"] != \"end\"\n",
    "    ].sort_values(\"AccountId\", ascending=True)\n",
    "\n",
    "    return events_for_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9a3fb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>total</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>count</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>None</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>1000</td>\n",
       "      <td>78</td>\n",
       "      <td>churn</td>\n",
       "      <td>10</td>\n",
       "      <td>upload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23</td>\n",
       "      <td>Whatever</td>\n",
       "      <td>1000</td>\n",
       "      <td>78</td>\n",
       "      <td>churn</td>\n",
       "      <td>670</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           application_id              model_id  total  user_id model_type  \\\n",
       "account_id                                                                   \n",
       "666                  None  ChurnModelForDrivers   1000       78      churn   \n",
       "999                    23              Whatever   1000       78      churn   \n",
       "\n",
       "            count   event  \n",
       "account_id                 \n",
       "666            10  upload  \n",
       "999           670     end  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>upload</td>\n",
       "      <td>213</td>\n",
       "      <td>d1001f2a41d24be1a38dfabd0c261824</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-03-30 13:20:32</td>\n",
       "      <td>78</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          application_id              model_id   event   id  \\\n",
       "AccountId                                                     \n",
       "666                  NaN  ChurnModelForDrivers  upload  213   \n",
       "\n",
       "                                       uuid  prev_count  total  \\\n",
       "AccountId                                                        \n",
       "666        d1001f2a41d24be1a38dfabd0c261824          10   1000   \n",
       "\n",
       "                      created  user_id model_type  \n",
       "AccountId                                          \n",
       "666       2023-03-30 13:20:32       78      churn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end_count = 1_000_000\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    update_table, user = create_test_update_table()\n",
    "    display(update_table)\n",
    "    recent_event_for_user = get_recent_events_for_user(user=user)\n",
    "    assert recent_event_for_user.empty, recent_event_for_user\n",
    "\n",
    "    update_mysql(update_table=update_table)\n",
    "\n",
    "    actual = get_recent_events_for_user(user=user)\n",
    "    display(actual)\n",
    "    assert len(actual) == 1\n",
    "    assert (actual[\"event\"] == \"upload\").all()\n",
    "    assert (actual[\"user_id\"] == user.id).all()\n",
    "    assert (actual.index == 666).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e6b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_count_from_training_data_ch_table(\n",
    "    account_ids: List[Union[int, str]]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get count of all rows for given account ids from clickhouse table\n",
    "\n",
    "    Args:\n",
    "        account_ids: List of account_ids to get count\n",
    "\n",
    "    Returns:\n",
    "        Count for the given account id\n",
    "    \"\"\"\n",
    "    return get_count_for_account_ids(\n",
    "        account_ids=account_ids,\n",
    "        username=environ[\"KAFKA_CH_USERNAME\"],\n",
    "        password=environ[\"KAFKA_CH_PASSWORD\"],\n",
    "        host=environ[\"KAFKA_CH_HOST\"],\n",
    "        port=int(environ[\"KAFKA_CH_PORT\"]),\n",
    "        database=environ[\"KAFKA_CH_DATABASE\"],\n",
    "        table=environ[\"KAFKA_CH_TABLE\"],\n",
    "        protocol=environ[\"KAFKA_CH_PROTOCOL\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3bf0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>999</td>\n",
       "      <td>2023-03-30 13:20:32.015994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           curr_count              curr_check_on\n",
       "AccountId                                       \n",
       "500               999 2023-03-30 13:20:32.015994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@contextmanager\n",
    "def patch_get_count_from_training_data_ch_table():\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_from_training_data_ch_table\",\n",
    "            lambda account_ids: pd.DataFrame(\n",
    "                {\n",
    "                    \"curr_count\": [999] * len(account_ids),\n",
    "                    \"AccountId\": account_ids,\n",
    "                    \"curr_check_on\": [datetime.utcnow()] * len(account_ids),\n",
    "                }\n",
    "            ).set_index(\"AccountId\"),\n",
    "        )\n",
    "        yield\n",
    "\n",
    "\n",
    "with patch_get_count_from_training_data_ch_table():\n",
    "    actual = get_count_from_training_data_ch_table(account_ids=[500])\n",
    "    display(actual)\n",
    "    assert actual.iloc[0][\"curr_count\"] == 999, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992a6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_user(username: str) -> User:\n",
    "    \"\"\"Get the user object for the given username\n",
    "\n",
    "    Args:\n",
    "        username: Username as a string\n",
    "\n",
    "    Returns:\n",
    "        The user object\n",
    "    \"\"\"\n",
    "    with get_session_with_context() as session:\n",
    "        user: User = session.exec(select(User).where(User.username == username)).one()\n",
    "\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e539a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = get_user(username=test_username)\n",
    "assert actual.username == test_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754191d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86912728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_new_update_table(\n",
    "    recent_events_df: pd.DataFrame, ch_df: pd.DataFrame, end_timedelta: int\n",
    ") -> pd.DataFrame:\n",
    "    merged = recent_events_df.merge(right=ch_df, how=\"left\", on=\"AccountId\")\n",
    "\n",
    "    updated = merged[\"curr_count\"] > merged[\"prev_count\"]\n",
    "    not_update_for_30s = (pd.to_datetime(merged[\"curr_check_on\"]) - \n",
    "        pd.to_datetime(merged[\"created\"])\n",
    "    ) > timedelta(seconds=end_timedelta)\n",
    "\n",
    "    df = merged[updated | not_update_for_30s]\n",
    "    df = df.assign(action=\"end\")\n",
    "\n",
    "    df.loc[df[\"curr_count\"] > df[\"prev_count\"], \"action\"] = \"upload\"\n",
    "\n",
    "    drop_columns = [\"event\", \"id\", \"uuid\", \"prev_count\", \"created\", \"curr_check_on\"]\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    df = df.rename(columns=dict(curr_count=\"count\", action=\"event\"))\n",
    "    df = df.astype({\"count\": \"int\"})\n",
    "    df.index = df.index.rename(\"account_id\")\n",
    "\n",
    "    df = df.replace({np.nan: None})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf8f0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>start</td>\n",
       "      <td>33</td>\n",
       "      <td>b465060fa1da4af8b9d597ec3c8f8e07</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-03-30 13:20:31.060036</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23</td>\n",
       "      <td>Whatever</td>\n",
       "      <td>upload</td>\n",
       "      <td>66</td>\n",
       "      <td>9999990fa1da4af8b9d597ec3c999999</td>\n",
       "      <td>670</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-03-30 13:19:32.060038</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>some app</td>\n",
       "      <td>CoolModel</td>\n",
       "      <td>upload</td>\n",
       "      <td>1000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2023-03-30 13:20:31.060039</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          application_id              model_id   event    id  \\\n",
       "AccountId                                                      \n",
       "666                  NaN  ChurnModelForDrivers   start    33   \n",
       "999                   23              Whatever  upload    66   \n",
       "1000            some app             CoolModel  upload  1000   \n",
       "\n",
       "                                       uuid  prev_count    total  \\\n",
       "AccountId                                                          \n",
       "666        b465060fa1da4af8b9d597ec3c8f8e07           0     1000   \n",
       "999        9999990fa1da4af8b9d597ec3c999999         670     1000   \n",
       "1000                       0000000000000000     1000000  1000000   \n",
       "\n",
       "                             created  user_id model_type  \n",
       "AccountId                                                 \n",
       "666       2023-03-30 13:20:31.060036       18      churn  \n",
       "999       2023-03-30 13:19:32.060038       18      churn  \n",
       "1000      2023-03-30 13:20:31.060039       18      churn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>10</td>\n",
       "      <td>2023-03-30 13:20:32.062145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>670</td>\n",
       "      <td>2023-03-30 13:20:32.062145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000000</td>\n",
       "      <td>2023-03-30 13:20:32.062145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           curr_count              curr_check_on\n",
       "AccountId                                       \n",
       "666                10 2023-03-30 13:20:32.062145\n",
       "999               670 2023-03-30 13:20:32.062145\n",
       "1000          1000000 2023-03-30 13:20:32.062145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>total</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>count</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>None</td>\n",
       "      <td>ChurnModelForDrivers</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "      <td>10</td>\n",
       "      <td>upload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>23</td>\n",
       "      <td>Whatever</td>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>churn</td>\n",
       "      <td>670</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           application_id              model_id  total  user_id model_type  \\\n",
       "account_id                                                                   \n",
       "666                  None  ChurnModelForDrivers   1000       18      churn   \n",
       "999                    23              Whatever   1000       18      churn   \n",
       "\n",
       "            count   event  \n",
       "account_id                 \n",
       "666            10  upload  \n",
       "999           670     end  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recent_events_df = get_mysql_test_table()\n",
    "ch_df = get_clickhouse_test_table()\n",
    "display(recent_events_df)\n",
    "display(ch_df)\n",
    "\n",
    "update_table = get_new_update_table(recent_events_df, ch_df, end_timedelta=30)\n",
    "display(update_table)\n",
    "assert update_table.shape == (2, 7), update_table.shape\n",
    "np.testing.assert_array_equal(update_table.index, (666, 999))\n",
    "assert update_table.index.name == \"account_id\"\n",
    "np.testing.assert_array_equal(update_table[\"event\"], (\"upload\", \"end\"))\n",
    "np.testing.assert_array_equal(update_table[\"count\"], (10, 670))\n",
    "np.testing.assert_array_equal(\n",
    "    update_table[\"application_id\"].fillna(\"nan\"), (\"nan\", \"23\")\n",
    ")\n",
    "np.testing.assert_array_equal(update_table[\"application_id\"], (None, \"23\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a509c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def update_kafka(update_table: pd.DataFrame, kafka_app: FastKafka) -> None:\n",
    "    async with create_task_group() as task_group:\n",
    "        to_infobip_training_data_status = task_group.soonify(\n",
    "            kafka_app.to_infobip_training_data_status\n",
    "        )\n",
    "        to_infobip_start_training = task_group.soonify(\n",
    "            kafka_app.to_infobip_start_training\n",
    "        )\n",
    "        # start training when necessary\n",
    "        ready_df = update_table[(update_table[\"event\"] == \"end\") | (update_table[\"count\"] >= update_table[\"total\"])]\n",
    "        rename_dict = dict(count=\"no_of_records\")\n",
    "        drop_columns = [\"model_type\", \"user_id\", \"event\", \"total\"]\n",
    "        msgs = (\n",
    "            ready_df.drop(columns=drop_columns)\n",
    "            .rename(columns=rename_dict)\n",
    "            .reset_index()\n",
    "            .to_dict(orient=\"records\")\n",
    "        )\n",
    "        for kwargs in msgs:\n",
    "            to_infobip_start_training(**kwargs)  # type: ignore\n",
    "            \n",
    "        # send status\n",
    "        drop_columns = [\"model_type\", \"user_id\", \"event\"]\n",
    "        rename_dict = dict(count=\"no_of_records\", total=\"total_no_of_records\")\n",
    "        msgs = (\n",
    "            update_table.drop(columns=drop_columns)\n",
    "            .rename(columns=rename_dict)\n",
    "            .reset_index()\n",
    "            .to_dict(orient=\"records\")\n",
    "        )\n",
    "        for kwargs in msgs:\n",
    "            to_infobip_training_data_status(**kwargs)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18707ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "update_table, _ = create_test_update_table()\n",
    "\n",
    "kafka_app = MagicMock()\n",
    "kafka_app.to_infobip_training_data_status = AsyncMock()\n",
    "kafka_app.to_infobip_start_training = AsyncMock()\n",
    "\n",
    "expected_infobip_training_data_status = [\n",
    "    call(\n",
    "        account_id=666,\n",
    "        application_id=None,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        total_no_of_records=1000,\n",
    "        no_of_records=10,\n",
    "    ),\n",
    "    call(\n",
    "        account_id=999,\n",
    "        application_id=\"23\",\n",
    "        model_id=\"Whatever\",\n",
    "        total_no_of_records=1000,\n",
    "        no_of_records=670,\n",
    "    ),\n",
    "]\n",
    "\n",
    "expected_infobip_start_training = [\n",
    "    call(\n",
    "        account_id=999,\n",
    "        application_id=\"23\",\n",
    "        model_id=\"Whatever\",\n",
    "        no_of_records=670,\n",
    "    ),\n",
    "]\n",
    "\n",
    "await update_kafka(update_table, kafka_app=kafka_app)\n",
    "\n",
    "assert kafka_app.to_infobip_training_data_status.call_count == 2\n",
    "assert kafka_app.to_infobip_training_data_status.call_args_list == expected_infobip_training_data_status\n",
    "\n",
    "assert kafka_app.to_infobip_start_training.call_count == 1\n",
    "assert kafka_app.to_infobip_start_training.call_args_list == expected_infobip_start_training, kafka_app.to_infobip_start_training.call_args_list\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e7fd420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_after(timeout: int):\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    def _f(t0: datetime = t0, timeout: int = timeout) -> bool:\n",
    "        return datetime.now() - t0 > timedelta(seconds=timeout)\n",
    "\n",
    "    return _f\n",
    "\n",
    "\n",
    "should_exit_f = exit_after(1)\n",
    "assert not should_exit_f()\n",
    "sleep(2)\n",
    "assert should_exit_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440d906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_training_status(\n",
    "    username: str,\n",
    "    fast_kafka_api_app: FastKafka,\n",
    "    *,\n",
    "    should_exit_f: Optional[Callable[[], bool]] = None,\n",
    "    sleep_min: int = 5,\n",
    "    sleep_max: int = 20,\n",
    "    end_timedelta: int = 120,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    An infinite loop to keep track of training_data uploads from user\n",
    "\n",
    "    Args:\n",
    "        username: username of user to track training data uploads\n",
    "    \"\"\"\n",
    "\n",
    "    while should_exit_f is None or not should_exit_f():\n",
    "        # moved here to allow for dynamic mocking up underlying functions\n",
    "        async_get_user = asyncify(get_user)\n",
    "        async_get_recent_events_for_user = asyncify(get_recent_events_for_user)\n",
    "        async_get_count_from_training_data_ch_table = asyncify(\n",
    "            get_count_from_training_data_ch_table\n",
    "        )\n",
    "        async_update_mysql = asyncify(update_mysql)\n",
    "        \n",
    "        #         logger.info(f\"Starting the process loop\")\n",
    "        try:\n",
    "            user = await async_get_user(username)\n",
    "            recent_events_df = await async_get_recent_events_for_user(user=user)\n",
    "            if not recent_events_df.empty:\n",
    "                ch_df = await async_get_count_from_training_data_ch_table(\n",
    "                    account_ids=recent_events_df.index.tolist()\n",
    "                )\n",
    "                update_table = get_new_update_table(\n",
    "                    recent_events_df=recent_events_df,\n",
    "                    ch_df=ch_df,\n",
    "                    end_timedelta=end_timedelta,\n",
    "                )\n",
    "                async with create_task_group() as tg:\n",
    "                    tg.soonify(update_kafka)(\n",
    "                        update_table=update_table, kafka_app=fast_kafka_api_app\n",
    "                    )\n",
    "                    tg.soonify(async_update_mysql)(update_table=update_table)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(\n",
    "                f\"Error in process_training_status - {e}, {traceback.format_exc()}\"\n",
    "            )\n",
    "\n",
    "        await asyncio.sleep(random.randint(sleep_min, sleep_max))  # nosec B311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a2d2b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All events for account id 9000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.start: 'start'>, account_id=9000, model_id='ChurnModelForDrivers', count=0, total=1000, user_id=80, id=215, uuid=UUID('c428eee9-2d64-469c-9668-99acc14b35d1'), application_id=None, model_type='churn', created=datetime.datetime(2023, 3, 30, 13, 20, 35)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=9000, model_id='ChurnModelForDrivers', count=999, total=1000, user_id=80, id=216, uuid=UUID('f4e84a62-5f13-4333-b8c0-c8c70c1d0f0f'), application_id=None, model_type='churn', created=datetime.datetime(2023, 3, 30, 13, 20, 35)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=9000, model_id='ChurnModelForDrivers', count=999, total=1000, user_id=80, id=217, uuid=UUID('371d3544-622c-4b5b-93f8-a002c6d2510a'), application_id=None, model_type='churn', created=datetime.datetime(2023, 3, 30, 13, 20, 42))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = create_user_for_testing()\n",
    "kafka_app = MagicMock()\n",
    "kafka_app.to_infobip_training_data_status = AsyncMock()\n",
    "kafka_app.to_infobip_start_training = AsyncMock()\n",
    "\n",
    "msg_count = 1000\n",
    "account_id = 9000\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == username)).one()\n",
    "    test_start_event = TrainingStreamStatus(\n",
    "        account_id=account_id,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        model_type=\"churn\",\n",
    "        event=\"start\",\n",
    "        count=0,\n",
    "        total=msg_count,\n",
    "        user=user,\n",
    "    )\n",
    "    session.add(test_start_event)\n",
    "    session.commit()\n",
    "\n",
    "\n",
    "with patch_get_count_from_training_data_ch_table():\n",
    "    await process_training_status(\n",
    "        username=username,\n",
    "        fast_kafka_api_app=kafka_app,\n",
    "        should_exit_f=exit_after(10),\n",
    "        sleep_min=1,\n",
    "        sleep_max=2,\n",
    "        end_timedelta=5,\n",
    "    )\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == username)).one()\n",
    "\n",
    "    display(f\"All events for account id {account_id}\")\n",
    "    all_events = session.exec(\n",
    "        select(TrainingStreamStatus)\n",
    "        .where(TrainingStreamStatus.user == user)\n",
    "        .where(TrainingStreamStatus.account_id == account_id)\n",
    "        .order_by(TrainingStreamStatus.id.asc())\n",
    "    ).all()\n",
    "    display(all_events)\n",
    "\n",
    "    assert all_events[-1].event == \"end\", all_events[-1]\n",
    "    assert all_events[-1].count == 999, all_events[-1]\n",
    "\n",
    "\n",
    "assert kafka_app.to_infobip_training_data_status.call_count == 2\n",
    "\n",
    "expected = [\n",
    "    call(\n",
    "        account_id=9000,\n",
    "        application_id=None,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        total_no_of_records=1000,\n",
    "        no_of_records=999,\n",
    "    ),\n",
    "    call(\n",
    "        account_id=9000,\n",
    "        application_id=None,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        total_no_of_records=1000,\n",
    "        no_of_records=999,\n",
    "    ),\n",
    "]\n",
    "\n",
    "assert kafka_app.to_infobip_training_data_status.call_args_list == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a54a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccountId': 6000,\n",
       " 'ApplicationId': 'DriverApp',\n",
       " 'ModelId': None,\n",
       " 'DefinitionId': 'sign_in',\n",
       " 'OccurredTimeTicks': 1649146037462,\n",
       " 'OccurredTime': '2022-04-05T08:07:17.462000',\n",
       " 'PersonId': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integration tests\n",
    "\n",
    "definitions = [\n",
    "    \"appLaunch\",\n",
    "    \"sign_in\",\n",
    "    \"sign_out\",\n",
    "    \"add_to_cart\",\n",
    "    \"purchase\",\n",
    "    \"custom_event_1\",\n",
    "    \"custom_event_2\",\n",
    "    \"custom_event_3\",\n",
    "]\n",
    "\n",
    "\n",
    "# applications = [\"DriverApp\", \"PUBG\", \"COD\"]\n",
    "applications = [\"DriverApp\"]\n",
    "\n",
    "\n",
    "def generate_n_rows_for_training_data(n: int, seed: int = 42):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    #     account_id = rng.choice([4000, 5000, 500], size=n)\n",
    "    account_id = 6000\n",
    "    definition_id = rng.choice(definitions, size=n)\n",
    "    application_id = rng.choice(applications, size=n)\n",
    "    model_id = rng.choice([\"ChurnModelForDrivers\", None], size=n)\n",
    "    occurred_time_ticks = rng.integers(\n",
    "        datetime(year=2022, month=1, day=1).timestamp() * 1000,\n",
    "        datetime(year=2022, month=11, day=1).timestamp() * 1000,\n",
    "        size=n,\n",
    "    )\n",
    "    occurred_time = pd.to_datetime(occurred_time_ticks, unit=\"ms\").strftime(\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "    )\n",
    "    person_id = rng.integers(n // 10, size=n)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"AccountId\": account_id,\n",
    "            \"ApplicationId\": application_id,\n",
    "            \"ModelId\": model_id,\n",
    "            \"DefinitionId\": definition_id,\n",
    "            \"OccurredTimeTicks\": occurred_time_ticks,\n",
    "            \"OccurredTime\": occurred_time,\n",
    "            \"PersonId\": person_id,\n",
    "        }\n",
    "    )\n",
    "    return json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "\n",
    "generate_n_rows_for_training_data(100)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ba6006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_username='hlzmyvhrib'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:22:44.925 [INFO] fastkafka._application.app: run_in_background() : Adding function 'startup_event' as background task\n",
      "23-03-30 13:22:44.926 [INFO] fastkafka._application.app: run_in_background() : Adding function 'startup_event' as background task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1680182564.784|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1680182564.784|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:22:44.929 [INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "23-03-30 13:22:44.930 [INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "23-03-30 13:22:44.931 [INFO] fastkafka._testing.local_broker: Starting zookeeper...\n",
      "23-03-30 13:22:45.681 [INFO] fastkafka._testing.local_broker: Starting kafka...\n",
      "23-03-30 13:22:47.582 [INFO] fastkafka._testing.local_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "23-03-30 13:22:49.511 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.525 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.532 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.539 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.545 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.551 [INFO] fastkafka._application.app: _populate_bg_tasks() : Starting background task 'startup_event'\n",
      "23-03-30 13:22:49.552 [INFO] fastkafka._application.app: _populate_bg_tasks() : Starting background task 'startup_event'\n",
      "23-03-30 13:22:49.572 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.573 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.574 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'group_id': 'airt-service-kafka-group', 'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.574 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.575 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'group_id': 'airt-service-kafka-group', 'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.576 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.576 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'group_id': 'airt-service-kafka-group', 'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.577 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.577 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'group_id': 'airt-service-kafka-group', 'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.579 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.580 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'group_id': 'airt-service-kafka-group', 'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.594 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.596 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.597 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_data'})\n",
      "23-03-30 13:22:49.598 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_data'}\n",
      "23-03-30 13:22:49.599 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.600 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.601 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_realtime_data'})\n",
      "23-03-30 13:22:49.601 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_realtime_data'}\n",
      "23-03-30 13:22:49.604 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.605 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.605 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_model_metrics'})\n",
      "23-03-30 13:22:49.606 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_model_metrics'}\n",
      "23-03-30 13:22:49.608 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.609 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.609 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training_data'})\n",
      "23-03-30 13:22:49.610 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training_data'}\n",
      "23-03-30 13:22:49.610 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.611 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.612 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training'})\n",
      "23-03-30 13:22:49.614 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training'}\n",
      "23-03-30 13:22:49.614 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.626 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.627 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.628 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.629 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.631 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.636 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.646 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.660 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "23-03-30 13:22:49.694 [INFO] airt_service.training_status_process: Error in process_training_status - 'KAFKA_CH_USERNAME', Traceback (most recent call last):\n",
      "  File \"/work/airt-service/airt_service/training_status_process.py\", line 261, in process_training_status\n",
      "    ch_df = await async_get_count_from_training_data_ch_table(\n",
      "  File \"/home/davor/.local/lib/python3.9/site-packages/asyncer/_main.py\", line 358, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/work/airt-service/airt_service/training_status_process.py\", line 143, in get_count_from_training_data_ch_table\n",
      "    username=environ[\"KAFKA_CH_USERNAME\"],\n",
      "  File \"/usr/lib/python3.9/os.py\", line 679, in __getitem__\n",
      "    raise KeyError(key) from None\n",
      "KeyError: 'KAFKA_CH_USERNAME'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:22:49.705 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.706 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.707 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.707 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.709 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.709 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.710 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.711 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.712 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-03-30 13:22:49.712 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "23-03-30 13:22:49.722 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.723 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_data_status'})\n",
      "23-03-30 13:22:49.724 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_data_status'}\n",
      "23-03-30 13:22:49.724 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.726 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.727 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_model_metrics'})\n",
      "23-03-30 13:22:49.727 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_model_metrics'}\n",
      "23-03-30 13:22:49.728 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.728 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.729 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training'})\n",
      "23-03-30 13:22:49.729 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training'}\n",
      "23-03-30 13:22:49.730 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.730 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.731 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_prediction'})\n",
      "23-03-30 13:22:49.731 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_prediction'}\n",
      "23-03-30 13:22:49.732 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.732 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-03-30 13:22:49.733 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_model_status'})\n",
      "23-03-30 13:22:49.733 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_model_status'}\n",
      "23-03-30 13:22:49.733 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-03-30 13:22:49.737 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.738 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.739 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.741 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.743 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'infobip_training_data_status': 1}. \n",
      "23-03-30 13:22:49.746 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'infobip_model_metrics': 1}. \n",
      "23-03-30 13:22:49.747 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'infobip_prediction': 1}. \n",
      "23-03-30 13:22:49.748 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'infobip_training_model_status': 1}. \n",
      "23-03-30 13:22:49.748 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'infobip_start_training': 1}. \n",
      "23-03-30 13:22:49.758 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.846 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.847 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.848 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.849 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.862 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.957 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.958 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.958 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.959 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:49.966 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.061 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.062 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.063 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.064 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.070 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.167 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.168 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.169 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.171 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:22:50.174 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.274 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.275 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.276 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.277 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.282 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.382 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.384 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.384 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.385 [ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "23-03-30 13:22:50.391 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.391 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.392 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "23-03-30 13:22:50.418 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 1) with member_id aiokafka-0.8.0-9bac5bce-b2f9-4c38-86cf-ae3f5de2f19a\n",
      "23-03-30 13:22:50.419 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-03-30 13:22:50.436 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 1\n",
      "23-03-30 13:22:50.436 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_training_data', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.492 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.494 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.494 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "23-03-30 13:22:50.496 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.496 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.497 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "23-03-30 13:22:50.498 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.498 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.499 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "23-03-30 13:22:50.500 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.500 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group airt-service-kafka-group\n",
      "23-03-30 13:22:50.501 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "server started\n",
      "23-03-30 13:22:53.441 [WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group airt-service-kafka-group because it is rebalancing\n",
      "23-03-30 13:22:53.453 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='infobip_training_data', partition=0)}) for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.454 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group airt-service-kafka-group\n",
      "23-03-30 13:22:53.458 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 2) with member_id aiokafka-0.8.0-9bac5bce-b2f9-4c38-86cf-ae3f5de2f19a\n",
      "23-03-30 13:22:53.458 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-03-30 13:22:53.460 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 2) with member_id aiokafka-0.8.0-b0adb47f-e100-43c7-be6c-a346c8725014\n",
      "23-03-30 13:22:53.461 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 2) with member_id aiokafka-0.8.0-da70d24d-07cb-4edb-989a-fd8f50bdb8cc\n",
      "23-03-30 13:22:53.461 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 2) with member_id aiokafka-0.8.0-d4348c4d-0666-4e3a-a390-68b720668874\n",
      "23-03-30 13:22:53.462 [INFO] aiokafka.consumer.group_coordinator: Joined group 'airt-service-kafka-group' (generation 2) with member_id aiokafka-0.8.0-202a6815-7dc0-45de-8411-6ec9f0ee00af\n",
      "23-03-30 13:22:53.481 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.481 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:53.482 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.483 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:53.484 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.484 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:53.485 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.486 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:53.506 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.507 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:53.509 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Cancelling background task 'startup_event'\n",
      "23-03-30 13:22:53.510 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Cancelling background task 'startup_event'\n",
      "23-03-30 13:22:53.510 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Waiting for background task 'startup_event' to finish\n",
      "23-03-30 13:22:53.511 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Execution finished for background task 'startup_event'\n",
      "23-03-30 13:22:53.512 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Waiting for background task 'startup_event' to finish\n",
      "23-03-30 13:22:53.512 [INFO] fastkafka._application.app: _shutdown_bg_tasks() : Execution finished for background task 'startup_event'\n",
      "23-03-30 13:22:53.937 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'infobip_training_data': 1} to {'infobip_training_data': 1, 'infobip_start_training_data': 1, 'infobip_realtime_data': 1, 'infobip_start_training': 1, 'infobip_model_metrics': 1}. \n",
      "23-03-30 13:22:53.940 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 2\n",
      "23-03-30 13:22:53.942 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_training_data', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.943 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-03-30 13:22:53.943 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_realtime_data', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.944 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 2\n",
      "23-03-30 13:22:53.945 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.946 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 2\n",
      "23-03-30 13:22:53.948 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training_data', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.948 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group airt-service-kafka-group with generation 2\n",
      "23-03-30 13:22:53.949 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_model_metrics', partition=0)} for group airt-service-kafka-group\n",
      "23-03-30 13:22:53.957 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-03-30 13:22:53.958 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:53.959 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:54.053 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-03-30 13:22:54.055 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:54.056 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:54.057 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-03-30 13:22:54.057 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-03-30 13:22:54.059 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:54.060 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:54.061 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:54.061 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:54.062 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-03-30 13:22:54.063 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-03-30 13:22:54.064 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-03-30 13:22:54.065 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 259496...\n",
      "23-03-30 13:22:55.844 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 259496 terminated.\n",
      "23-03-30 13:22:55.845 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 259114...\n",
      "23-03-30 13:22:57.179 [INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 259114 terminated.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TesterMocks' object has no attribute 'on_None_training_data_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Tester(fast_kafka_api_app) \u001b[38;5;28;01mas\u001b[39;00m tester:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# Server started.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     sanitized_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m test_process_training_status(tester)\n\u001b[1;32m     84\u001b[0m sanitized_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver stopped\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Server stopped.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 28\u001b[0m, in \u001b[0;36mtest_process_training_status\u001b[0;34m(tester)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(msg_count):\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m tester\u001b[38;5;241m.\u001b[39mto_infobip_training_data(EventData(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtraining_data[i]))\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m tester\u001b[38;5;241m.\u001b[39mawaited_mocks\u001b[38;5;241m.\u001b[39mon_None_training_data_status\u001b[38;5;241m.\u001b[39massert_awaited_with(\n\u001b[1;32m     29\u001b[0m     TrainingDataStatus(\n\u001b[1;32m     30\u001b[0m         AccountId\u001b[38;5;241m=\u001b[39maccount_id,\n\u001b[1;32m     31\u001b[0m         ApplicationId\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDriverApp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m         ModelId\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChurnModelForDrivers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m         no_of_records\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m999\u001b[39m,\n\u001b[1;32m     34\u001b[0m         total_no_of_records\u001b[38;5;241m=\u001b[39mmsg_count,\n\u001b[1;32m     35\u001b[0m     ),\n\u001b[1;32m     36\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_session_with_context() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m     40\u001b[0m     user \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mexec(select(User)\u001b[38;5;241m.\u001b[39mwhere(User\u001b[38;5;241m.\u001b[39musername \u001b[38;5;241m==\u001b[39m test_username))\u001b[38;5;241m.\u001b[39mone()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TesterMocks' object has no attribute 'on_None_training_data_status'"
     ]
    }
   ],
   "source": [
    "# test_username = \"infobip\"\n",
    "\n",
    "\n",
    "async def test_process_training_status(tester):\n",
    "    with get_session_with_context() as session:\n",
    "        user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "        msg_count = 1000\n",
    "        account_id = 6000\n",
    "\n",
    "        test_start_event = TrainingStreamStatus(\n",
    "            account_id=account_id,\n",
    "            application_id=\"DriverApp\",\n",
    "            model_id=\"ChurnModelForDrivers\",\n",
    "            model_type=\"churn\",\n",
    "            event=\"start\",\n",
    "            count=0,\n",
    "            total=msg_count,\n",
    "            user=user,\n",
    "        )\n",
    "        session.add(test_start_event)\n",
    "        session.commit()\n",
    "\n",
    "        training_data = generate_n_rows_for_training_data(msg_count, seed=999)\n",
    "        for i in range(msg_count):\n",
    "            await tester.to_None_training_data(EventData(**training_data[i]))\n",
    "\n",
    "    await tester.awaited_mocks.on_None_training_data_status.assert_awaited_with(\n",
    "        TrainingDataStatus(\n",
    "            AccountId=account_id,\n",
    "            ApplicationId=\"DriverApp\",\n",
    "            ModelId=\"ChurnModelForDrivers\",\n",
    "            no_of_records=999,\n",
    "            total_no_of_records=msg_count,\n",
    "        ),\n",
    "        timeout=5 * 60,\n",
    "    )\n",
    "\n",
    "    with get_session_with_context() as session:\n",
    "        user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "        display(f\"All events for account id {account_id}\")\n",
    "        all_events = session.exec(\n",
    "            select(TrainingStreamStatus)\n",
    "            .where(TrainingStreamStatus.user == user)\n",
    "            .where(TrainingStreamStatus.account_id == account_id)\n",
    "        )\n",
    "        display([e for e in all_events])\n",
    "\n",
    "\n",
    "display(f\"{test_username=}\")\n",
    "create_topics_for_user(username=test_username)\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_from_training_data_ch_table\",\n",
    "            lambda account_ids: pd.DataFrame(\n",
    "                {\n",
    "                    \"curr_count\": [999],\n",
    "                    \"AccountId\": 6000,\n",
    "                    \"curr_check_on\": [datetime.utcnow()],\n",
    "                }\n",
    "            ).set_index(\"AccountId\"),\n",
    "        )\n",
    "        app, fast_kafka_api_app = create_ws_server(\n",
    "            assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "        )\n",
    "\n",
    "        @fast_kafka_api_app.run_in_background()\n",
    "        async def startup_event():\n",
    "            await process_training_status(\n",
    "                username=test_username,\n",
    "                fast_kafka_api_app=fast_kafka_api_app,\n",
    "                end_timedelta=30,\n",
    "            )\n",
    "\n",
    "        config = uvicorn.Config(app, host=\"0.0.0.0\", port=6010, log_level=\"debug\")\n",
    "\n",
    "        async with Tester(fast_kafka_api_app) as tester:\n",
    "            # Server started.\n",
    "            sanitized_print(\"server started\")\n",
    "            await test_process_training_status(tester)\n",
    "\n",
    "        sanitized_print(\"server stopped\")\n",
    "        # Server stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62834287",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
