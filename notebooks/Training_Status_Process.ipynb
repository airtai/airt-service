{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24fe3dc",
   "metadata": {},
   "source": [
    "# Training Status Process\n",
    "> Process to handle training data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training_status_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc957a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from os import environ\n",
    "from time import sleep\n",
    "from typing import *\n",
    "\n",
    "import asyncio\n",
    "from asyncer import asyncify\n",
    "from fastapi import FastAPI\n",
    "from fast_kafka_api.application import FastKafkaAPI\n",
    "from sqlalchemy.exc import NoResultFound\n",
    "from sqlmodel import Session, select, func\n",
    "\n",
    "import airt_service\n",
    "from airt_service.data.clickhouse import get_count\n",
    "from airt_service.db.models import get_session_with_context, User, TrainingStreamStatus\n",
    "from airt.logger import get_logger\n",
    "from airt.patching import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0806d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:37:49.632 [INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import json\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import uvicorn\n",
    "from confluent_kafka import Producer, Consumer\n",
    "from _pytest.monkeypatch import MonkeyPatch\n",
    "\n",
    "from airt_service.confluent import confluent_kafka_config, create_topics_for_user\n",
    "from airt_service.db.models import create_user_for_testing\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.server import create_ws_server\n",
    "from airt_service.sanitizer import sanitized_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f23d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gdyqwsavak'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0affdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f920174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "def _create(\n",
    "    cls: TrainingStreamStatus,\n",
    "    *,\n",
    "    account_id: int,\n",
    "    application_id: Optional[str] = None,\n",
    "    model_id: str,\n",
    "    event: str,\n",
    "    count: int,\n",
    "    total: int,\n",
    "    user: User,\n",
    "    session: Session\n",
    ") -> TrainingStreamStatus:\n",
    "    \"\"\"\n",
    "    Method to create event\n",
    "\n",
    "    Args:\n",
    "        account_id: account id\n",
    "        application_id: Id of the application in case there is more than one for the AccountId\n",
    "        model_id: User supplied ID of the model trained\n",
    "        event: one of start, upload, end\n",
    "        count: current count of rows in clickhouse db\n",
    "        total: total no. of rows sent by user\n",
    "        user: user object\n",
    "        session: session object\n",
    "\n",
    "    Returns:\n",
    "        created object of type TrainingStreamStatus\n",
    "    \"\"\"\n",
    "    training_event = TrainingStreamStatus(\n",
    "        account_id=account_id,\n",
    "        application_id=application_id,\n",
    "        model_id=model_id,\n",
    "        event=event,\n",
    "        count=count,\n",
    "        total=total,\n",
    "        user=user,\n",
    "    )\n",
    "    session.add(training_event)\n",
    "    session.commit()\n",
    "    return training_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=789, model_id='ChurnModelForDrivers', total=1000, user_id=151, uuid=UUID('80edaccc-7b28-49f1-9dd8-a56b32f8a1f6'), id=36, application_id=None, count=0, created=datetime.datetime(2023, 2, 3, 8, 37, 50))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "throwaway_username = create_user_for_testing()\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == throwaway_username)).one()\n",
    "\n",
    "    test_end_event = TrainingStreamStatus._create(\n",
    "        account_id=789,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        event=\"end\",\n",
    "        count=0,\n",
    "        total=1000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "    session.refresh(test_end_event)\n",
    "    display(test_end_event)\n",
    "    assert test_end_event.id\n",
    "    assert test_end_event.event == \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_recent_event_for_user(\n",
    "    username: str, session: Session\n",
    ") -> List[TrainingStreamStatus]:\n",
    "    \"\"\"\n",
    "    Get recent event for user\n",
    "\n",
    "    Args:\n",
    "        username: username of user to get recent events\n",
    "        session: session object\n",
    "\n",
    "    Returns:\n",
    "        A list of recent events for given user\n",
    "    \"\"\"\n",
    "    user = session.exec(select(User).where(User.username == username)).one()\n",
    "    try:\n",
    "        unique_account_ids = session.exec(\n",
    "            select(TrainingStreamStatus.account_id)\n",
    "            .where(TrainingStreamStatus.user == user)\n",
    "            .distinct()\n",
    "        )\n",
    "    except NoResultFound:\n",
    "        return []\n",
    "\n",
    "    events = []\n",
    "    for unique_account_id in unique_account_ids:\n",
    "        try:\n",
    "            events.append(\n",
    "                session.exec(\n",
    "                    select(TrainingStreamStatus)\n",
    "                    .where(\n",
    "                        TrainingStreamStatus.user == user,\n",
    "                        TrainingStreamStatus.account_id == unique_account_id,\n",
    "                    )\n",
    "                    .order_by(TrainingStreamStatus.created.desc())  # type: ignore\n",
    "                    .order_by(TrainingStreamStatus.id.desc())  # type: ignore\n",
    "                    .limit(1)\n",
    "                ).one()\n",
    "            )\n",
    "        except NoResultFound:\n",
    "            pass\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3fb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=999, model_id='ChurnModelForDrivers', total=10000, user_id=150, uuid=UUID('373984c6-dd62-44d5-8da4-3247c6e90b8a'), id=38, application_id=None, count=10000, created=datetime.datetime(2023, 2, 3, 8, 37, 50)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.start: 'start'>, account_id=666, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('88ddaccb-0301-401d-ab52-31a74f0a47d7'), id=39, application_id=None, count=0, created=datetime.datetime(2023, 2, 3, 8, 37, 50))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end_count = 1_000_000\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    actual = get_recent_event_for_user(username=test_username, session=session)\n",
    "    assert actual == [], actual\n",
    "    test_start_event = TrainingStreamStatus._create(\n",
    "        account_id=999,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        event=\"start\",\n",
    "        count=0,\n",
    "        total=10000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "    test_end_event = TrainingStreamStatus._create(\n",
    "        account_id=999,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        event=\"end\",\n",
    "        count=10000,\n",
    "        total=10000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    test_start_event = TrainingStreamStatus._create(\n",
    "        account_id=666,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        event=\"start\",\n",
    "        count=0,\n",
    "        total=1000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    session.refresh(test_start_event)\n",
    "    session.refresh(test_end_event)\n",
    "\n",
    "    actual = get_recent_event_for_user(username=test_username, session=session)\n",
    "    display(actual)\n",
    "    assert len(actual) == 2\n",
    "    assert actual[0] == test_end_event\n",
    "    assert actual[1] == test_start_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_count_from_training_data_ch_table(account_id: int) -> int:\n",
    "    \"\"\"\n",
    "    Get count of all rows for given account id from clickhouse table\n",
    "\n",
    "    Args:\n",
    "        account_id: account id to use\n",
    "\n",
    "    Returns:\n",
    "        Count for the given account id\n",
    "    \"\"\"\n",
    "    return airt_service.data.clickhouse.get_count(\n",
    "        account_id=account_id,\n",
    "        username=environ[\"KAFKA_CH_USERNAME\"],\n",
    "        password=environ[\"KAFKA_CH_PASSWORD\"],\n",
    "        host=environ[\"KAFKA_CH_HOST\"],\n",
    "        port=int(environ[\"KAFKA_CH_PORT\"]),\n",
    "        database=environ[\"KAFKA_CH_DATABASE\"],\n",
    "        table=environ[\"KAFKA_CH_TABLE\"],\n",
    "        protocol=environ[\"KAFKA_CH_PROTOCOL\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with MonkeyPatch.context() as monkeypatch:\n",
    "    monkeypatch.setattr(\n",
    "        \"__main__.get_count_from_training_data_ch_table\",\n",
    "        lambda account_id: 999,\n",
    "    )\n",
    "    actual = get_count_from_training_data_ch_table(account_id=500)\n",
    "    display(actual)\n",
    "    assert actual == 999, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d167398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_recent_event(\n",
    "    recent_event: TrainingStreamStatus,\n",
    "    *,\n",
    "    session: Session,\n",
    "    end_timedelta: int = 30,\n",
    "    fast_kafka_api_app: FastKafkaAPI\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a single recent event for an username and an AccountId\n",
    "\n",
    "    Args:\n",
    "        recent_event: A recent event of type TrainingStreamStatus from database\n",
    "        session: session object\n",
    "        end_timedelta: timedelta in seconds to use to determine whether upload is over or not\n",
    "    \"\"\"\n",
    "    prev_count = recent_event.count\n",
    "\n",
    "    if recent_event.event == \"end\":\n",
    "        # Check model training status started and start it if not already\n",
    "        pass\n",
    "    elif recent_event.event in [\"start\", \"upload\"]:\n",
    "        curr_count = await asyncify(get_count_from_training_data_ch_table)(\n",
    "            account_id=recent_event.account_id\n",
    "        )\n",
    "        curr_check_on = datetime.utcnow()\n",
    "\n",
    "        #         logger.info(f\"{recent_event=}\")\n",
    "        if (\n",
    "            curr_count == prev_count\n",
    "            and curr_check_on - recent_event.created > timedelta(seconds=end_timedelta)\n",
    "        ):\n",
    "            to_update_event = \"end\"\n",
    "            # Start model training status\n",
    "        elif curr_count != prev_count:\n",
    "            to_update_event = \"upload\"\n",
    "        else:\n",
    "            return\n",
    "        upload_event = await asyncify(TrainingStreamStatus._create)(  # type: ignore\n",
    "            account_id=recent_event.account_id,\n",
    "            application_id=recent_event.application_id,\n",
    "            model_id=recent_event.model_id,\n",
    "            event=to_update_event,\n",
    "            count=curr_count,\n",
    "            total=recent_event.total,\n",
    "            user=recent_event.user,\n",
    "            session=session,\n",
    "        )\n",
    "        # send status msg to kafka\n",
    "        #         training_data_status = TrainingDataStatus(\n",
    "        #             AccountId=recent_event.account_id,\n",
    "        #             no_of_records=curr_count,\n",
    "        #             total_no_of_records=recent_event.total,\n",
    "        #         )\n",
    "        await fast_kafka_api_app.to_infobip_training_data_status(\n",
    "            account_id=recent_event.account_id,\n",
    "            application_id=recent_event.application_id,\n",
    "            model_id=recent_event.model_id,\n",
    "            no_of_records=curr_count,\n",
    "            total_no_of_records=recent_event.total,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc2dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=999, model_id='ChurnModelForDrivers', total=10000, user_id=150, uuid=UUID('373984c6-dd62-44d5-8da4-3247c6e90b8a'), id=38, application_id=None, count=10000, created=datetime.datetime(2023, 2, 3, 8, 37, 50)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=666, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('a5f2f3a8-3644-423e-9b31-eada0dc1ad66'), id=40, application_id=None, count=1000, created=datetime.datetime(2023, 2, 3, 8, 37, 50))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:02.432 [INFO] __main__: from dummy func for to_infobip_training_data_status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=999, model_id='ChurnModelForDrivers', total=10000, user_id=150, uuid=UUID('373984c6-dd62-44d5-8da4-3247c6e90b8a'), id=38, application_id=None, count=10000, created=datetime.datetime(2023, 2, 3, 8, 37, 50)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=666, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('c065d965-8ac7-4e80-8b5f-8a61d0248e4b'), id=41, application_id=None, count=1000, created=datetime.datetime(2023, 2, 3, 8, 38, 2))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_fast_kafka_api = FastKafkaAPI(FastAPI())\n",
    "\n",
    "\n",
    "async def dummy_to_infobip_training_data_status(*args, **kwargs):\n",
    "    logger.info(\"from dummy func for to_infobip_training_data_status\")\n",
    "\n",
    "\n",
    "dummy_fast_kafka_api.to_infobip_training_data_status = (\n",
    "    dummy_to_infobip_training_data_status\n",
    ")\n",
    "\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    test_upload_event = TrainingStreamStatus._create(\n",
    "        account_id=666,\n",
    "        model_id=\"ChurnModelForDrivers\",\n",
    "        event=\"upload\",\n",
    "        count=1000,\n",
    "        total=1000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_from_training_data_ch_table\",\n",
    "            lambda account_id: 1000,\n",
    "        )\n",
    "\n",
    "        user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "        test_recent_events = get_recent_event_for_user(\n",
    "            username=test_username, session=session\n",
    "        )\n",
    "        display(test_recent_events)\n",
    "\n",
    "        await process_recent_event(\n",
    "            test_recent_events[0],\n",
    "            session=session,\n",
    "            fast_kafka_api_app=dummy_fast_kafka_api,\n",
    "        )\n",
    "        changed_recent_events = get_recent_event_for_user(\n",
    "            username=test_username, session=session\n",
    "        )\n",
    "        assert test_recent_events == changed_recent_events\n",
    "\n",
    "        sleep(12)\n",
    "        await process_recent_event(\n",
    "            test_recent_events[1],\n",
    "            session=session,\n",
    "            end_timedelta=10,\n",
    "            fast_kafka_api_app=dummy_fast_kafka_api,\n",
    "        )\n",
    "        changed_recent_events = get_recent_event_for_user(\n",
    "            username=test_username, session=session\n",
    "        )\n",
    "        display(changed_recent_events)\n",
    "        assert test_recent_events[0] == changed_recent_events[0]\n",
    "        assert changed_recent_events[1].account_id == 666\n",
    "        assert changed_recent_events[1].event == \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_training_status(username: str, fast_kafka_api_app: FastKafkaAPI):\n",
    "    \"\"\"\n",
    "    An infinite loop to keep track of training_data uploads from user\n",
    "\n",
    "    Args:\n",
    "        username: username of user to track training data uploads\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        #         logger.info(f\"Starting the process loop\")\n",
    "        with get_session_with_context() as session:\n",
    "            recent_events = await asyncify(get_recent_event_for_user)(username, session)\n",
    "            for recent_event in recent_events:\n",
    "                await process_recent_event(\n",
    "                    recent_event, session=session, fast_kafka_api_app=fast_kafka_api_app\n",
    "                )\n",
    "        await asyncio.sleep(random.randint(1, 4))  # nosec B311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccountId': 6000,\n",
       " 'Application': 'COD',\n",
       " 'DefinitionId': 'sign_in',\n",
       " 'OccurredTimeTicks': 1649146037462,\n",
       " 'OccurredTime': '2022-04-05T08:07:17.462000',\n",
       " 'PersonId': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions = [\n",
    "    \"appLaunch\",\n",
    "    \"sign_in\",\n",
    "    \"sign_out\",\n",
    "    \"add_to_cart\",\n",
    "    \"purchase\",\n",
    "    \"custom_event_1\",\n",
    "    \"custom_event_2\",\n",
    "    \"custom_event_3\",\n",
    "]\n",
    "\n",
    "\n",
    "applications = [\"DriverApp\", \"PUBG\", \"COD\"]\n",
    "\n",
    "\n",
    "def generate_n_rows_for_training_data(n: int, seed: int = 42):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    #     account_id = rng.choice([4000, 5000, 500], size=n)\n",
    "    account_id = 6000\n",
    "    definition_id = rng.choice(definitions, size=n)\n",
    "    application = rng.choice(applications, size=n)\n",
    "    occurred_time_ticks = rng.integers(\n",
    "        datetime(year=2022, month=1, day=1).timestamp() * 1000,\n",
    "        datetime(year=2022, month=11, day=1).timestamp() * 1000,\n",
    "        size=n,\n",
    "    )\n",
    "    occurred_time = pd.to_datetime(occurred_time_ticks, unit=\"ms\").strftime(\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "    )\n",
    "    person_id = rng.integers(n // 10, size=n)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"AccountId\": account_id,\n",
    "            \"Application\": application,\n",
    "            \"DefinitionId\": definition_id,\n",
    "            \"OccurredTimeTicks\": occurred_time_ticks,\n",
    "            \"OccurredTime\": occurred_time,\n",
    "            \"PersonId\": person_id,\n",
    "        }\n",
    "    )\n",
    "    return json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "\n",
    "generate_n_rows_for_training_data(100)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a571e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(uvicorn.Server):\n",
    "    def install_signal_handlers(self):\n",
    "        pass\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def run_in_thread(self):\n",
    "        thread = threading.Thread(target=self.run)\n",
    "        thread.start()\n",
    "        try:\n",
    "            while not self.started:\n",
    "                sleep(1e-3)\n",
    "            yield\n",
    "        finally:\n",
    "            self.should_exit = True\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Called once for each message produced to indicate delivery result.\n",
    "    Triggered by poll() or flush().\"\"\"\n",
    "    if err is not None:\n",
    "        sanitized_print(\"Message delivery failed: {}\".format(err))\n",
    "    else:\n",
    "        #         sanitized_print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:02.534 [INFO] airt_service.confluent: Topic gdyqwsavak_start_training_data created\n",
      "23-02-03 08:38:02.535 [INFO] airt_service.confluent: Topic gdyqwsavak_training_data created\n",
      "23-02-03 08:38:02.535 [INFO] airt_service.confluent: Topic gdyqwsavak_realtime_data created\n",
      "23-02-03 08:38:02.536 [INFO] airt_service.confluent: Topic gdyqwsavak_training_data_status created\n",
      "23-02-03 08:38:02.536 [INFO] airt_service.confluent: Topic gdyqwsavak_training_model_status created\n",
      "23-02-03 08:38:02.536 [INFO] airt_service.confluent: Topic gdyqwsavak_model_metrics created\n",
      "23-02-03 08:38:02.537 [INFO] airt_service.confluent: Topic gdyqwsavak_prediction created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1675413482.472|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1675413482.472|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:02.783 [INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [27613]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:02.894 [INFO] fast_kafka_api._components.asyncapi: Keeping the old async specifications at: 'asyncapi/spec/asyncapi.yml'\n",
      "23-02-03 08:38:02.895 [INFO] fast_kafka_api._components.asyncapi: Skipping generating async documentation in '/work/airt-service/notebooks/asyncapi/docs'\n",
      "23-02-03 08:38:02.897 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-02-03 08:38:02.917 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-02-03 08:38:02.937 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-02-03 08:38:02.952 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-02-03 08:38:02.966 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-02-03 08:38:02.967 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "23-02-03 08:38:02.968 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-02-03 08:38:02.968 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "23-02-03 08:38:02.969 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-02-03 08:38:02.969 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:6009 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server started\n",
      "23-02-03 08:38:02.976 [INFO] __main__: I am done at tests\n",
      "23-02-03 08:38:03.016 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-02-03 08:38:03.023 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_start_training_data'})\n",
      "23-02-03 08:38:03.023 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_start_training_data'}\n",
      "23-02-03 08:38:03.023 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-02-03 08:38:03.024 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-02-03 08:38:03.024 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_realtime_data'})\n",
      "23-02-03 08:38:03.025 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_realtime_data'}\n",
      "23-02-03 08:38:03.025 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-02-03 08:38:03.029 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-02-03 08:38:03.030 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'infobip_training_data'})\n",
      "23-02-03 08:38:03.031 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'infobip_training_data'}\n",
      "23-02-03 08:38:03.031 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-02-03 08:38:03.037 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.038 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.038 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.041 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 35) with member_id aiokafka-0.8.0-2a627f89-e304-43af-a415-1a0035ca8fce\n",
      "23-02-03 08:38:03.041 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-02-03 08:38:03.043 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.044 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.044 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.045 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1003 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.046 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.046 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:03.047 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 35\n",
      "23-02-03 08:38:03.048 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training_data', partition=5), TopicPartition(topic='infobip_start_training_data', partition=0), TopicPartition(topic='infobip_start_training_data', partition=3), TopicPartition(topic='infobip_start_training_data', partition=4), TopicPartition(topic='infobip_start_training_data', partition=1), TopicPartition(topic='infobip_start_training_data', partition=2)} for group kumaran-airt-service-kafka-1:9092_group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1675413483.004|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1675413483.004|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:06.052 [WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "23-02-03 08:38:06.054 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='infobip_start_training_data', partition=0), TopicPartition(topic='infobip_start_training_data', partition=3), TopicPartition(topic='infobip_start_training_data', partition=2), TopicPartition(topic='infobip_start_training_data', partition=5), TopicPartition(topic='infobip_start_training_data', partition=4), TopicPartition(topic='infobip_start_training_data', partition=1)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:06.055 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:06.056 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-ffa5855e-211f-406b-91f5-7879b2041735\n",
      "23-02-03 08:38:06.057 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-2a627f89-e304-43af-a415-1a0035ca8fce\n",
      "23-02-03 08:38:06.058 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-02-03 08:38:06.059 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 36) with member_id aiokafka-0.8.0-32cce58c-219c-418b-b00b-aafcbd79ccd7\n",
      "23-02-03 08:38:06.557 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'infobip_start_training_data': 6} to {'infobip_training_data': 6, 'infobip_realtime_data': 6, 'infobip_start_training_data': 6}. \n",
      "23-02-03 08:38:06.559 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "23-02-03 08:38:06.559 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_realtime_data', partition=2), TopicPartition(topic='infobip_realtime_data', partition=4), TopicPartition(topic='infobip_realtime_data', partition=5), TopicPartition(topic='infobip_realtime_data', partition=0), TopicPartition(topic='infobip_realtime_data', partition=3), TopicPartition(topic='infobip_realtime_data', partition=1)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:06.560 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "23-02-03 08:38:06.560 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_training_data', partition=3), TopicPartition(topic='infobip_training_data', partition=1), TopicPartition(topic='infobip_training_data', partition=4), TopicPartition(topic='infobip_training_data', partition=5), TopicPartition(topic='infobip_training_data', partition=0), TopicPartition(topic='infobip_training_data', partition=2)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:06.560 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 36\n",
      "23-02-03 08:38:06.561 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='infobip_start_training_data', partition=5), TopicPartition(topic='infobip_start_training_data', partition=0), TopicPartition(topic='infobip_start_training_data', partition=3), TopicPartition(topic='infobip_start_training_data', partition=4), TopicPartition(topic='infobip_start_training_data', partition=1), TopicPartition(topic='infobip_start_training_data', partition=2)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-02-03 08:38:09.054 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:14.093 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:19.129 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:24.166 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:29.202 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:34.228 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5') id=43 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 4)\n",
      "23-02-03 08:38:39.262 [INFO] __main__: event in test is event=<TrainingEvent.end: 'end'> account_id=6000 model_id='ChurnModelForDrivers' total=1000 user_id=150 uuid=UUID('2b106413-8b27-48de-a35a-e6f53228b7a5') id=44 application_id=None count=999 created=datetime.datetime(2023, 2, 3, 8, 38, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All events for account id 6000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.start: 'start'>, account_id=6000, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('17422eb8-0a82-4bda-8e68-dd177126c314'), id=42, application_id=None, count=0, created=datetime.datetime(2023, 2, 3, 8, 38, 3)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=6000, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('6a541b79-6833-45d2-b1be-53f59c456ce5'), id=43, application_id=None, count=999, created=datetime.datetime(2023, 2, 3, 8, 38, 4)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=6000, model_id='ChurnModelForDrivers', total=1000, user_id=150, uuid=UUID('2b106413-8b27-48de-a35a-e6f53228b7a5'), id=44, application_id=None, count=999, created=datetime.datetime(2023, 2, 3, 8, 38, 35))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-03 08:38:39.472 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-02-03 08:38:39.473 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-02-03 08:38:39.473 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-02-03 08:38:39.474 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-02-03 08:38:39.474 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-02-03 08:38:39.475 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-02-03 08:38:39.475 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-02-03 08:38:39.476 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-02-03 08:38:39.476 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [27613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "create_topics_for_user(username=test_username)\n",
    "\n",
    "\n",
    "def test_process_training_status():\n",
    "    logger.info(\"I am done at tests\")\n",
    "    with get_session_with_context() as session:\n",
    "        user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "        test_start_event = TrainingStreamStatus._create(\n",
    "            account_id=6000,\n",
    "            model_id=\"ChurnModelForDrivers\",\n",
    "            event=\"start\",\n",
    "            count=0,\n",
    "            total=1000,\n",
    "            user=user,\n",
    "            session=session,\n",
    "        )\n",
    "        session.add(test_start_event)\n",
    "        session.commit()\n",
    "\n",
    "        p = Producer(confluent_kafka_config)\n",
    "        msg_count = 1000\n",
    "        training_data = generate_n_rows_for_training_data(msg_count, seed=999)\n",
    "        for i in range(msg_count):\n",
    "            p.produce(\n",
    "                f\"{test_username}_training_data\",\n",
    "                json.dumps(training_data[i]).encode(\"utf-8\"),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "        p.flush()\n",
    "\n",
    "    while True:\n",
    "        sleep(5)\n",
    "        with get_session_with_context() as session:\n",
    "            user = session.exec(\n",
    "                select(User).where(User.username == test_username)\n",
    "            ).one()\n",
    "            event = session.exec(\n",
    "                select(TrainingStreamStatus)\n",
    "                .where(TrainingStreamStatus.user == user)\n",
    "                .where(TrainingStreamStatus.account_id == 6000)\n",
    "                .order_by(TrainingStreamStatus.id.desc())\n",
    "                .limit(1)\n",
    "            ).one()\n",
    "            logger.info(f\"event in test is {event}\")\n",
    "            if event.event == \"end\":\n",
    "                display(f\"All events for account id {6000}\")\n",
    "                all_events = session.exec(\n",
    "                    select(TrainingStreamStatus)\n",
    "                    .where(TrainingStreamStatus.user == user)\n",
    "                    .where(TrainingStreamStatus.account_id == 6000)\n",
    "                )\n",
    "                display([e for e in all_events])\n",
    "                break\n",
    "\n",
    "\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_from_training_data_ch_table\",\n",
    "            lambda account_id: 999,\n",
    "        )\n",
    "        app, fast_kafka_api_app = create_ws_server(\n",
    "            assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "        )\n",
    "\n",
    "        @fast_kafka_api_app.run_in_background()\n",
    "        async def startup_event():\n",
    "            await process_training_status(\n",
    "                username=test_username, fast_kafka_api_app=fast_kafka_api_app\n",
    "            )\n",
    "\n",
    "        config = uvicorn.Config(app, host=\"127.0.0.1\", port=6009, log_level=\"debug\")\n",
    "        server = Server(config=config)\n",
    "\n",
    "        with server.run_in_thread():\n",
    "            # Server started.\n",
    "            sanitized_print(\"server started\")\n",
    "            test_process_training_status()\n",
    "\n",
    "        sanitized_print(\"server stopped\")\n",
    "        # Server stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62834287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
