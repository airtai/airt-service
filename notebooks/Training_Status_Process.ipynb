{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24fe3dc",
   "metadata": {},
   "source": [
    "# Training Status Process\n",
    "> Process to handle training data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training_status_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc957a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:27.890 [INFO] airt.executor.subcommand: Module loaded.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from os import environ\n",
    "from time import sleep\n",
    "from typing import *\n",
    "\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from asyncer import asyncify\n",
    "from fastapi import FastAPI\n",
    "from fast_kafka_api.application import FastKafkaAPI\n",
    "from sqlalchemy.exc import NoResultFound\n",
    "from sqlmodel import Session, select, func\n",
    "\n",
    "import airt_service\n",
    "from airt_service.users import User\n",
    "from airt_service.data.clickhouse import get_count_for_account_ids\n",
    "from airt_service.db.models import (\n",
    "    create_connection_string,\n",
    "    get_db_params_from_env_vars,\n",
    "    get_engine,\n",
    "    get_session_with_context,\n",
    "    User,\n",
    "    TrainingStreamStatus,\n",
    ")\n",
    "from airt.logger import get_logger\n",
    "from airt.patching import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0806d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "import posix_ipc\n",
    "import pytest\n",
    "import uvicorn\n",
    "from confluent_kafka import Producer, Consumer\n",
    "from _pytest.monkeypatch import MonkeyPatch\n",
    "\n",
    "from airt_service.confluent import confluent_kafka_config, create_topics_for_user\n",
    "from airt_service.db.models import create_user_for_testing\n",
    "from airt_service.helpers import set_env_variable_context\n",
    "from airt_service.server import create_ws_server\n",
    "from airt_service.sanitizer import sanitized_print\n",
    "from airt_service.uvicorn_helpers import run_uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f23d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pfwmozvbyr'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_username = create_user_for_testing()\n",
    "display(test_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0affdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f920174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch(cls_method=True)\n",
    "def _create(\n",
    "    cls: TrainingStreamStatus,\n",
    "    *,\n",
    "    account_id: int,\n",
    "    event: str,\n",
    "    count: int,\n",
    "    total: int,\n",
    "    user: User,\n",
    "    session: Session\n",
    ") -> TrainingStreamStatus:\n",
    "    \"\"\"\n",
    "    Method to create event\n",
    "\n",
    "    Args:\n",
    "        account_id: account id\n",
    "        event: one of start, upload, end\n",
    "        count: current count of rows in clickhouse db\n",
    "        total: total no. of rows sent by user\n",
    "        user: user object\n",
    "        session: session object\n",
    "\n",
    "    Returns:\n",
    "        created object of type TrainingStreamStatus\n",
    "    \"\"\"\n",
    "    training_event = TrainingStreamStatus(\n",
    "        account_id=account_id, event=event, count=count, total=total, user=user\n",
    "    )\n",
    "    session.add(training_event)\n",
    "    session.commit()\n",
    "    return training_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=789, total=1000, user_id=447, uuid=UUID('33d86684-9cb6-4397-872c-111bd5a8474e'), id=44, count=0, created=datetime.datetime(2023, 1, 24, 17, 54, 29))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "throwaway_username = create_user_for_testing()\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == throwaway_username)).one()\n",
    "\n",
    "    test_end_event = TrainingStreamStatus._create(\n",
    "        account_id=789, event=\"end\", count=0, total=1000, user=user, session=session\n",
    "    )\n",
    "    session.refresh(test_end_event)\n",
    "    display(test_end_event)\n",
    "    assert test_end_event.id\n",
    "    assert test_end_event.event == \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with get_session_with_context() as session:\n",
    "#     user = session.exec(select(User).where(User.username == throwaway_username)).one()\n",
    "\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=112, event=\"start\", count=0, total=1000, user=user, session=session\n",
    "#     )\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=112, event=\"upload\", count=500, total=1000, user=user, session=session\n",
    "#     )\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=112, event=\"end\", count=1000, total=1000, user=user, session=session\n",
    "#     )\n",
    "\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=141, event=\"start\", count=0, total=3000, user=user, session=session\n",
    "#     )\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=141, event=\"upload\", count=100, total=3000, user=user, session=session\n",
    "#     )\n",
    "\n",
    "#     TrainingStreamStatus._create(\n",
    "#         account_id=600, event=\"start\", count=0, total=6000, user=user, session=session\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8608f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_recent_event_for_user(username: str, session: Session) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get recent event for user\n",
    "\n",
    "    Args:\n",
    "        username: username of user to get recent events\n",
    "        session: session object\n",
    "\n",
    "    Returns:\n",
    "        A list of recent events for given user\n",
    "    \"\"\"\n",
    "    user = session.exec(select(User).where(User.username == username)).one()\n",
    "\n",
    "    conn_str = create_connection_string(**get_db_params_from_env_vars())  # type: ignore\n",
    "\n",
    "    # Get all rows from table\n",
    "    df = pd.read_sql_table(table_name=\"trainingstreamstatus\", con=conn_str)\n",
    "\n",
    "    # Filter events for given user and group by account_id\n",
    "    events_for_user = (\n",
    "        df.loc[df[\"user_id\"] == user.id]\n",
    "        .sort_values([\"created\", \"id\"], ascending=[False, False])\n",
    "        .groupby(\"account_id\")\n",
    "        .first()\n",
    "    )\n",
    "    events_for_user.index.names = [\"AccountId\"]\n",
    "    events_for_user.rename(columns={\"count\": \"prev_count\"}, inplace=True)\n",
    "\n",
    "    # Leave 'end' events\n",
    "    return events_for_user.loc[events_for_user[\"event\"] != \"end\"].sort_values(\n",
    "        [\"AccountId\"], ascending=[True]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3fb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>start</td>\n",
       "      <td>47</td>\n",
       "      <td>7d472408558b4fd9bf775d424b796018</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-24 17:54:29</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event  id                              uuid  prev_count  total  \\\n",
       "AccountId                                                                   \n",
       "666        start  47  7d472408558b4fd9bf775d424b796018           0   1000   \n",
       "\n",
       "                      created  user_id  \n",
       "AccountId                               \n",
       "666       2023-01-24 17:54:29      446  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end_count = 1_000_000\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    actual = get_recent_event_for_user(username=test_username, session=session)\n",
    "    assert actual.empty, actual\n",
    "    test_start_event = TrainingStreamStatus._create(\n",
    "        account_id=999, event=\"start\", count=0, total=10000, user=user, session=session\n",
    "    )\n",
    "    test_end_event = TrainingStreamStatus._create(\n",
    "        account_id=999,\n",
    "        event=\"end\",\n",
    "        count=10000,\n",
    "        total=10000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    test_start_event = TrainingStreamStatus._create(\n",
    "        account_id=666, event=\"start\", count=0, total=1000, user=user, session=session\n",
    "    )\n",
    "\n",
    "    session.refresh(test_start_event)\n",
    "    session.refresh(test_end_event)\n",
    "\n",
    "    actual = get_recent_event_for_user(username=test_username, session=session)\n",
    "    display(actual)\n",
    "    assert len(actual) == 1\n",
    "    actual.iloc[0][\"event\"] == test_start_event.event\n",
    "    actual.iloc[0][\"user_id\"] == test_start_event.user.id\n",
    "    actual.index[0] == test_start_event.account_id\n",
    "    test_recent_events_df = actual.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_count_from_training_data_ch_table(\n",
    "    account_ids: List[Union[int, str]]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get count of all rows for given account ids from clickhouse table\n",
    "\n",
    "    Args:\n",
    "        account_ids: List of account_ids to get count\n",
    "\n",
    "    Returns:\n",
    "        Count for the given account id\n",
    "    \"\"\"\n",
    "    return airt_service.data.clickhouse.get_count_for_account_ids(\n",
    "        account_ids=account_ids,\n",
    "        username=environ[\"KAFKA_CH_USERNAME\"],\n",
    "        password=environ[\"KAFKA_CH_PASSWORD\"],\n",
    "        host=environ[\"KAFKA_CH_HOST\"],\n",
    "        port=int(environ[\"KAFKA_CH_PORT\"]),\n",
    "        database=environ[\"KAFKA_CH_DATABASE\"],\n",
    "        table=environ[\"KAFKA_CH_TABLE\"],\n",
    "        protocol=environ[\"KAFKA_CH_PROTOCOL\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>999</td>\n",
       "      <td>2023-01-24 17:54:28.874082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           curr_count              curr_check_on\n",
       "AccountId                                       \n",
       "500               999 2023-01-24 17:54:28.874082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with MonkeyPatch.context() as monkeypatch:\n",
    "    monkeypatch.setattr(\n",
    "        \"__main__.get_count_from_training_data_ch_table\",\n",
    "        lambda account_ids: pd.DataFrame(\n",
    "            {\n",
    "                \"curr_count\": [999] * len(account_ids),\n",
    "                \"AccountId\": account_ids,\n",
    "                \"curr_check_on\": [datetime.utcnow()] * len(account_ids),\n",
    "            }\n",
    "        ).set_index(\"AccountId\"),\n",
    "    )\n",
    "    actual = get_count_from_training_data_ch_table(account_ids=[500])\n",
    "    display(actual)\n",
    "    assert actual.iloc[0][\"curr_count\"] == 999, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_user(username: str, session: Session) -> Optional[User]:\n",
    "    \"\"\"Get the user object for the given username\n",
    "\n",
    "    Args:\n",
    "        username: Username as a string\n",
    "\n",
    "    Returns:\n",
    "        The user object if username is valid else None\n",
    "    \"\"\"\n",
    "\n",
    "    return session.exec(select(User).where(User.username == username)).one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e539a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_session_with_context() as session:\n",
    "    actual = get_user(username=test_username, session=session)\n",
    "    assert actual.username == test_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_row(\n",
    "    row: pd.Series,\n",
    "    user: User,\n",
    "    session: Session,\n",
    "    fast_kafka_api_app: FastKafkaAPI,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a single row, update mysql db and send status message to kafka\n",
    "\n",
    "    Args:\n",
    "        row: pandas row\n",
    "        user: user object\n",
    "        session: session object\n",
    "    \"\"\"\n",
    "    if not row[\"action\"]:\n",
    "        return\n",
    "\n",
    "    async_training_stream_status_create = asyncify(TrainingStreamStatus._create)\n",
    "\n",
    "    account_id = row.name\n",
    "\n",
    "    upload_event = await async_training_stream_status_create(  # type: ignore\n",
    "        account_id=account_id,\n",
    "        event=row[\"action\"],\n",
    "        count=row[\"curr_count\"],\n",
    "        total=row[\"total\"],\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "    await fast_kafka_api_app.to_infobip_training_data_status(\n",
    "        account_id=account_id,\n",
    "        no_of_records=row[\"curr_count\"],\n",
    "        total_no_of_records=row[\"total\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0003505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>start</td>\n",
       "      <td>47</td>\n",
       "      <td>7d472408558b4fd9bf775d424b796018</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-24 17:54:29</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event  id                              uuid  prev_count  total  \\\n",
       "AccountId                                                                   \n",
       "666        start  47  7d472408558b4fd9bf775d424b796018           0   1000   \n",
       "\n",
       "                      created  user_id  \n",
       "AccountId                               \n",
       "666       2023-01-24 17:54:29      446  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>500</td>\n",
       "      <td>2023-01-24 17:54:28.914447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           curr_count              curr_check_on\n",
       "AccountId                                       \n",
       "666               500 2023-01-24 17:54:28.914447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "      <th>curr_count</th>\n",
       "      <th>curr_check_on</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>start</td>\n",
       "      <td>47</td>\n",
       "      <td>7d472408558b4fd9bf775d424b796018</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-24 17:54:29</td>\n",
       "      <td>446</td>\n",
       "      <td>500</td>\n",
       "      <td>2023-01-24 17:54:28.914447</td>\n",
       "      <td>upload</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event  id                              uuid  prev_count  total  \\\n",
       "AccountId                                                                   \n",
       "666        start  47  7d472408558b4fd9bf775d424b796018           0   1000   \n",
       "\n",
       "                      created  user_id  curr_count              curr_check_on  \\\n",
       "AccountId                                                                       \n",
       "666       2023-01-24 17:54:29      446         500 2023-01-24 17:54:28.914447   \n",
       "\n",
       "           action  \n",
       "AccountId          \n",
       "666        upload  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:28.948 [INFO] __main__: from dummy func for to_infobip_training_data_status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"most_recent_event=TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=666, total=1000, user_id=446, uuid=UUID('debecf80-b7d5-490f-b4fe-ff07fe45629a'), id=48, count=500, created=datetime.datetime(2023, 1, 24, 17, 54, 29))\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_recent_events_df)\n",
    "test_ch_df = pd.DataFrame(\n",
    "    {\n",
    "        \"curr_count\": [500],\n",
    "        \"AccountId\": 666,\n",
    "        \"curr_check_on\": [datetime.utcnow()],\n",
    "    }\n",
    ").set_index(\"AccountId\")\n",
    "display(test_ch_df)\n",
    "\n",
    "merged = pd.merge(test_recent_events_df, test_ch_df, on=\"AccountId\")\n",
    "merged[\"action\"] = np.where(\n",
    "    merged[\"curr_count\"] != merged[\"prev_count\"],\n",
    "    \"upload\",\n",
    "    np.where(\n",
    "        merged[\"curr_check_on\"] - merged[\"created\"] > pd.Timedelta(seconds=10),\n",
    "        \"end\",\n",
    "        None,\n",
    "    ),\n",
    ")\n",
    "display(merged)\n",
    "\n",
    "dummy_fast_kafka_api = FastKafkaAPI(FastAPI())\n",
    "\n",
    "\n",
    "async def dummy_to_infobip_training_data_status(*args, **kwargs):\n",
    "    logger.info(\"from dummy func for to_infobip_training_data_status\")\n",
    "\n",
    "\n",
    "dummy_fast_kafka_api.to_infobip_training_data_status = (\n",
    "    dummy_to_infobip_training_data_status\n",
    ")\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "\n",
    "    for index, row in merged.iterrows():\n",
    "\n",
    "        await process_row(\n",
    "            row, user=user, session=session, fast_kafka_api_app=dummy_fast_kafka_api\n",
    "        )\n",
    "\n",
    "    most_recent_event = session.exec(\n",
    "        select(TrainingStreamStatus)\n",
    "        .where(TrainingStreamStatus.user == user)\n",
    "        #         .where(TrainingStreamStatus.account_id == 666)\n",
    "        .order_by(TrainingStreamStatus.id.desc())\n",
    "        .limit(1)\n",
    "    ).one()\n",
    "    display(f\"{most_recent_event=}\")\n",
    "    assert most_recent_event.account_id == 666\n",
    "    assert most_recent_event.event == \"upload\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc02e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_dataframes(\n",
    "    recent_events_df: pd.DataFrame,\n",
    "    ch_df: pd.DataFrame,\n",
    "    *,\n",
    "    user: User,\n",
    "    session: Session,\n",
    "    end_timedelta: int = 30,\n",
    "    fast_kafka_api_app: FastKafkaAPI,\n",
    "):\n",
    "    \"\"\"\n",
    "    Process mysql, clickhouse dataframes and take action if needed\n",
    "\n",
    "    Args:\n",
    "        recent_events_df: recent events as pandas dataframe from mysql db\n",
    "        ch_df: count from clickhouse table as dataframe\n",
    "        user: user object\n",
    "        session: session object\n",
    "        end_timedelta: timedelta in seconds to use to determine whether upload is over or not\n",
    "    \"\"\"\n",
    "    df = pd.merge(recent_events_df, ch_df, on=\"AccountId\")\n",
    "    xs = np.where(  # type: ignore\n",
    "        df[\"curr_check_on\"] - df[\"created\"] > pd.Timedelta(seconds=end_timedelta),\n",
    "        \"end\",\n",
    "        None,\n",
    "    )\n",
    "    df[\"action\"] = np.where(\n",
    "        df[\"curr_count\"] != df[\"prev_count\"],\n",
    "        \"upload\",\n",
    "        xs,\n",
    "    )\n",
    "\n",
    "    for account_id, row in df.iterrows():\n",
    "\n",
    "        await process_row(\n",
    "            row, user=user, session=session, fast_kafka_api_app=fast_kafka_api_app\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8072e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>upload</td>\n",
       "      <td>49</td>\n",
       "      <td>47a56022025648fe850baa5e0f2a5ec8</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2023-01-24 17:54:29</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            event  id                              uuid  prev_count  total  \\\n",
       "AccountId                                                                    \n",
       "666        upload  49  47a56022025648fe850baa5e0f2a5ec8        1000   1000   \n",
       "\n",
       "                      created  user_id  \n",
       "AccountId                               \n",
       "666       2023-01-24 17:54:29      446  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:41.094 [INFO] __main__: from dummy func for to_infobip_training_data_status\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>prev_count</th>\n",
       "      <th>total</th>\n",
       "      <th>created</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AccountId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [event, id, uuid, prev_count, total, created, user_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"most_recent_event=TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=666, total=1000, user_id=446, uuid=UUID('235f40b2-8efc-43f7-9516-7164d8c9108b'), id=50, count=1000, created=datetime.datetime(2023, 1, 24, 17, 54, 41))\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_fast_kafka_api = FastKafkaAPI(FastAPI())\n",
    "\n",
    "\n",
    "async def dummy_to_infobip_training_data_status(*args, **kwargs):\n",
    "    logger.info(\"from dummy func for to_infobip_training_data_status\")\n",
    "\n",
    "\n",
    "dummy_fast_kafka_api.to_infobip_training_data_status = (\n",
    "    dummy_to_infobip_training_data_status\n",
    ")\n",
    "\n",
    "\n",
    "with get_session_with_context() as session:\n",
    "    test_upload_event = TrainingStreamStatus._create(\n",
    "        account_id=666,\n",
    "        event=\"upload\",\n",
    "        count=1000,\n",
    "        total=1000,\n",
    "        user=user,\n",
    "        session=session,\n",
    "    )\n",
    "\n",
    "    user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "    test_recent_events = get_recent_event_for_user(\n",
    "        username=test_username, session=session\n",
    "    )\n",
    "    display(test_recent_events)\n",
    "    test_ch_df = pd.DataFrame(\n",
    "        {\"curr_count\": [1000], \"AccountId\": [666], \"curr_check_on\": [datetime.utcnow()]}\n",
    "    ).set_index(\"AccountId\")\n",
    "\n",
    "    await process_dataframes(\n",
    "        recent_events_df=test_recent_events,\n",
    "        ch_df=test_ch_df,\n",
    "        user=user,\n",
    "        session=session,\n",
    "        fast_kafka_api_app=dummy_fast_kafka_api,\n",
    "    )\n",
    "    changed_recent_events = get_recent_event_for_user(\n",
    "        username=test_username, session=session\n",
    "    )\n",
    "    pd.testing.assert_frame_equal(test_recent_events, changed_recent_events)\n",
    "    #     assert test_recent_events == changed_recent_events\n",
    "\n",
    "    sleep(12)\n",
    "    test_ch_df = pd.DataFrame(\n",
    "        {\"curr_count\": [1000], \"AccountId\": [666], \"curr_check_on\": [datetime.utcnow()]}\n",
    "    ).set_index(\"AccountId\")\n",
    "    await process_dataframes(\n",
    "        recent_events_df=test_recent_events,\n",
    "        ch_df=test_ch_df,\n",
    "        user=user,\n",
    "        session=session,\n",
    "        end_timedelta=10,\n",
    "        fast_kafka_api_app=dummy_fast_kafka_api,\n",
    "    )\n",
    "\n",
    "    changed_recent_events = get_recent_event_for_user(\n",
    "        username=test_username, session=session\n",
    "    )\n",
    "    display(changed_recent_events)\n",
    "    assert changed_recent_events.empty\n",
    "\n",
    "    most_recent_event = session.exec(\n",
    "        select(TrainingStreamStatus)\n",
    "        .where(TrainingStreamStatus.user == user)\n",
    "        #         .where(TrainingStreamStatus.account_id == 666)\n",
    "        .order_by(TrainingStreamStatus.id.desc())\n",
    "        .limit(1)\n",
    "    ).one()\n",
    "    display(f\"{most_recent_event=}\")\n",
    "    assert most_recent_event.account_id == 666\n",
    "    assert most_recent_event.event == \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e0267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_training_status(username: str, fast_kafka_api_app: FastKafkaAPI):\n",
    "    \"\"\"\n",
    "    An infinite loop to keep track of training_data uploads from user\n",
    "\n",
    "    Args:\n",
    "        username: username of user to track training data uploads\n",
    "    \"\"\"\n",
    "    async_get_user = asyncify(get_user)\n",
    "    async_get_recent_event_for_user = asyncify(get_recent_event_for_user)\n",
    "    async_get_count_from_training_data_ch_table = asyncify(\n",
    "        get_count_from_training_data_ch_table\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        #         logger.info(f\"Starting the process loop\")\n",
    "        try:\n",
    "            engine = get_engine(**get_db_params_from_env_vars())  # type: ignore\n",
    "            session = Session(engine)\n",
    "\n",
    "            user = await async_get_user(username, session)\n",
    "            recent_events_df = await async_get_recent_event_for_user(username, session)\n",
    "            if not recent_events_df.empty:\n",
    "                ch_df = await async_get_count_from_training_data_ch_table(\n",
    "                    account_ids=recent_events_df.index.tolist()\n",
    "                )\n",
    "                await process_dataframes(\n",
    "                    recent_events_df=recent_events_df,\n",
    "                    ch_df=ch_df,\n",
    "                    user=user,  # type: ignore\n",
    "                    session=session,\n",
    "                    fast_kafka_api_app=fast_kafka_api_app,\n",
    "                )\n",
    "\n",
    "            session.close()\n",
    "            engine.dispose()\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Error in process_training_status - {e}\")\n",
    "\n",
    "        await asyncio.sleep(random.randint(5, 20))  # nosec B311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AccountId': 6000,\n",
       " 'Application': 'COD',\n",
       " 'DefinitionId': 'sign_in',\n",
       " 'OccurredTimeTicks': 1649146037462,\n",
       " 'OccurredTime': '2022-04-05T08:07:17.462000',\n",
       " 'PersonId': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions = [\n",
    "    \"appLaunch\",\n",
    "    \"sign_in\",\n",
    "    \"sign_out\",\n",
    "    \"add_to_cart\",\n",
    "    \"purchase\",\n",
    "    \"custom_event_1\",\n",
    "    \"custom_event_2\",\n",
    "    \"custom_event_3\",\n",
    "]\n",
    "\n",
    "\n",
    "applications = [\"DriverApp\", \"PUBG\", \"COD\"]\n",
    "\n",
    "\n",
    "def generate_n_rows_for_training_data(n: int, seed: int = 42):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    #     account_id = rng.choice([4000, 5000, 500], size=n)\n",
    "    account_id = 6000\n",
    "    definition_id = rng.choice(definitions, size=n)\n",
    "    application = rng.choice(applications, size=n)\n",
    "    occurred_time_ticks = rng.integers(\n",
    "        datetime(year=2022, month=1, day=1).timestamp() * 1000,\n",
    "        datetime(year=2022, month=11, day=1).timestamp() * 1000,\n",
    "        size=n,\n",
    "    )\n",
    "    occurred_time = pd.to_datetime(occurred_time_ticks, unit=\"ms\").strftime(\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "    )\n",
    "    person_id = rng.integers(n // 10, size=n)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"AccountId\": account_id,\n",
    "            \"Application\": application,\n",
    "            \"DefinitionId\": definition_id,\n",
    "            \"OccurredTimeTicks\": occurred_time_ticks,\n",
    "            \"OccurredTime\": occurred_time,\n",
    "            \"PersonId\": person_id,\n",
    "        }\n",
    "    )\n",
    "    return json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "\n",
    "generate_n_rows_for_training_data(100)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a571e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_report(err, msg):\n",
    "    \"\"\"Called once for each message produced to indicate delivery result.\n",
    "    Triggered by poll() or flush().\"\"\"\n",
    "    if err is not None:\n",
    "        sanitized_print(\"Message delivery failed: {}\".format(err))\n",
    "    else:\n",
    "        #         sanitized_print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba6006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'starting semaphore'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'semaphore started'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:41.267 [INFO] airt_service.confluent: Topic pfwmozvbyr_start_training_data created\n",
      "23-01-24 17:54:41.268 [INFO] airt_service.confluent: Topic pfwmozvbyr_training_data created\n",
      "23-01-24 17:54:41.268 [INFO] airt_service.confluent: Topic pfwmozvbyr_realitime_data created\n",
      "23-01-24 17:54:41.269 [INFO] airt_service.confluent: Topic pfwmozvbyr_training_data_status created\n",
      "23-01-24 17:54:41.269 [INFO] airt_service.confluent: Topic pfwmozvbyr_training_model_status created\n",
      "23-01-24 17:54:41.269 [INFO] airt_service.confluent: Topic pfwmozvbyr_model_metrics created\n",
      "23-01-24 17:54:41.270 [INFO] airt_service.confluent: Topic pfwmozvbyr_prediction created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674582881.183|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674582881.183|CONFWARN|rdkafka#producer-1| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:41.596 [INFO] airt_service.server: kafka_config={'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'group_id': 'kumaran-airt-service-kafka-1:9092_group', 'auto_offset_reset': 'earliest'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [88256]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:41.734 [INFO] fast_kafka_api._components.asyncapi: New async specifications generated at: 'asyncapi/spec/asyncapi.yml'\n",
      "server started\n",
      "23-01-24 17:54:46.632 [INFO] __main__: I am done at tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1674582886.652|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property group.id is a consumer property and will be ignored by this producer instance\n",
      "%4|1674582886.652|CONFWARN|rdkafka#producer-2| [thrd:app]: Configuration property auto.offset.reset is a consumer property and will be ignored by this producer instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:54:52.698 [INFO] __main__: event in test is event=<TrainingEvent.start: 'start'> account_id=6000 total=1000 user_id=446 uuid=UUID('831abe3c-2fe1-4df1-9286-2249e03713b0') id=51 count=0 created=datetime.datetime(2023, 1, 24, 17, 54, 47)\n",
      "23-01-24 17:54:57.748 [INFO] __main__: event in test is event=<TrainingEvent.start: 'start'> account_id=6000 total=1000 user_id=446 uuid=UUID('831abe3c-2fe1-4df1-9286-2249e03713b0') id=51 count=0 created=datetime.datetime(2023, 1, 24, 17, 54, 47)\n",
      "23-01-24 17:55:00.650 [INFO] fast_kafka_api._components.asyncapi: Async docs generated at 'asyncapi/docs'\n",
      "23-01-24 17:55:00.652 [INFO] fast_kafka_api._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'\u001b[32m\n",
      "\n",
      "Done! âœ¨\u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/work/airt-service/notebooks/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "\n",
      "23-01-24 17:55:00.653 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-01-24 17:55:00.674 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-01-24 17:55:00.697 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-01-24 17:55:00.721 [INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092'}'\n",
      "23-01-24 17:55:00.745 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-01-24 17:55:00.746 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "23-01-24 17:55:00.748 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-01-24 17:55:00.750 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n",
      "23-01-24 17:55:00.751 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-01-24 17:55:00.752 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'kumaran-airt-service-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'group_id': 'kumaran-airt-service-kafka-1:9092_group'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6010 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:55:01.012 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-01-24 17:55:01.014 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_realtime_data'})\n",
      "23-01-24 17:55:01.015 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_realtime_data'}\n",
      "23-01-24 17:55:01.016 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-01-24 17:55:01.029 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-01-24 17:55:01.031 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_start_training_data'})\n",
      "23-01-24 17:55:01.034 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_start_training_data'}\n",
      "23-01-24 17:55:01.036 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-01-24 17:55:01.039 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-01-24 17:55:01.041 [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'None_training_data'})\n",
      "23-01-24 17:55:01.044 [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'None_training_data'}\n",
      "23-01-24 17:55:01.045 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-01-24 17:55:01.070 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.071 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.071 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.077 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 63) with member_id aiokafka-0.8.0-4603e920-961e-4c3b-91cf-a81bea43aa92\n",
      "23-01-24 17:55:01.078 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-01-24 17:55:01.081 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 63\n",
      "23-01-24 17:55:01.083 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.085 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.085 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.086 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.090 [INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.091 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:01.092 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:02.792 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:04.086 [WARNING] aiokafka.consumer.group_coordinator: Heartbeat failed for group kumaran-airt-service-kafka-1:9092_group because it is rebalancing\n",
      "23-01-24 17:55:04.092 [INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions frozenset({TopicPartition(topic='None_realtime_data', partition=0)}) for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:04.093 [INFO] aiokafka.consumer.group_coordinator: (Re-)joining group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:04.095 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 64) with member_id aiokafka-0.8.0-4603e920-961e-4c3b-91cf-a81bea43aa92\n",
      "23-01-24 17:55:04.097 [INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "23-01-24 17:55:04.100 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 64) with member_id aiokafka-0.8.0-eb233eb6-7673-4e17-98b6-86c2a39adde8\n",
      "23-01-24 17:55:04.101 [INFO] aiokafka.consumer.group_coordinator: Joined group 'kumaran-airt-service-kafka-1:9092_group' (generation 64) with member_id aiokafka-0.8.0-106c3bfa-0045-439d-8e03-7ebf1b0cd36e\n",
      "23-01-24 17:55:04.103 [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {'None_realtime_data': 1} to {'None_start_training_data': 1, 'None_realtime_data': 1, 'None_training_data': 1}. \n",
      "23-01-24 17:55:04.107 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 64\n",
      "23-01-24 17:55:04.110 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:04.111 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 64\n",
      "23-01-24 17:55:04.113 [INFO] aiokafka.consumer.group_coordinator: Successfully synced group kumaran-airt-service-kafka-1:9092_group with generation 64\n",
      "23-01-24 17:55:04.114 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_start_training_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:04.116 [INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='None_realtime_data', partition=0)} for group kumaran-airt-service-kafka-1:9092_group\n",
      "23-01-24 17:55:07.827 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:12.861 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:17.898 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:22.936 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:27.970 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:33.006 [INFO] __main__: event in test is event=<TrainingEvent.upload: 'upload'> account_id=6000 total=1000 user_id=446 uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88') id=52 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 1)\n",
      "23-01-24 17:55:38.043 [INFO] __main__: event in test is event=<TrainingEvent.end: 'end'> account_id=6000 total=1000 user_id=446 uuid=UUID('7380ae02-6586-4f7b-b051-56da168965c2') id=53 count=999 created=datetime.datetime(2023, 1, 24, 17, 55, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All events for account id 6000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TrainingStreamStatus(event=<TrainingEvent.start: 'start'>, account_id=6000, total=1000, user_id=446, uuid=UUID('831abe3c-2fe1-4df1-9286-2249e03713b0'), id=51, count=0, created=datetime.datetime(2023, 1, 24, 17, 54, 47)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.upload: 'upload'>, account_id=6000, total=1000, user_id=446, uuid=UUID('517388ba-ae13-4cad-8456-1b62962e8c88'), id=52, count=999, created=datetime.datetime(2023, 1, 24, 17, 55, 1)),\n",
       " TrainingStreamStatus(event=<TrainingEvent.end: 'end'>, account_id=6000, total=1000, user_id=446, uuid=UUID('7380ae02-6586-4f7b-b051-56da168965c2'), id=53, count=999, created=datetime.datetime(2023, 1, 24, 17, 55, 33))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-01-24 17:55:38.254 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-01-24 17:55:38.255 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-01-24 17:55:38.256 [INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "23-01-24 17:55:38.257 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-01-24 17:55:38.257 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-01-24 17:55:38.259 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-01-24 17:55:38.260 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-01-24 17:55:38.261 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-01-24 17:55:38.262 [INFO] fast_kafka_api._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [88256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server stopped\n"
     ]
    }
   ],
   "source": [
    "def test_process_training_status():\n",
    "    logger.info(\"I am done at tests\")\n",
    "    with get_session_with_context() as session:\n",
    "        user = session.exec(select(User).where(User.username == test_username)).one()\n",
    "        test_start_event = TrainingStreamStatus._create(\n",
    "            account_id=6000,\n",
    "            event=\"start\",\n",
    "            count=0,\n",
    "            total=1000,\n",
    "            user=user,\n",
    "            session=session,\n",
    "        )\n",
    "        session.add(test_start_event)\n",
    "        session.commit()\n",
    "\n",
    "        p = Producer(confluent_kafka_config)\n",
    "        msg_count = 1000\n",
    "        training_data = generate_n_rows_for_training_data(msg_count, seed=999)\n",
    "        for i in range(msg_count):\n",
    "            p.produce(\n",
    "                f\"{test_username}_training_data\",\n",
    "                json.dumps(training_data[i]).encode(\"utf-8\"),\n",
    "                on_delivery=delivery_report,\n",
    "            )\n",
    "        p.flush()\n",
    "\n",
    "    start = datetime.utcnow()\n",
    "    while True:\n",
    "        if datetime.utcnow() - start > timedelta(seconds=10 * 60):\n",
    "            assert None, \"Taking too long to finish while loop. Probably loop is stuck.\"\n",
    "        sleep(5)\n",
    "        with get_session_with_context() as session:\n",
    "            user = session.exec(\n",
    "                select(User).where(User.username == test_username)\n",
    "            ).one()\n",
    "            event = session.exec(\n",
    "                select(TrainingStreamStatus)\n",
    "                .where(TrainingStreamStatus.user == user)\n",
    "                .where(TrainingStreamStatus.account_id == 6000)\n",
    "                .order_by(TrainingStreamStatus.id.desc())\n",
    "                .limit(1)\n",
    "            ).one()\n",
    "            logger.info(f\"event in test is {event}\")\n",
    "            if event.event == \"end\":\n",
    "                display(f\"All events for account id {6000}\")\n",
    "                all_events = session.exec(\n",
    "                    select(TrainingStreamStatus)\n",
    "                    .where(TrainingStreamStatus.user == user)\n",
    "                    .where(TrainingStreamStatus.account_id == 6000)\n",
    "                )\n",
    "                display([e for e in all_events])\n",
    "                break\n",
    "\n",
    "\n",
    "display(\"starting semaphore\")\n",
    "# with posix_ipc.Semaphore(\n",
    "#     \"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT, initial_value=1\n",
    "# ) as sem:\n",
    "# sem = posix_ipc.Semaphore(\"/infobip_kafka_topics_semaphore\", flags=posix_ipc.O_CREAT)\n",
    "# sem.acquire(timeout=10 * 60)\n",
    "display(\"semaphore started\")\n",
    "create_topics_for_user(username=test_username)\n",
    "with set_env_variable_context(variable=\"JOB_EXECUTOR\", value=\"fastapi\"):\n",
    "    with MonkeyPatch.context() as monkeypatch:\n",
    "        monkeypatch.setattr(\n",
    "            \"__main__.get_count_from_training_data_ch_table\",\n",
    "            lambda account_ids: pd.DataFrame(\n",
    "                {\n",
    "                    \"curr_count\": [999],\n",
    "                    \"AccountId\": 6000,\n",
    "                    \"curr_check_on\": [datetime.utcnow()],\n",
    "                }\n",
    "            ).set_index(\"AccountId\"),\n",
    "        )\n",
    "        app, fast_kafka_api_app = create_ws_server(\n",
    "            assets_path=Path(\"../assets\"), start_process_for_username=None\n",
    "        )\n",
    "\n",
    "        @fast_kafka_api_app.run_in_background()\n",
    "        async def startup_event():\n",
    "            await process_training_status(\n",
    "                username=test_username, fast_kafka_api_app=fast_kafka_api_app\n",
    "            )\n",
    "\n",
    "        config = uvicorn.Config(app, host=\"0.0.0.0\", port=6010, log_level=\"debug\")\n",
    "\n",
    "        with run_uvicorn(config):\n",
    "            # Server started.\n",
    "            sanitized_print(\"server started\")\n",
    "            test_process_training_status()\n",
    "\n",
    "        sanitized_print(\"server stopped\")\n",
    "        # Server stopped.\n",
    "# sem.release()\n",
    "# sem.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62834287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
